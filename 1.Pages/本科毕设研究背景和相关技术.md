---
Type:
  - Page
aliases: 
Status:
  - archive
tags: 
modifiedDate: 星期一, 五月 26日 2025, 8:43:17 晚上
---

## 研究现状

### RAG在推荐系统中的应用

利用大模型强大的推理和生成能力获得的外部知识的这种做法存在包括幻觉，过时的知识等问题。RAG技术可以用来缓解这些问题。

RAG（Retrieval-Augmented Generation）检索增强生成结合了检索和生成的机器学习方法，主要用于自然语言处理领域。RAG模型通过检索相关信息来增强语言生成任务，例如文本摘要、翻译、问答等。RAG模型的核心思想是利用大规模的文档集合作为知识库，当处理一个特定的输入时，模型首先从这个知识库中检索出最相关的文档或文档片段，然后将这些检索到的信息与输入一起送入一个生成模型，如Transformer，以生成更加准确和丰富的输出。

根据研究,RAG总体可分为四类，分别是**基于查询的 RAG 方法，基于隐空间表达的 RAG 方法,基于概率表示的 RAG 方法以及投机 的RAG 方法。**

- 基于查询的 RAG 方法是最为广泛使用的方法，又称为提示扩充，检索器将检索的到的内容与用户原始的输入合并，形成一个增强序列。这个增强序列随后被输入模型获得结果。这种方法本质上与提示工程中的生成知识提示【】类似，且可以与提示词工程、少样本学习相结合。
- 基于隐空间表达（latent representation）的RAG方法通过在生成过程中将检索到的内容以潜在向量形式与模型内部状态交互，增强了模型对信息的理解力。这种方法常采用拼接或注意力机制等技术来优化生成内容的质量和相关性。
- 基于概率表示的RAG方法在生成文本时，通过概率融合技术结合检索信息，使得模型能够在解码过程中考虑不同信息源的相关性和可靠性。这种方法通过概率求和或加权，优化了生成内容的准确性和丰富性。
- 投机RAG方法通过优先使用成本较低的检索过程来替代或辅助生成过程，以降低整体计算成本。这种方法在处理常见问题或已有答案的场景下，通过检索历史数据来快速提供响应，提高了效率并节约了资源。

### 预训练语言模型作为推荐器本身

PLM的出现不仅给自然语言处理带来了巨大的成功，其也在推荐等其它领域展现出了巨大的潜力。一个有前景的方向也就是让PLM直接作为推荐器本身，让PLM直接完成推荐任务。在早期阶段，推荐所使用的语言模型的规模相对较小（例如，参数少于十亿），通常使用微调以获得更好的性能。例如，LMRecSys[7]将基于会话的推荐任务转移到提示中并评估BERT和GPT-2在电影推荐中的性能。P5[8]和M6-Rec[9]通过将多个推荐任务转换为自然语言序列来微调预训练语言模型，以便将训练语料库中的知识与语义结合起来，以实现个性化的推荐。类似的，RecFormer[9]将用户偏好和项目特征建模为语言表示，用于顺序推荐。

随着模型规模和数据集的扩大，LLM展现了其在多种任务上不可思议的能力。推理能力是LLM的独特能力之一，且只有当模型大小超过一定阈值时才会出现。又因为如果要微调LLM，这需要大量算力，所以零样本学习（Zero-shot learning）或上下文学习（In-context learning）的方法被广泛使用。一些将LLM应用为推荐器的研究获得了一些初步结果。例如，ChatRec[11]了研究了能否将LLM应用为会话式多轮推荐的推荐系统接口。一项工作[44]研究了能否通过特定任务提示词将ChatGPT作为推荐器，并报告了其零样本学习的性能。又一项工作[26]进一步报告了LLM 与历史交互数据结合情况下的零样本排名的性能。

然而，直接使用LLM作为推荐器的性能通常落后于最先进的推荐算法，这表明了领域知识和协作信号对推荐任务的重要性[12,13]。因此，一些工作尝试通过微调LLM以提高推荐性能。例如，TALLRec[14]使用LoRA对LLaMA-7B进行微调。ONCE[17]将LlaMA-7B作为内容编码器并微调部分参数。另一项研究[15]在推荐数据上对Open-AI的ada模型进行了微调，但发现其性能不佳。但无论是哪种方法，均忽略了LLM巨大的参数量造成的难以接受的推理延迟以及组合性差距问题。

### 预训练语言模型作为传统推荐组件

与上一小节所说的将PLM作为推荐器本身的研究方向不同，另一种研究方向探索的是如何将PLM作为传统推荐系统的辅助工具并提高推荐系统性能。一类方法将PLM用于编码文本特征（项目概述、用户评论），从而获得更好的用户或项目表示。例如，U-BERT [16]使用BERT编码用户评论来补充用户表示。ZEREC [18]将传统推荐系统与PLM 结合起来，使其能够从单个训练数据集推广到其它陌生的数据集上。UniSRec[19]利用BERT来编码用户行为，从而学习下游推荐的通用序列表示。上述方法通常使用小型PLM（例如具有110M参数的bert-base）将文本转换为密集向量，其语义信息可能有限，因此可能无法为传统推荐系统提供强有力的帮助。

另一类方法采用具有十亿级参数的大型语言模型，专注于编码文本或使用提示词技术获取来自LLM的外部知识。例如，一些研究人员提出了S&R多域基础模型[21]，它对ChatGLM2-6B[20]进行微调，以提取域内不变特征，从而在冷启动场景中提升搜索和推荐性能。LLM-Rec[22]研究了从GPT-3生成增强输入文本的各种提示策略，这提高了推荐能力。另一项研究[23]利用InstructGPT-175B从用户-项目交互中创作合成叙事查询，并在合成数据上训练检索模型，以增强叙事驱动的推荐。尽管这些方法在利用LLM方面进行了早期尝试，但它们要么只是简单地将LLM用作编码器，将原始文本转换为密集向量，而不生成额外的文本知识，要么没有专门设计网络结构将生成的文本信息融入到传统推荐系统中。事实上，使用LLM获得的嵌入的噪音或高维度可能会导致推荐系统的不稳定。
