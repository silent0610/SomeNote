---
Type:
  - Paper
aliases:
tags: 
Status:
  - done
modifiedDate: 2025/07/09, 14:33:02
---

# Parallel and Distributed Bayesian Network Structure Learning

## Abstract

贝叶斯网络（Bayesian Networks, BNs）是表示因果发现中不确定性的图形模型，因其高效性和良好的可解释性，被广泛应用于医疗诊断和基因分析。然而，主流的贝叶斯网络结构学习方法计算成本高昂，因为它们必须执行大量的条件独立性（Conditional Independence, CI）测试来确定边的存在。一些研究人员尝试通过并行化来加速学习过程，但面临负载不均衡、昂贵的主要并行开销等问题。

我们提出了一种多线程方法，即多核 CPU 上的 Fast-BNS version1（简称 Fast-BNS-v1），以提高贝叶斯网络结构学习的效率。Fast-BNS-v1 包括一系列效率优化措施，包括使用动态工作池以改进调度、分组 CI 测试以避免不必要的操作、缓存友好的数据存储以提高内存效率，以及即时生成条件集以避免额外的内存消耗。

为了进一步提升学习性能，我们开发了一种两级并行方法 Fast-BNS v2，通过多进程的边级并行和多线程的 CI 级并行相结合。Fast-BNS-v2 配备了一系列精心设计的优化措施，包括通过动态工作窃取实现负载平衡、使用 SIMD 技术删除边列表以更新列表，以及有效的通信策略以实现同步。

综合实验表明，我们的 Fast-BNS 在单机上比最先进的多线程方法快 9 至 235 倍。当运行在多台机器上时，与单机实现相比，它进一步减少了 80% 的执行时间。

### 索引词

贝叶斯网络, 分布式机器学习系统, 并行化

## Ⅰ. 介绍

贝叶斯网络（Bayesian Networks, BNs）[1] 是一种概率图模型，使用有向无环图（Directed Acyclic Graphs, DAGs）来紧凑地表示一组随机变量及其条件依赖关系。贝叶斯网络的图形化特性使其非常适合表示带有不确定性的知识和有效推理。随着近年来对可解释机器学习模型需求的增长，贝叶斯网络因其固有的可解释性引起了大量研究关注 [2], [3]。

贝叶斯网络（BNs）训练中的一个关键任务是结构学习，其目标是学习与观测数据高度匹配的有向无环图（DAGs）。图 1 展示了一个基于某数据集的交通预测贝叶斯网络示例。数据集中的每一列代表一个变量并对应于贝叶斯网络中的一个节点，而每一行是一个样本，记录了这些变量的观测值。直观上，在大多数情况下，如果“Cloudy”（多云）或“Windy”（有风）为“yes”，则“Rainy”（下雨）也为“yes”，因此我们推断“Cloudy”和“Windy”很可能是“Rainy”的原因。因此，在贝叶斯网络结构学习中，我们倾向于发现两条有向边，分别连接“Cloudy”到“Rainy”和“Windy”到“Rainy”。类似的思路可用于推测其他变量之间的边。

然而，由此直观方法学到的贝叶斯网络结构过于粗略，难以应用于实际场景。为了更精确地学习贝叶斯网络结构，常用的两种方法是基于评分的方法和基于约束的方法。基于评分的方法使用评分函数来衡量 DAGs 与数据的匹配度，并在所有可能的 DAGs 中找到得分最高的一个，这使得可能的 DAGs 数量随着学习问题的维度（即变量数）的增加呈超指数级增长 [4]。另一方面，基于约束的方法通过执行大量的条件独立性（CI）测试来识别随机变量之间的条件独立关系，并将这些关系作为约束来构建贝叶斯网络。这类方法通常在多项式时间内运行，并在实际应用中被广泛使用 [5]。

一个基本的基于约束的算法是 PC 算法（以其作者 Peter 和 Clark 命名）[6]，该算法从一个完全无向图开始，并根据条件独立性（CI）测试在连续的深度中移除边。PC-stable [7] 解决了原始 PC 算法中的顺序依赖问题，并减少了比原始 PC 算法更多的错误。PC-stable 算法已广泛应用于各种应用中 [5], [8]，并在不同的主流贝叶斯网络包中实现，如 bnlearn [9]、pcalg [10] 和 tetrad [11]。此外，大多数基于约束的方法都是 PC-stable 算法的改进版本，或在类似的思路上进行发展。然而，PC-stable 算法在执行大量 CI 测试时，尤其是在高维问题中，执行时间较长。由于 PC-stable 的算法改进并非易事 [12]，因此已有多个研究致力于在多核 CPU 上加速 PC-stable 算法 [13], [14], [15]。最常见的方法是并行化每一深度中不同网络边的处理，这在 PC-stable 算法的顺序无关特性下直观可行。然而，直接的边级并行存在负载不均衡的问题，因为不同边的 CI 测试工作量差异很大。为了克服这些问题，我们提出了 Fast-BNS 第一版（简称 Fast-BNS-v1），这是一种基于 CI 级别的多线程并行 PC-stable 实现，配备了动态工作池来容纳待处理的边及其在 CI 测试中的处理进度。Fast-BNS-v1 利用 CI 测试批处理、缓存友好的存储和即时数据生成来加速 PC-stable 并节省内存消耗。相关内容已在一篇会议论文中发表 [16]。

为了进一步提高贝叶斯网络结构学习的效率，我们将 Fast-BNS-v1 扩展到多进程和分布式设置，从而得到了 Fast-BNS-v2。由于每个进程具有独立的内存以避免竞争条件，多进程并行通常能实现更高的 CPU 利用率 [17]，同时通过释放多台机器的计算能力来减少时间消耗。此外，Fast-BNS-v2 利用了两级并行，结合了多线程和多进程并行的优点，以增强设备利用率并提升算法性能。在不同的层级中，我们应用了不同的并行策略和粒度。更具体地说，为了减少通信开销并平衡工作负载，Fast-BNS-v2 的高层采用粗粒度的子任务划分，而低层则采用细粒度的子任务划分。在 Fast-BNS-v2 中，CI 级别的并行在线程级别实现，边级别的并行在进程级别执行。值得指出的是，CI 级别的工作负载平衡通过类似于 Fast-BNS-v1 的动态工作池来实现，而边级别的工作负载调度则利用动态工作窃取 [18]。

总之，本文是我们会议论文 [16] 的扩展，具有以下额外的贡献。

- 我们扩展了之前的算法 Fast-BNS-v1，并提出了 Fast-BNS-v2 以支持多机环境。由于进程之间具有独立的内存空间，Fast-BNS-v2 利用了两级并行，从而在多核和多机环境中实现了更好的资源利用。在 Fast-BNS-v2 中，边级并行实现于多进程并行，而 CI 级并行则应用于多线程并行。
- 为了进一步提高 Fast-BNS-v2 的效率，我们开发了一系列新技术，包括通过动态工作窃取实现负载平衡以提升 CPU 利用率、使用 SIMD 技术删除边列表以维护活跃边、以及简化的通信协议以减少数据传输成本。
- 我们进行了实验以研究我们提出的方法的有效性。单机实验结果表明，Fast-BNS-v1 和 Fast-BNS-v2 的顺序版本在性能上比现有的工作 bnlearn [9] 和 tetrad [11] 快多达 50 倍。与 bnlearn [13] 中的多线程实现相比，Fast-BNS-v1 快 9 到 24 倍，而 Fast-BNS-v2 快 9 到 235 倍。最后，我们展示了 Fast-BNS-v2 在分布式环境中的良好可扩展性，进一步减少了单机实现的 80% 执行时间。

## Ⅱ. 预备知识

在本节中，我们提供与贝叶斯网络结构学习相关的关键术语和定义，然后回顾PC-satble算法。

### A. 贝叶斯网络

贝叶斯网络（BNs）是一类图形模型，通过有向无环图（DAG）表示一组随机变量 $V = \{V_0, V_1, \dots, V_{n-1}\}$ 上的联合分布 $P$。通常，一个变量对应于机器学习问题中的一个特征。我们用 $G = (V, E)$ 来表示该 DAG。图 1(a) 展示了一个示例 DAG，记作 $G$，其中 $V$ 中的每个节点与一个变量相关联，$E$ 中的每条边表示两个变量之间的条件依赖关系。如果在 $G$ 中从 $V_j$ 到 $V_i$ 存在一条有向边，则称 $V_j$ 为 $V_i$ 的父节点，我们用 $P_a(V_i)$ 表示 $V_i$ 的父节点集合。在贝叶斯网络中，每个变量都有其局部概率分布，描述在给定其父节点配置的情况下，该变量可能取值的概率。贝叶斯网络中变量 $V$ 的联合概率可以分解为每个变量的局部概率分布的乘积，每个局部概率分布仅依赖于一个变量 $V_i$ 及其父节点：

$$
P(V_0,V_1,\ldots,V_{n-1})=\prod_{i=0}^{n-1}P(V_i|Pa(V_i)),
$$

其中, $n$ 是变量的数量，$P(V_0, V_1, \dots, V_{n-1})$ 是联合概率,$P(V_i \mid P_a(V_i))$ 是变量 $V_i$ 的条件概率，给定其父节点 $P_a(V_i)$。

### B. 条件独立性检验

考虑贝叶斯网络中的一些随机变量 $V_i$, $V_j$ 和 $V_k$，一个条件独立性（CI）检验断言形式为 $I(V_i, V_j \mid \{V_k\})$，表示在给定 $V_k$ 的条件下，$V_i$ 和 $V_j$ 独立。令 $D = \{c_0, c_1, \dots, c_{m-1}\}$ 表示一个包含 $m$ 个完整样本的数据集，一个 CI 检验 $I(V_i, V_j \mid \{V_k\})$ 决定是否根据数据集 $D$ 的统计量验证对应的假设 $I(V_i, V_j \mid \{V_k\})$ 是否成立。对于离散变量，最常用的用于检验 $I(V_i, V_j \mid \{V_k\})$ 的统计量是 G2 检验统计量 [6]，定义为：

$$
G^{2}=2\sum_{x,y,z}N_{xyz}log\frac{N_{xyz}}{E_{xyz}},
$$

其中，$N_{xyz}$ 是数据集 $D$ 中满足 $V_i = x$, $V_j = y$ 且 $V_k = z$ 的样本数量。$N_{xyz}$ 的值可以从列出所有取值配置频率的列联表中获得。$G^2$ 服从渐近的 $\chi^2$ 分布，其自由度为 $(|V_i| - 1)(|V_j| - 1)$，其中 $| \cdot |$ 表示变量可能取值的数量。$\chi^2$ 分布的 $p$ 值可以根据 $G^2$ 统计量计算，最终决策通过将 $p$ 值与显著性水平 $\alpha$ 比较来做出。如果 $p$ 值大于 $\alpha$，则接受独立性假设 $I(V_i, V_j \mid \{V_k\})$；否则，拒绝该假设。$E_{xyz}$ 是期望频率，其定义为：

$$
E_{xyz}=\frac{N_{x+z}N_{+yz}}{N_{++z}},
$$

其中，$N_{x+z} = \sum_{y} N_{xyz}$，$N_{+yz} = \sum_{x} N_{xyz}$，以及 $N_{++z} = \sum_{xy} N_{xyz}$，它们分别表示边际频率。

### C. PC稳定算法

PC-stable 算法是一种基于约束的方法，用于从数据中学习贝叶斯网络（BN）的结构。PC-stable 包括三个步骤。 第一步是确定图的骨架。骨架是指学习到的网络的基础无向图。这个步骤通过执行大量的条件独立性（CI）检验来完成。 第二步是识别骨架中的 v 结构。一个 v 结构是一个三元组 $(V_i, V_j, V_k)$，可以表示为 $V_i \to V_k \gets V_j$。换句话说，节点 $V_i$ 和 $V_j$ 有一条指向节点 $V_k$ 的出边，并且 $V_i$ 和 $V_j$ 在图中没有任何边相连。v 结构是区分不同网络结构的关键组件。通过在此步骤中识别 v 结构，骨架中的一些边变成了有向边。 第三步是通过应用一组称为 Meek 规则 [19] 的规则，为尽可能多的剩余无向边设置方向。例如，当存在一条有向边 $V_i \to V_j$ 且 $V_i$ 和 $V_k$ 不相邻时，将无向边 $V_j - V_k$ 的方向设置为 $V_j \to V_k$；否则会创建一个新的 v 结构。 在 PC-stable 算法的三个步骤中，第一步耗时最多 [20]，在许多问题中占总执行时间的 90\% 以上。在第三节中，我们详细阐述了我们提出的用于加速第一步的技术。  

PC-stable 算法第一步的伪代码如算法 1 所示。其总体思想是初始化 $G$ 为节点集 $V$ 上的完全无向图（第 3 行），并通过在连续深度中执行若干条件独立性（CI）检验移除部分边（第 6 至第 16 行）。  
具体来说，在每个深度 $d$，算法会迭代记录所有节点的当前邻接集，其中 $adj(G, V_i)$ 表示 $V_i$ 在图 $G$ 中的邻接节点（第 5 行）。此操作用于稍后选择条件集 $S$。接下来，对于图 $G$ 中的每条边 $(V_i, V_j)$，对不同的条件集执行若干 CI 检验 $I(V_i, V_j|S)$。条件集中的元素从 $a(V_i)\setminus\{V_j\}$ 中选择，并且每个条件集的大小 $|S|$ 等于当前深度 $d$（第 7 至第 10 行）。如果存在一个条件集 $S$ 使得 $V_i$ 在给定 $S$ 的条件下与 $V_j$ 独立，则从 $G$ 中移除边 $(V_i, V_j)$，并将 $S$ 存储到 $SepSet(V_i, V_j)$ 中（第 11 至第 13 行）。$SepSet(V_i, V_j)$ 表示 $V_i$ 和 $V_j$ 的分离集，用于 PC-stable 算法第二步中识别 v 结构。由于第二步执行速度快且不是我们工作的重点，因此省略分离集的详细信息。当所有边都被考虑后，深度 $d$ 增加 1（第 15 行），并对下一个深度重复上述过程。深度 $d$ 用于控制条件集的大小从小到大递增。此过程持续进行，直到图 $G$ 中所有相邻节点对 $(V_i, V_j)$ 满足 $|a(V_i)\setminus\{V_j\}| < d$，如第 16 行所示。

## Ⅲ. 我们提出的 FAST-BNS

本节介绍了我们提出的Fast-BNS的技术细节，这是一种用于BN结构学习的并行方法。我们提出的方法的两个版本（即Fast-BNS-v1和Fast-BNS-v2）的细节将在下文中详细阐述。

### A. 设计概述

以下是对我们提出的 Fast-BNS 的概述。Fast-BNS 是一种在并行和分布式环境中高效学习贝叶斯网络（BN）结构的并行与分布式方法。图 2 描述了 Fast-BNS 在深度 $d$ 时的设计，该设计涉及两个分布式进程。

在分布式多进程层面，全局边列表由根进程维护，边通过动态工作窃取策略分发到所有进程（参见第 III-C 节）。在并行多线程层面，每个进程维护一个动态工作池，用于监控分布边在条件独立性（CI）检验方面的处理进度（参见第 III-B 节）。CI 检验会动态地被提取并由并行线程处理。根据 CI 检验的结果，每个进程的本地边列表会被更新并合并到全局边列表中。

传统并行化可分为两种类型：数据级并行和任务级并行。数据级并行将不同的数据块分配给执行相同操作的工作单元，而任务级并行将带有不同指令的子任务映射到工作单元。在 PC-stable 算法中，每一步都依赖于前一步的结果，这使得其不适合任务级并行化。大多数 BN 结构学习的并行方法利用数据级并行性来加速算法的执行，因为数据是可分割的。

从实现的角度来看，并行技术包括多线程并行和多进程并行。在本工作中，我们首先开发了 Fast-BNS-v1，该方法通过同时评估多个 CI 检验来实现多线程并行。尽管多线程并行实现简单，但它仅利用一个进程，这限制了学习过程所能使用的总资源，同时限制了线程之间的并行性。另一方面，多进程并行避免了竞争条件并提高了总体计算能力，因为每个进程占有自己的内存空间和计算资源。

为了提高 Fast-BNS-v1 的效率，我们提出了 Fast-BNS-v2。该方法使用多进程并行并通过负载平衡策略实现了边级并行。此外，Fast-BNS 配备了一系列创新优化，包括：

1. 将 CI 检验分组以减少不必要的 CI 检验；
2. 使用缓存友好的数据存储提高内存效率；
3. 动态生成 CI 检验的条件集，并行执行以避免额外的内存消耗；
4. 利用 SIMD 边列表删除减少计算复杂度。

为了更好地理解 Fast-BNS，我们对其性能进行了理论分析。接下来，我们详细阐述了 Fast-BNS 的技术细节并推导了其理论结果。

### B.多线程并行

在本小节中，我们介绍了所提出的方法：FastBNS-v1，它采用多线程并行化。在每一深度，线程可以并行处理来自不同边的条件独立性（CI）检验。为了实现多线程并行化，我们的关键思想是在共享内存中为每一深度使用一个动态工作池，该工作池通过一个栈实现。工作池包含需要处理的边及其与 CI 检验相关的处理进度。因此，每次一个线程可以从工作池中提取属于多条边的 CI 检验，通过这些边的处理进度找到下一组 CI 检验并并行执行。

创建和删除线程通常消耗较少的时间，因此可以经济地维护一批线程。我们的方法也可以视为一种 fork-join 模型【21】。在每一深度开始时，主进程会 fork 出一些线程，这些线程共享同一内存空间以并行执行 CI 检验。随后，这些 fork 出的线程会被合并回主进程，并执行数据合并操作。由于 fork 和 join 操作的开销相对较低，fork-join 模型在多线程并行中被广泛使用。

具体来说，在每一深度开始时，当前图 $G$ 中的所有边都会以零处理进度被推入工作池。然后，每次从工作池中弹出 $t$ 条边，并枚举这些边的 CI 检验。每个线程负责处理一组 CI 检验，其中 CI 检验的数量以 $gs$ 表示（$gs \geq 1$）。当 $gs$ 个 CI 检验完成后，需要做出以下两个决策：

1. 是否接受这组 CI 检验的独立性假设；
2. 该边是否需要重新推入工作池。

具体而言，如果这组 CI 检验中任意一个 CI 检验接受其独立性假设，则接受这组的独立性假设；否则，拒绝该假设。如果接受了独立性假设，或者在处理这组后该边已完成了所有 CI 检验，则意味着该边的处理完成，无需将其重新推入工作池；否则，该边会被推回工作池，并将其处理进度记录为上一次处理的最后一个 CI 检验。

之后，再次从工作池中弹出 $t$ 条边，并由 $t$ 个并行线程处理每条边接下来的 $gs$ 个 CI 检验（根据其处理进度）。这一过程会迭代执行，直到工作池为空。

直观上，这一过程可以看作多个线程并行处理不同边上的多个 CI 检验，但线程并未固定绑定到某一条边。当某条边的处理完成后，线程会立即转向处理其他边的 CI 检验，而无需等待其他边的完成。这得益于动态工作池的设计，该工作池可以监控每条边的处理进度。通过边监控技术，已完成处理的边会及时终止，从而减少不必要的 CI 检验。此外，借助动态工作池的设计，我们可以更好地调度线程之间的工作负载。所有线程始终处理需要处理的 CI 检验，因此在并行区域内所有线程都是活跃的。

如图 3 所示，黄色的 CI 检验被分配给线程 0，蓝色的 CI 检验被分配给线程 1。一条边的 CI 检验不一定由一个线程全部处理完成。

$gs$ 是 CI 检验数量与内存访问之间的权衡。在并行区域，每个线程每次处理同一条边 $Vi - Vj$ 的 $gs$ 个 CI 检验，并根据结果做出决策。因此，组内的 CI 检验共享相同的形式 $I(Vi, Vj|S_n), 0 \leq n < gs$。由于 $Vi$ 和 $Vj$ 对整个组是共同的，我们建议在遍历数据集时重用它们，从而减少内存访问。随着 $gs$ 的增大，减少的内存访问也增多。然而，同时也引入了更多冗余的 CI 检验，因为在做出是否需要再次处理边的最终决策之前，组内的所有 CI 检验都必须执行。在特殊情况下，当 $gs = 1$ 时，不会引入冗余的 CI 检验。我们仔细检查了 $gs$ 的影响，观察到像 6 或 8 这样的较小 $gs$ 在实践中是较好的选择。

值得注意的是，当深度 $d \geq 1$ 时，使用了多线程并行化。而在深度 $d = 0$ 时，条件集 $S = \emptyset$，因为条件集的大小等于 $d$（参见算法 1，第 11 行）。具体来说，对于图 $G$ 中的每条边 $(Vi, Vj)$，只需要一个 CI 检验，即 $I(Vi, Vj|\emptyset)$，或简而言之是一个边际独立性检验 $I(Vi, Vj)$。换句话说，我们可以预先知道在深度零时需要多少个 CI 检验，这个数量等于 $n(n - 1)/2$，表示节点集 $V$ 上完整无向图 $G$ 中的边数，其中 $n$ 表示节点的数量。因此，深度零所需的计算可以简化。因此，在深度零时直接应用边级别并行化，而不会遇到负载不均衡的效率问题。

### C. 多进程并行

在本小节中，我们介绍了所提出的多进程并行方法 Fast-BNS-v2，该方法将边级别的子任务分配给进程，并在并行中执行这些子任务。一般来说，多线程并行更适合细粒度的子任务，而多进程并行更适合粗粒度的子任务。多进程并行避免了竞争条件，并提高了整体性能，因为每个进程占用独立的内存空间和计算资源。为了实现多进程并行，我们必须设计进程间通信技术，因为进程之间有独立的内存空间。如何快速而精确地同步和交换数据与信号是多进程并行中的关键步骤。直观地，我们可以将粗粒度的子任务分配给进程。然后，我们将粗粒度的子任务划分为细粒度的子任务，并分配线程来执行这些细粒度的子任务。为了充分利用进程和线程，我们开发了一个两级并行的 PC-stable 算法，采用多线程的 CI 检验级别并行性和多进程的边级别并行性。为了更好地利用多进程，我们设计了两项技术以进一步提高 Fast-BNS-v2 的效率：i) 通过动态工作偷取机制实现负载平衡，以减少 CPU 空闲时间，ii) 单向和集体通信策略，以减少数据传输开销。

1. **边级别并行性和 CI 级别并行性**：将 PC-stable 算法并行化的最自然方案是并行处理每个深度内的不同边，这是粗粒度的并行性。PC-stable 算法的顺序无关特性使得它适合在每个深度进行并行化。换句话说，删除某个边不会影响同一深度内其他边的处理，因此不同边的处理可以并行进行。在每个深度 d 中，它并行化每个边的 CI 测试（即算法 1 中第 7 行的 for 循环），将 $|\mathcal{E}_d|$ / t 条边分配给每个线程，其中 t 表示线程或进程的数量，$|\mathcal{E}_d|$ 表示深度 d 中需要处理的边的数量。图 3 展示了 CI 级别并行性和边级别并行性的执行进度。图中的例子包含四条边，因此在使用两个进程的情况下，每个进程有两个线程，每个进程负责处理两条边。具体来说，进程 0 负责 E0 和 E1 边，而 E2 和 E3 则分配给进程 1。边级别并行可以合理分配工作负载给进程，并由于其较小的通信开销，在多机器上运行。然而，不同的边有不同数量的 CI 测试，这需要通过负载均衡策略来仔细处理。相比之下，CI 级别并行性在共享内存中的线程之间负载均衡，但将大量 CI 测试分配到多机器上会导致巨大的通信开销。在 Fast-BNS-v2 中，我们结合这两个层次，采用在多进程中进行边级别并行，在多线程中进行 CI 级别并行，从这两个层次中获取好处。表 I 总结了三种并行性：边级别、CI 级别和两级（边级别和 CI 级别的组合）。在 CI 级别并行性的自然实现中，我们需要枚举所有可能的 CI 测试，总共是$O(\binom nr)$次 CI 测试。然后，协调线程需要将这些 CI 测试分配给工作线程进行评估。只需稍加操作就能指定线程在共享内存空间中进行 CI 测试。然而，将这些 CI 测试分配给进程会产生显著的通信开销，因为 CI 测试的数量非常庞大。进程间通信是为了在多进程并行中交换分布式内存中的数据，但它在 CI 级别数据交换中的效果有限。因此，多进程并行在 CI 级别上不适用。  
     
   对于多进程并行来说，具有较大粒度的边级别更适合于 BN 结构学习。算法 2 展示了我们提出的 Fast-BNS-v2 的管道过程。与算法 1 类似，我们首先形成一个完整的图并将深度设置为 0（第 3 到第 4 行）。在这里，我们创建一个布尔标签数组来记录需要删除的边（第 5 行）。我们按深度检查边，直到无法找到足够的变量来构建分离集（第 7 到第 26 行）。对于每个进程，它不断获取新的边子列表，直到没有更多新的子列表（第 9 到第 22 行）。获取边子列表 T 后，我们从 T 中获取一个子列表 T ′ 并将这些边分解为 CI 测试（第 14 到第 15 行）。然后，我们使用多线程并行性和 CI 级别并行性来进行 CI 测试，方式与 Fast-BNS-v1 的实现相同（第 17 到第 21 行）。如果某个 CI 测试成立，我们为该边打上需要删除的标签（第 20 行），并跳过同一边的 CI 测试（第 21 行）。完成该深度的所有 CI 测试后，我们应用集体通信操作：allreduce 来同步进程间的需要删除标签（第 23 行），然后通过 SIMD 边列表删除操作删除这些边（第 24 行）。
   
2. **进程间负载均衡策略**：在判断一条边之前，我们无法准确预测需要进行多少次 CI 测试才能确认该边的存在。每条边的 CI 测试数量是不同的：在最佳情况下为 1 次，而在最坏情况下则与邻居的数量成指数关系。因此，一次性分配工作会导致负载不均衡，因为每个进程测试一条边所需的时间是不可预测的。我们的目标是调度进程以获得接近的执行时间，并避免空闲时间，从而提高机器的利用率。首先，我们尝试选择一个代理函数来估算每条边的 CI 测试数量。根据最坏情况下 O((n r )) 对一条边的估算，我们将这些边分配给具有相同总组合数的进程。然而，这种一次性负载均衡策略是低效的，因为代理函数不准确。受到动态负载均衡方法——任务偷取的启发，我们将边列表划分为 rwd 个子列表，其中 wd 是深度 d 中子列表的大小。每个进程一开始拥有一个子列表。一旦某个进程完成检查一个子列表，非阻塞调度器就会为该进程提供一个新的子列表，直到没有更多新的子列表为止，使用单向通信（在第 III-C2 节中提到），而其他进程的执行不受调度器干扰。一个简单的方法是将每个子列表设置为相同的长度。根据流量控制理论，我们可以通过将头部子列表设置得比底部子列表长来减少通信开销，因为所有进程在开始时有相同的起始时间并同步运行任务。因此，我们在这里减少了同步的频率，以降低通信成本。当所有进程接近结束时，较短的子列表可以占据较小的进程时间间隔。然而，子列表的长度也有一个下限，以避免过多的通信。为了平衡通信开销和计算开销，我们需要将子列表的长度设置为一个合理的大小。在完成此深度的所有子列表后，我们应用 allreduce 操作来收集来自不同进程的结果。
   
3. **进程通信优化**：多进程并行中的通信成本对整体效率有显著影响。因此，我们提出了三种技术来减少通信成本。首先，在完成 PC-stable 第一步之后，我们采用不同的策略来执行第二步和第三步。在多进程设置下，我们选择只让一个进程在一台机器上执行。在多机器设置下，每台机器同时执行这两个步骤并获取结果，从而避免了结果传输的通信。其次，为了缩短单一深度中通信所消耗的时间，我们只维护一个整数变量——未检查边列表的起始位置。一旦一个进程完成其当前的子任务，它便获取起始位置并通过增加新子列表的长度来更新该变量。这一策略通过单向通信 [22] 实现，它是一种非阻塞通信，解耦了数据交换和任务执行。我们在主进程中创建一个共享内存窗口，其他进程可以访问此窗口来获取和更新。通过单向通信，获取新子列表不会干扰主进程中的任务运行。一个锁保证了每次只有一个进程能够访问窗口，从而避免了竞争问题。第三，在完成某一深度的 CI 测试后，我们通过 allreduce 操作同步不同进程中的结果。每个进程维护一个布尔数组，表示每条边的存在性，并与其他进程的数组进行按位与操作，以合并 CI 测试的结果。为了完成这一步，简单的实现方法是先收集各个进程的数组，然后计算结果，最后将结果数组发送给每个进程。Allreduce 操作有效地将通信和计算结合在一起，并具有强大的可扩展性，容易扩展到多台机器。在我们的算法中，由于 CI 测试数量庞大，我们采用了适用于大数据集的树形 allreduce 实现。

### D. 进一步改进 Fast-BNS

我们在现有的实现中发现了四个问题：[13]，[14]，[15]。首先，将具有相同端点的边的CI测试分配给不同的线程效率低，因为这可能导致不必要的CI测试。其次，内存访问模式不规则，因为一个CI测试所需的值不一定是顺序存储的。第三，CI测试的数量较大，需要大量内存来存储所有CI测试的条件集合的索引。第四，按顺序逐个删除边表中的元素效率低，因为从数组中删除一个元素需要线性时间，导致总的时间复杂度为平方级别。这些问题在我们上述提出方法的朴素组合中降低了性能。我们的方法需要仔细设计优化，以提高其效率。在这里，我们旨在解决这四个问题，以进一步提高Fast-BNS的整体效率。

1. 将具有相同端点的边的CI测试分组：我们将具有相同端点的边，如边$V_i - V_j$和$V_j - V_i$，视为Fast-BNS-v1中的同一条边，而不是像原始的PC-stable算法那样将其分开，因为分开这两条边的CI测试效率低。例如，给定$V_i$和$V_j$之间的边，我们需要在$adj(G, V_i)\setminus \{V_j\}$和$adj(G, V_j)\setminus \{V_i\}$中的变量条件下执行CI测试。然而，如果我们首先在$adj(G, V_i)\setminus \{V_j\}$中的变量条件下执行CI测试，并且$V_i$和$V_j$之间的边被移除，那么在$adj(G, V_j)\setminus \{V_i\}$中的变量条件下执行的CI测试是没有必要的。因此，我们通过将具有相同端点的边的CI测试分组在一起，减少需要执行的CI测试数量，从而提高效率。如果$V_i$和$V_j$之间的CI测试在以$S \in adj(G, V_i)\setminus \{V_j\}$为条件时接受独立性假设，则Fast-BNS-v1不会在$adj(G, V_j)\setminus \{V_i\}$中的变量条件下执行CI测试。
2. 使用缓存友好的数据存储：算法的关键步骤是计算列联表。例如，测试$I(X, Y | \{Z_1, Z_2\})$时，我们需要遍历整个数据集并获取所有样本的$X$，$Y$，$Z_1$和$Z_2$的值。对于一个朴素的二维数据集存储，其中每一行表示一个样本，每一列表示一个特征（即BN中的一个变量），我们需要遍历所有行并为每一行查找四个值。由于$X$，$Y$，$Z_1$和$Z_2$不一定是连续存储的，因此会有许多随机内存访问，因此每次内存访问可能会造成缓存未命中。因此，我们提出转置数据矩阵，即使用每一行表示一个特征，每一列表示一个样本，这是一种缓存友好的数据存储方式。对于前面的例子，在第一列的前四次内存访问之后，后续的迭代会访问缓存中先前获取的值旁边的地址。因此，Fast-BNS-v1在开始时只会有四次缓存未命中，剩余的则可以从四个缓存行中获取。
3. 按需生成条件集合：} 在PCstable算法中，处理一条边可能需要许多CI测试，这取决于当前的深度$d$和其端点的邻居节点数量。在朴素的实现中，我们必须在处理边之前生成该边的所有CI测试。这种方法效率低，因为需要额外的内存来存储所有CI测试的条件集合的索引。给定一条边$V_i - V_j$，其条件集合的选择可以视为一个组合问题，从$p = |a(V_i)\setminus \{V_j\}|$个元素中一次选择$q$个元素（参见算法1，第11行）。Fast-BNS-v1实现了一个组合函数以字典顺序生成$S$[23]。给定$p$，$q$和$r$，Fast-BNS-v2的组合函数能够直接计算向量$S_r$，而不计算整个集合$S$。借助该组合函数，所有CI测试的条件集合索引可以按需计算，并且可以并行执行。因此，Fast-BNS-v1的工作池只包含待处理的边及其处理进度（即$r$）。不需要额外的内存来存储边的条件集合的索引。
4. 使用SIMD进行边表删除：在我们之前的实现中，Fast-BNS-v1[16]，它是逐个删除元素的。删除边表中的一个元素需要线性时间。因此，更新整个边表的时间复杂度为$O(n^2)$，这对于整个算法来说是非常耗时的。每一层结束时的边表更新是一个布尔掩码操作，它从旧的边表中选择元素来构建一个新的边表，参照一个与旧边表长度相同的布尔数组。基于这个观察，Fast-BNS-v2创建了一个新的边表，并将所需的元素复制到其中。通过$O(n)$的内存分配和$O(n)$的复制操作，整体复杂度降至$O(n)$，极大地提高了边表删除效率。实验结果表明，该操作的执行时间接近$O(1)$。

### E. 性能分析

在这里，我们分析了我们在本节前面讨论的优化所提供的理论加速。要分析的优化包括：i）使用CI级别的并行性与动态工作池的设计；ii）将具有相同端点的边的CI测试分组；iii）使用缓存友好的数据存储。我们还将在本节中讨论通信开销。

1. CI级别的并行性和边级别的并行性：在图$G$的深度$d$处，存在$|\mathcal{E}_d|$条边需要处理。每条边$E_i$，具有两个端点$ep_i^1$和$ep_i^2$，有若干个CI测试。两个端点的邻接节点数，分别表示为$a_i^1 = |adj(G, ep_i^1)|$和$a_i^2 = |adj(G, ep_i^2)|$，以及深度$d$和CI测试的结果，决定了CI测试的数量。具体来说，每条边最多会导致个CI测试，而如果在处理一条边的过程中某个CI测试接受了独立性假设，则该边的处理会提前终止（即剩余的CI测试变得不必要）。对于并行运行的$t$个线程，边级别的并行性将$|\mathcal{E}_d|/t$条边分配给每个线程。理想情况下，分配给每个线程的$|\mathcal{E}_d|/t$条边具有相同数量的CI测试需要处理。然而，在实际情况中，大多数情况下存在负载不平衡的问题。例如，$|\mathcal{E}_d|/t$条边会处理每条边所需的所有个CI测试，而其他$(t-1)||\mathcal{E}_d|/t$条边在处理它们的第一个CI测试时，由于接受了独立性假设，只会处理一个CI测试。在最坏的情况下，处理所有所需CI测试的$|\mathcal{E}_d|/t$条边被分配到同一个线程$p$上。在这种情况下，边级别并行性的性能可能会受到严重影响，因为所有线程必须等待最慢线程$p$完成。如果每个CI测试的时间为$T_{CI}$，那么在$t$个线程下，边级别并行性所需的时间为

   $$














T_1=T_{CI}\sum_{i=1}^{\frac{|\mathcal{E}_d|}{t}}\left(\begin{pmatrix}a_i^1\\d\end{pmatrix}+\begin{pmatrix}a_i^2\\d\end{pmatrix}\right).\quad\text{(1)}

$$
   然而，所提出的CI级并行在动态工作池的帮助下将所有CI测试均匀地分布到每个线程，因此所需的时间是
   
$$

T_2=\frac{T_{CI}}{t}\left(\sum_{i=1}^{\frac{|\mathcal{E}_d|}{t}}\left(\begin{pmatrix}a_i^1\\d\end{pmatrix}+\begin{pmatrix}a_i^2\\d\end{pmatrix}\right)+\frac{(t-1)|\mathcal{E}_d|}{t}\right).\quad(2)

$$
   因此，使用动态工作池设计的CI级别并行性提供的加速比为$S_{CI} = \frac{T_1} {T_2}$
   
   在我们的Fast-BNS-v2中，我们开发了两级并行（多线程和多进程级别）。在边缘层，我们为Fast-BNS-v2配备了动态工作窃取机制来平衡进程之间的工作负载，这类似于多线程并行中动态工作池的效果。因此，所需时间为
   
   进程之间最大的时间滞后是执行时间最长的边，并且该边位于队列的最后位置。
1. 将具有相同端点的边的CI测试分组：该优化通过减少不必要的CI测试提供加速。考虑深度d的情况，该深度有$|\mathcal{E}_d|$条边需要处理，对于Vi和Vj之间的边，由于在原始的PC-stable算法中，边Vi−Vj和Vj−Vi被视为分开的，我们需要执行考虑两个集合的CI测试，即adj(G, Vi)\\{Vj}和adj(G, Vj)\\{Vi}。因此，对于深度d中的$|\mathcal{E}_d|$条边，我们需要考虑总共2$|\mathcal{E}_d|$个集合。然而，通过将Vi−Vj和Vj−Vi的CI测试分组，如果在考虑集合adj(G, Vi)\\{Vj}时，CI测试接受独立性假设，则Fast-BNS-v2不再考虑集合adj(G, Vj)\\{Vi}。假设ρd是深度d的边删除比率。那么， 该优化通过删除ρd$|\mathcal{E}_d|$个不必要的集合来减少CI测试。也就是说，只需要考虑2$|\mathcal{E}_d|$−ρd$|\mathcal{E}_d|$个集合。因此，如果忽略不同集合CI测试数量的差异，分组CI测试带来的加速为：
      
$$

S_{grouping}=\frac{2|\mathcal{E}_d|}{2|\mathcal{E}_d|-\rho_d|\mathcal{E}_d|}=\frac{2}{2-\rho_d}.

$$
3. 使用缓存友好的数据存储：该优化通过减少缓存未命中的比例提供加速。PC-stable的内存访问主要来自在计算列联表时对数据集的访问。对于深度d中的CI测试I(X, Y |{Z1, . . ., Zd})，我们需要访问数据集中的m个样本的X, Y, Z1, ..., Zd的值，每个值在内存中占用4字节。假设缓存行大小为B字节。首先，我们考虑访问$\frac{B}{4}$ 个样本。对于缓存不友好的数据存储，由于X, Y, Z1,..., $Z_d$不一定存储在彼此相邻的位置，每次内存访问都可能是一次缓存未命中。因此，缓存不友好的数据存储中，访问$\frac{B}{4}$个样本的所需时间为：

   
$$

T_4=T_{DRAM}(d+2)\frac{B}{4},

$$
   其中，$T_{DRAM}$ 表示主内存的访问时间（由于缓存未命中导致）。但是，对于缓存友好的数据存储，它只有 $(d+2)$ 次缓存未命中，用于访问第一个样本，而剩下的 $(\frac{B}{4}-1)$ 个样本的访问可以从 $(d+2)$ 个缓存行中得到服务，因为它们访问的地址紧挨着之前在缓存中获取的值的地址。因此，访问 $\frac{B}{4}$ 个样本的值所需要的缓存友好数据存储的时间是
   
$$

T_5=T_{DRAM}(d+2)+T_{cache}(d+2)\left(\frac{B}{4}-1\right),

$$
   式中，Tcache为缓存访问时间。由于m通常远大于B，因此对整个数据集的访问时间是对$\frac{B}{4}$ 个样本的访问时间的倍数。因此，缓存友好型数据存储提供的加速是$S_{cache}=\frac{T4}{T5}$。  
1. 总体加速比：最后，Fast-BNS 的性能提升可以通过以下公式计算：$S=S_{\text{CI}} \cdot S_{\text{grouping}} \cdot S_{\text{cache}}$. 例如，假设线程数 t = 4 且深度 d= 2。假设在深度 2 开始时有$|\mathcal{E}_d|=1200$ 条边，结束时有 480 条边，因此，边删除比率 $ρ_d$=0.6。假设每条边有相同数量的邻接节点，即图的平均度（假设平均度为 10）。因此，公式 (1) 和 (2) 中的每个 $a_i^1$和 $a_i^2$都可以替换为平均度 10。此外，缓存行大小 BB 通常为 64 字节。缓存访问时间 `T_cache` 通常比主内存访问时间 `T_DRAM` 快 5 到 10 倍，我们假设 $\frac{T_{DRAM}}{  T_{cache}} = 8$。因此，在这些情况下，我们可以计算出 Fast-BNS 提供的理想加速比：$S_{CI} = 3.87$，$S_{grouping} = 1.43$，$S_{cache} = 5.57$，因此总加速比 S = 30.8。然而，这一理论分析仅提供了 Fast-BNS 的一般加速比，实验中的情况往往比理想情况更为复杂。例如，$|E_d|$、$ρ_d$、$a_{i}^1$ 和 $a_{i}^2$ 的值都取决于待解决的具体问题，而且这些值通常在事先是未知的。

2. 通信分析：在这一部分，我们讨论 Fast-BNS 的通信开销。在每个深度开始时，每个进程通过单边通信获取其子列表。子列表的总数为 $rw_d$，因此这一单边通信开销为$rw_d$ 字节。在所有进程完成每个深度内的 CI 测试后，执行 allreduce 操作来同步不同进程之间的 CI 测试结果。深度 $d$ 中的边的大小为$∣\mathcal{E}_{d}∣$，因此我们的方法在该深度传输 $(r+1)∣\mathcal{E}_{d}∣$ 字节。最后，我们得出总的通信量为：$\sum_d(r+1)|\mathcal{E}_d|+rw_d$  字节
## F. 我们模型的推广

我们提出的方法可以很容易地扩展到其他机器学习模型。例如，在卷积神经网络（CNN）中，我们可以应用批次之间的多进程并行和一个批次中样本之间的多线程并行。此外，具有通信优化的负载平衡技术适用于多进程范例，例如多GPU训练。对样本进行分组或提高缓存效率有利于拥有大量数据集的任务。即时生成中等结果有助于减少其他任务的内存开销。SIMD数组修改可以加速深度学习方法中的张量运算。
# IV. 实验
我们进行了广泛的实验来证明我们的方法的性能，并将结果与最先进的方法进行比较。
## A. 实验设置
我们在 C++ 中实现了我们的贝叶斯网络结构学习方法，使用了 OpenMPI 和 OpenMP 库，并将它们的性能与现有方法进行了比较。所有的单机实验都在一台 Linux 机器上进行，该机器配备了两颗 28 核 2.6 GHz 的 Intel Xeon Gold 6348 CPU 和 768 GB 主内存。对于多机设置，我们使用了 8 台具有上述环境的机器。具体来说，我们比较了 Fast-BNS-v2 和 Fast-BNS-v1 的顺序实现与三个不同的开源软件包，包括 bnlearn [9]、pcalg [10] 和 tetrad [11]。我们还将 Fast-BNS-v2 与 bnlearn [13] 和 parallel-PC [15] 中的最新多线程实现进行了比较。Bnlearn、pcalg 和 parallel-PC 都是 R 包，而 tetrad 是用 Java 实现的。还进行了实验，比较了 Fast-BNS-v1 和 Fast-BNS-v2，以展示本文工作的改进，相比于我们之前的工作 [16]。还有其他的并行工作，例如文献 [14] 中的工作，然而，该算法不是开源的。此外，他们的实验结果显示，相比于 Fast-BNS-v2 的并行实现相对于其顺序实现的加速效果，该算法的并行实现相对于其顺序实现的加速效果较低。因此，我们没有将 Fast-BNS-v2 与其进行比较。

我们实验中使用的数据集来自八个不同大小的基准 BN，如表 II 所示，其中最后四个数据集是大规模的 BN。这些网络代表了不同领域的问题，并且在 BN 结构学习的文献中广泛用于比较。我们从每个网络中获得了 5000 个没有缺失值的样本数据。此外，为了测试不同样本大小的影响，我们为前四个网络分别获得了 10000 和 15000 个样本。我们使用 G2 检验统计量来执行 CI 测试，并在所有实验中将显著性水平 α 设置为 0.05。Fast-BNS-v2 和 Fast-BNS-v1 的准确性与其他 PC-stable 算法实现完全相同，因为这两种方法是相同 PC-stable 算法的加速实现。因此，我们省略了准确性比较的结果。
## B. 总体对比

在对 Fast-BNS-v2 的总体评估中，我们将 Fast-BNS-v2 的顺序和并行实现的执行时间与现有实现进行了比较，比较的对象是八个包含 5000 个样本的数据集。具体而言，我们将 Fast-BNS-v2 的顺序版本与 bnlearn [9]、pcalg [10] 和 tetrad [11] 软件包中的 PC-stable 实现进行了比较；我们还将 Fast-BNS-v2 的并行版本与 bnlearn [13] 和 parallel-PC [15] 中的多线程实现进行了比较。所有实验中，Fast-BNS-v2 的 gs 都设置为 1。在比较并行实现时，我们将 MPI 进程的数量 t 从 1 改为 32，并选择了执行时间最短的一个。如果实验的执行时间超过 48 小时且没有得到结果，则实验终止。

实验结果总结在表 III 中。从表格中的“Speedup”列可以看出，我们提出的 Fast-BNS-v2 的顺序实现通常比 tetrad 和 pcalg 快两到三个数量级，并且比 bnlearn 的顺序版本快 1.07 到 82 倍。Fast-BNS-v2 的加速主要得益于精心的优化，包括 SIMD 边列表删除、对具有相同端点的边的 CI 测试分组、使用缓存友好的数据存储以及动态生成条件集合。这些通用优化可以应用于顺序和并行实现。

在比较并行实现时，Fast-BNS-v2 通常比 parallel-PC 快得多，比并行 bnlearn 快 9.2 到 283 倍。值得注意的是，对于一些小数据集，如 Alarm 和 Insurance，bnlearn 没有通过多线程技术获得改进，因此其顺序实现和并行实现的结果相同。另一个观察结果是，Fast-BNS-v2 始终在 t = 32 时实现最短的执行时间。此外，使用多进程可以将 Fast-BNS-v2 的顺序版本的执行时间减少超过 85%。在 Link 数据集上的实验是完成时间最长的任务。该任务使用现有的顺序实现（bnlearn、tetrad、pcalg）和并行实现（parallel-PC）运行了超过 2 天，而在 Fast-BNS-v2 中，执行时间显著减少至大约 14 分钟。
## C. Fast-BNS -V2 Vs Fast-BNS-V1
为了更好地理解 Fast-BNS-v2 的改进，我们将其与 Fast-BNS-v1 进行比较。表 IV 显示了结果。在顺序版本的比较中，Fast-BNS-v2 通过 SIMD 边列表删除带来了最多 16% 的改进。我们观察到，Fast-BNS-v1 修改边列表数组大约需要 170 秒，而 Fast-BNS-v2 仅在这部分花费了 0.02 秒，得益于 SIMD 边列表删除技术。在并行版本中，由于多进程初始化的开销，Fast-BNS-v2 在小数据集上的提升不显著。当数据集的大小增加时，例如在 Diabetes、Link、Munin2 和 Munin3 数据集上，Fast-BNS-v2 相比 Fast-BNS-v1 缩短了 5 到 48 倍的执行时间，这得益于我们的多进程并行和增强技术，包括 SIMD 边列表删除、负载均衡方法和通信策略。

为了进一步探究为什么 Fast-BNS-v2 比 Fast-BNS-v1 更快，我们对比了多线程并行和多进程并行。在多进程版本中，我们将每个进程设置为仅使用一个线程，并在单台机器上运行。图 4 显示了 Fast-BNS-v2 在多进程并行下减少执行时间（强扩展性），在较大的数据集上尤为明显。在 Munin1 中，两个版本显示出相似的执行时间，而在 Munin2 和 Munin3 中，多进程版本显著快于多线程版本。图 4 的另一个观察结果是，当线程数少于 8 时，增加线程数是有益的，而 32 个线程的性能与 16 个线程相似。原因是，多线程在一个进程中维护一个动态线程池，其中的线程共享进程的资源。相比之下，每个进程持有自己的资源，无需干扰其他进程。因此，由于隔离的运行环境，多进程并行可以理想地减少训练时间。例如，4 个进程的执行时间大约是 2 个进程的一半。

为了进一步研究为什么 Fast-BNS-v2 更快，我们使用 perf Linux 分析器对 Fast-BNS-v1 和 Fast-BNS-v2 进行了详细的测量。表 V 显示了 Munin2 和 Munin3 上的结果。我们可以观察到，无论是并行版本还是顺序版本，Fast-BNS-v2 的 CPU 利用率和 FLOPS 都比 Fast-BNS-v1 更高。这是因为多进程并行提升了资源利用率，而一个进程中的多线程并行受到操作系统的限制，无法充分利用 CPU。

我们还在图 5 中测量了不同样本数下的耗时（弱扩展性），在三个数据集上进行比较。在 Munin1 中，耗时呈线性增长，而在 Munin2 和 Munin3 中，15000 与 10000 之间的时间增长大于 10000 与 5000 之间的增长。较大的数据集导致了更多的加载数据和计算 CI 测试项的时间，这在较小的数据集上并不明显。


## D. 进程的负载平衡和通信
在这组实验中，我们研究了我们提出的负载均衡策略的有效性，其中我们为每个进程分配了相等数量的边，并以 Munin3 作为示例。图 6(a) 和 (b) 显示了 Munin3 数据集中的深度 1 和深度 2 执行时间，其中深度 1 和深度 2 每个分离集分别有一个和两个变量。从结果可以看出，Fast-BNS-v2 在没有负载均衡优化的情况下会导致负载不均。在深度 1 中，最快的进程花费了 60 秒，而最慢的进程花费了 180 秒，这是因为每个边的工作负载不同。进程需要在每个层次结束时进行同步，导致了空闲问题。在应用负载均衡策略后（在第 III-C 节讨论），进程的执行时间趋于约 125 秒。在深度 2 中，我们的方法减少了最慢进程的 30% 执行时间，并提高了利用率。图 6(c) 显示了不同深度下平衡方法和不平衡方法的时间分布。深度 1 和深度 2 占用了两种方法中大部分的时间，而其他深度的时间则微不足道。我们的负载均衡策略有一个超参数 l，它是动态工作窃取中的子列表数。由于子列表数量可能会影响整体效率，这里我们改变了 l 的值以更好地了解其影响。图 7 展示了不同 l 值下的执行时间。对于 Munin1 数据集，4 或 8 个子列表就足够了，而对于 Munin2 和 Munin3，则 16 或 32 个子列表更为合适。正如图中所见，当 l 增加到 128 时，由于更高的通信成本，执行效率降低。

我们提出的多进程并行性可以自然地在分布式环境中运行。这里，我们研究了 Fast-BNS-v2 的可扩展性，并分析了它的通信成本。我们在单机和多机设置下测量了通信成本。在单机设置中，我们观察到通信成本小于 15 毫秒，如图 8 所示，显示了 Munin2 和 Munin3 中的时间。结果表明，该任务是计算密集型的，通信成本在总执行过程中占的时间很小。在多机设置中，我们在 2 到 9 台机器上运行 Fast-BNS-v2，每台机器只有一个进程，进程间的通信是机器间通信。图 9 显示了结果。随着机器数量的增加，执行时间减少，而通信成本保持较低。我们观察到，速度提升并没有随着进程数量的增长而线性提升。这主要是因为：九台机器之间工作负载不完全平衡（尽管不平衡度不会超过一个边），为每个进程设置计算环境的开销，以及我们的方法并没有将所有步骤都并行化。
# V. 相关工作
贝叶斯网络（BNs）是强大的模型，用于人工智能中的表示学习和不确定性推理。最近，贝叶斯网络在研究界和工业界都受到了广泛关注。一个关键方面是从数据中学习贝叶斯网络的依赖图，这被称为结构学习。在本文中，我们将相关的贝叶斯网络结构学习的研究工作分为两类：基于评分的方法和基于约束的方法。

基于评分的方法 [30]、[31]、[32]、[33] 根据评分函数来寻找最佳的有向无环图（DAG），这些评分函数衡量贝叶斯网络结构与观察数据的适配程度。广泛采用的评分函数包括 BDeu、BIC 和 MDL。然而，可能的 DAG 数量是变量数量的超指数级别 [4]。因此，许多基于评分的方法采用启发式方法，如贪婪搜索或模拟退火，以尝试减少搜索空间。这些方法很容易陷入局部最优解 [12]。本文中的优化技术集中于基于约束的方法，这些方法通常能更好地扩展到高维数据。

基于约束的方法 [6]、[7]、[34] 使用一系列统计检验，如卡方检验、G2 检验和互信息检验，来学习模型中变量之间的条件独立关系。然后，根据这些关系构建 DAG 作为约束。在本工作中，我们集中于加速 PC-stable 算法用于学习贝叶斯网络结构。事实上，许多常见的基于约束的算法类似或是 PC 或 PC-stable 算法的变种 [6]、[7]，例如结合 PC 和贪婪搜索的 GES [35]，结合 PC 和 GES 优点的 MMHC [36]，通过 CI 检验从局部到全局搜索 Markov Blanket 的 IAMB [36]，以及为快速训练设计的启发式搜索 Hiton-PC [37]。与基于评分的方法不同，基于约束的方法通常难以通过通用优化理论进行算法改进。

一些著名的开源贝叶斯网络库包含了 PC-stable 算法的实现，例如 bnlearn [9]、pcalg [10] 和 tetrad [11]。同时，由于最近出现的多核 CPU 和 GPU 等并行计算平台，可以有效地解决各种计算机器学习问题 [38]、[39]、[40]，因此有一些研究工作集中在使用并行技术加速 PC-stable 算法在 CPU 上的应用 [13]、[14]、[15]。其关键思想是并行处理每个深度内的不同边，这个想法非常直观，因为 PC-stable 算法具有顺序无关的属性。然而，边级并行性存在负载不均衡的问题，因为不同边的条件独立性检验的工作负载高度偏斜。本文通过条件独立性级并行性提高 PC-stable 算法的效率，以加速贝叶斯网络结构学习的应用。并行技术也被应用于马尔可夫毯方法 [41]。如今，GPU 并行技术显示出巨大的贝叶斯网络学习加速潜力。gpuPC [42] 和 cuPC [20] 提出了基于 GPU 的 PC 和 PC-stable 加速。然而，GPU 在处理分歧（如 if 语句）时存在困难，而分歧是 CI 检验中的一个重要部分。此外，GPU 很难安排不规则的子任务大小并平衡进程或线程之间的工作负载，这使得贝叶斯网络学习的实现变得更加困难。

我们在表 VI 中比较了 CPU 和 GPU 在贝叶斯网络学习中的特性。配备分支预测的 CPU 可以更好地处理 CI 检验的计算。CPU 还具有更好的灵活性和通用性，适用于顺序、多线程、多进程和多机执行。相比之下，GPU 在多进程或多机执行方面存在一定的局限性，因为它们对进程隔离的支持较弱，并且在多个 GPU 之间的数据传输和协调机制本身较为复杂。同时，GPU 中的线程或处理器数量超过 CPU，适用于在不同数据上应用更简单的指令。因此，CPU并行对于复杂的并行计算场景（如混合边缘级和CI级并行）表现出明显的优势，而GPU并行仅支持CI级或更细粒度级并行。

# VI. 结论
贝叶斯网络结构学习一直是因果发现和可靠机器学习的热门话题。本文提出了一种新颖的并行和分布式方法（称为 FastBNS），旨在加速 PC-stable 算法，这是最常用的基于约束的结构学习算法之一。过去的方法仅关注多线程并行性，而 FastBNS 利用多进程和多线程并行性，并支持多台机器。在数据方面，条件独立性（CI）级别对于多进程并行性来说过于精细，但边级并行性则面临工作负载不均衡的问题。在 Fast-BNS 中，我们开发了负载平衡策略，以克服工作负载不均衡问题，同时利用多线程的 CI 级并行性进一步提升性能。我们的实验结果表明，Fast-BNS 可以比最先进的实现速度快 9 到 235 倍。在多机运行时，它节省了 80% 的时间，相较于单机实现，且通信开销较低。
