---
Type:
aliases: 
tags: 
modifiedDate: 2025/07/05, 00:24:22
---

# 前向渲染和延迟渲染面经

## 知道哪些常见渲染路径，它们有什么差异？描述一下延迟渲染和前向渲染？什么是延迟渲染？延迟渲染和正向渲染的区别是什么？说说延迟渲染管线？

主要分为前向着色（forward shading）和 [[延迟渲染|Deferred Shading]] 两类。

前向着色是思路是：将一个图元发送到管线中，计算对应片元的颜色，并最终更新到屏幕上。
前向着色会出现较多的过度绘制，主要来自于两个方面：
- 首先是某些执行着色计算的片元，之后可能会因为被遮挡而丢弃；
- 其次是对2×2四边形中的所有像素都需要执行着色，尽管可能只有1一个像素真正位于三角形中。
- **2×2 四边形**：光栅化过程中，GPU 会以 **像素块** 的方式处理三角形。通常，光栅化并不是逐像素进行的，而是将屏幕分成若干个像素块（例如 2x2 的块），每个像素块包括 4 个像素。在某些实现中，GPU 会将这些像素块一起处理以提高效率。
- **着色计算**：对于每个像素块，GPU 会执行一次**着色计算**，这意味着即使有些像素在三角形外部并不需要计算，GPU 也会执行这些不必要的计算。虽然只有一个像素在三角形内部有效，但对于整个 2x2 四边形中的所有像素，GPU 都需要进行着色计算。
- **过度绘制**：这就造成了所谓的 **过度绘制**，即对不必要的像素也进行了渲染和计算，但这些像素最后可能会因为深度测试（或其他遮挡测试）被丢弃。换句话说，GPU 做了很多不必要的工作，尤其是在复杂的场景中，很多像素最终是看不见的，但仍然被计算了。

延迟着色的思路是：首先第一个pass执行可见性测试以及所需表面属性的评估计算，将这些信息存储在G-buffer（geometric buffer）中。然后第二个pass再使用这些信息进行着色计算。延迟着色也会出现过度绘制(重复的写入 Buffer)，即在几何pass中生成G-buffer的过程中，但是这里过度绘制的成本会低很多，因为不需要执行真正的着色计算。

## 前向渲染的优缺点是什么？

基础前向渲染的优点：
- 实现简单
- 支持多种着色模型
- 支持透明物体
- 带宽压力和显存压力低
- 支持 MSAA
缺点：
- OverDraw 浪费算力, 如果不使用 [[Z-Prepass]] 等算法
- 无法处理大量光源

## 延迟渲染的优缺点是什么？在移动端实现需要注意什么？

- 优点
    - 支持大量光源, 每像素进行着色计算而不是每个片元, 大大减少计算量
    - 几何 Pass 预先保存可见性信息和材质信息, 减少 OverDraw
    - 易与 [[Visibility Buffer]] 等技术整合
    - G-buffer中的信息可以便于实现各种后处理效果。
    - **所有的像素着色使用同一个像素着色器，减少了着色器的变体数量。**
- 缺点
    - 需要使用多个 Buffer 保存信息, 带宽和显存压力大
    - 重复读写G-buffer时，很容易造成带宽瓶颈。
    - 对MSAA的支持不友好（开销过大）。通常使用 FXAA 或 TAA
        - 在 G-buffer 中为每个像素存储颜色、法线、深度等信息。每个像素对应多个样本时，G-buffer 会为每个样本创建单独的存储，这会导致 **G-buffer 的存储开销** 成倍增加。
        - **内存开销**：MSAA 会增加每个像素的样本数，导致 **G-buffer** 的大小增加。例如，如果开启 4x MSAA，每个像素的 G-buffer 会需要 **4 倍的内存**。
        - **计算开销**：在光照计算阶段，需要对每个样本进行独立的光照计算，增加了计算的复杂度。每个样本的光照计算是独立的，因此 **需要多次遍历和计算**，这使得计算开销显著增加。
    - 不支持透明物体渲染, 因为只渲染最前面的
        - 透明物体需要基于 **深度排序** 来正确地进行混合。透明物体的光照是依赖于**正确的绘制顺序**（通常是从远到近），这与延迟渲染的设计思想不兼容，因为延迟渲染通过 **统一的光照计算** 阶段处理场景中的所有物体，但它不保留每个像素的 **深度顺序**，这对于透明物体的混合至关重要。
    - **只能使用单一的着色模型。**

## 如何改进前向渲染？具体怎么实现？

1. 使用一个 [[Z-Prepass]], 预先计算写入所有不透明物体的深度, 但不进行任何着色计算, 然后使用这个 Z-buffer, 再来个 Pass, 剔除所有不可见片元
2. 可以对场景物体进行粗略排序，按照大致从前向后的顺序进行渲染，这样也可以降低过度绘制，其效果类似于使用z-prepass。
3. 结合分 Tile思想, 即 [[TileBasedLighting]], 或者 forward+. 使用一个 computeshader 对点光源逐 tile 进行划分. 每个 shader 根据片元所在屏幕空间的位置访问该 Tile 的光源列表 
4. 使用 [[ClusterBasedLighting]] ,即在 view space 内, 对每个 Tile 构成的视锥体进行非均匀划分, 每个 cluster 存储光源列表. 在进行片元着色的时候，查询并该片元所对应的光源列表。
5. 使用 [[Hi-Z]], 借鉴 mipmap 思想, 上层的 Z 是下层区域 Z 的最大值, 如果物体比上层大, 即可直接剔除, 加速遮挡查询

## 你会选用 forward+ 还是延迟渲染？为什么？

- 首先需要明确的一点是, 没有任何一个算法是通用且最优的，具体使用什么样的技术组合才是最佳的，不仅仅取决于场景内容，也取决于每个物体或者每个光源上的变化，需要根据实际项目需求进行分析。

### 我会选择 **延迟渲染**，如果项目符合以下特征：

- **核心需求是支持海量的动态光源**，例如一个拥有上千个点光源的夜晚城市或科幻场景。
- 场景中的**不透明物体占绝大多数**，透明物体（如玻璃、特效）很少或不重要。
- 对**高质量的 MSAA 没有硬性要求**，可以使用 TAA (时间性抗锯齿) 等现代后处理方案作为替代。
- **材质类型相对统一**，不需要支持大量截然不同的光照模型。
- 目标平台是**拥有高显存和高带宽的现代 PC 或主机**。

### 我会选择 **Forward+**，如果项目符合以下特征：

- 需要**高质量、稳定的抗锯齿效果 (MSAA)**，例如竞速或模拟类游戏。
- 场景中有**大量的透明或半透明效果**，例如水、玻璃建筑、复杂的粒子系统。
- 需要**支持非常丰富的材质**，例如角色皮肤、布料、金属、车漆等混合在一个场景中。
- 目标平台**包含移动设备或中低端 PC**，对显存带宽和占用比较敏感。
- 光源数量虽然多，但没有多到延迟渲染成为唯一选择的程度。

## 什么场景用延迟？什么场景用前向？

- 延迟渲染适用的场景
    - 场景内光源数量较多
    - 场景内深度复杂度很高
    - 场景中存在大量小三角形
        - 这和上一点（高深度复杂度）密切相关。一个由大量微小三角形构成的复杂模型（例如高精度的角色、茂密的植被）必然会导致严重的Overdraw。
    - 场景中的贴花效果较多
        - 贴花是指在场景表面上投射的额外纹理
        - 你可以直接渲染一个简单的几何体（如一个立方体包围盒）来代表贴花区域。在这个立方体的着色器中，读取G-Buffer的像素信息，判断该像素是否在贴花的投射范围内，如果是，就直接**修改G-Buffer中的数据**（例如，将反照率颜色改为弹孔的颜色）。这个修改会自然而然地被后续的光照阶段所使用，效果完美且性能开销极低。
    - 场景中的透明物体数量较少
    - 目标平台的分辨率较高（高分辨在一定程度上可以替代MSAA）
    - 目标平台的带宽较大
- 前向渲染
    1. 场景中的光源数量较少
    2. 场景中的深度复杂度较低
    3. 场景中的小三角形数量较少
    4. 场景中的贴花效果较少
    5. 场景中的透明物体数量较多
    6. 目标平台的分辨率较低
    7. 目标平台的带宽较低

## 例如水面反射在延迟渲染的屏幕空间下会丢失信息，那么前向渲染如何进行计算？

这里说水面反射在延迟渲染的屏幕空间下会丢失信息，应该指的是在延迟渲染中使用 [[SSR]] 来渲染水面反射，由于SSR所使用的场景几何描述实际上只有屏幕深度信息，因此位于屏幕之外的，或者被某些场景物体所遮挡的信息并不会被深度缓冲记录下来，本质上我们只使用了一个场景壳，因此会丢失一些信息。

- SSR需要使用法线缓冲和深度缓冲，因此非常适合在延迟渲染中进行使用，如果前向渲染想要使用SSR，还需要一个pre-depth&normal的pass。
- 在前向渲染中想要实现水面反射效果，可以使用平面反射（Planar Reflection）技术，即保持场景表示不变，将观察者的位置和观察方向反射到反射平面的另一侧，这种反射操作可以通过对投影矩阵进行修改来实现。

## 如果使用延迟渲染，一些透明材质的物体如何渲染？

### 方法一 （通用做法）

是在使用延迟着色渲染不透明表面之后，再使用前向着色来渲染透明物体。如果场景中存在大量光源，那么这些透明物体需要进行逐光源的着色计算，可以使用一些包含光源剔除方案的前向着色来渲染这些透明物体。

### 方法二（不常见）

- 可以在像素位置处，存储对应的透明表面列表，并使用一个纯延迟方法。好像是 [[A-Buffer]]

## 如果是一个室外光源很少的环境用延迟还是前向？如果是夜晚环境，有很多光源营造出五光十色的效果如何渲染，使用延迟还是前向？如果远景有很多个建筑层层叠叠的情况用前向or延迟？

- 室外光源很少的环境，最主要的光源就行太阳光，不需要进行光源剔除操作；同时，室外开阔环境的深度复杂度一般不太高，发生过度绘制的情况相对室内场景少一些，使用前向渲染即可。如果使用延迟渲染，可能会花费更多是时间。
- 对于夜晚大量光源的场景, 一般使用延迟渲染, 实现逐像素的光源计算
- 对于远景有很多个建筑层层叠叠的场景，深度复杂度较高，使用前向渲染可能会发生大量的过度绘制，因此一般使用延迟渲染。
    - 或者也可以保存为贴图?

## 开了depth only的forward着色和延迟着色效率上有什么区别？

depth only指的是执行一次prepass，其中只记录深度信息，用于后续的效果处理。
- 这里有两种可能，
    - 第一种是指类似Unity中的Depth only pass，但是这个pass只能生成一张rendertexture来用于实现画面效果，无法用于后续对片元进行剔除；
    - 第二种是指真正z-prepass，用于后续的片元剔除。第一种情况对性能没有帮助，反而会带来额外的开销；第二种情况可能会对性能有所帮助。
- 首先，这个z-prepass本身会带来一定的开销，
- 对于深度复杂度较高的场景而言，在前向渲染中使用一个z-prepass可以帮助减少一定的过度绘制。
- 如果网格是通过曲面细分、蒙皮或者其他相关过程形成的，那么添加这个pass所带来的成本可能会相当大，同时还需要对镂空纹理进行特殊处理。
    - 当顶点处理本身就**极其昂贵**（因为曲面细分、蒙皮动画等），将其成本翻倍所带来的巨大开销，会远远超过它所节省的像素着色开销。这时，Z-Prepass 的**成本 > 收益**，反而会导致性能下降。
- 一般来说，只会在这个初始pass中渲染那些体积较大（屏幕空间或者世界空间中）的遮挡物。
- 另一方面，即使使用了z-prepass，后续前向着色中，每个片元还是需要针对场景中的所有光源进行光照计算。因此总体上来说，执行z-prepass的前向着色，只能在一定程度上降低过度绘制问题。

## 被遮挡，没有光直接照射的地方计算直接光照时怎么减少这样的计算？（说了延时渲染，问了前向渲染怎么做？）

这个问题的实质是：场景中的某些光源，并不会对某些片元产生影响，在进行着色计算的适合，如何将这类光源剔除。这个问题问的并不是使用延迟渲染还是前向渲染，而是光源剔除策略。
又或者使用 Z-prepass 提前剔除
1. 分块渲染。分块着色的核心思想是，将光源分配到每个像素的tile上，在着色过程中中访问这些逐tile的光源列表。同时可以根据这个tile中的最大深度和最小深度来对光源进行剔除，即位于这个深度范围之外的光源作用体积会被丢弃。
2. 聚类渲染。将视锥体划分成一组三维单元格cluster，光源会按照与它们重叠的cluster来进行分类，并形成对应的光源列表。与分块着色的z-depth剔除方法不同，这种聚类着色的细分是在整个视锥体上进行的，独立于场景中的几何形状。由此产生的算法对于不同相机位置的性能波动较小，并且可以在tile中包含深度不连续性时表现更好。

## 延迟渲染的G-buffer中要存几张贴图 ？存储那些贴图？格式是什么？

- G-Buffer 中可以存储你任何想要存储的东西. 通常一个 G-Buffer 中会包含 3-5 哥 RT, 但是有些系统中,可以达到 8 个之多. 更多的 RT 带来更大的带宽压力
- 一般需要进行存储的内容包括：**深度**，**法线**，**金属度，粗糙度，**纹理颜色（albedo）**，光照强度，高光强度等。
- 一般的G-buffer是一张32bit的渲染目标，具体每个bit存储那些内容，需要依据实际情况而定。

## 延迟渲染存的位置信息精度问题，为何不直接用深度来还原世界空间的位置？**（存疑）**

想要获得世界空间的位置坐标，有两种方法，
- 第一种是直接将x,y,z坐标存储在G-buffer中；
- 第二种是使用深度信息和屏幕坐标来重建世界空间中的深度信息，由于深度信息从一开始的世界空间深度，被压缩到[0,1]范围内，然后再从到[0,1]范围将其还原，在这个过程中存在一定的精度损失。

## 延迟渲染存的法线在哪个空间？如何存储法线？

**一般存储在世界空间中**
法线存储方法：
- 直接存储法线的x,y,z数据。
- 只存储 x,y 数据,利用归一化特性重建 Z(对带宽有要求)
- 使用球坐标，存储两个角度参数，重建球面上的归一化法线。
- 八面体映射，将球面投影到一个八面体上，压缩效果好，编解码速度快。[[八面体映射]]
    - 它将单位球面投影到一个八面体上，然后像剥橘子皮一样将八面体展开成一个二维的正方形。
    - 好像是 [[Lumen]] 中的那啥压缩方式
- 球极投影（Stereographic Projection）.
    - 将球上的点从一个极点（例如北极）“投射”到一个与赤道相切的平面上。
- 使用球面贴图
    - 将法线半球（通常是朝向相机的半球）映射到一个圆内。
- Per-pixel View Space：view space中的法线z分量始终为正，可以节省一半精度。
    - 在**视图空间（View Space）**中，摄像机位于原点，朝向-Z轴。任何能被摄像机看到的物体表面，其法线向量的Z分量必然是**大于等于0**的
    - 对于**方法2（存储x,y, 重建z）**：既然 `Nz` 恒为正，我们就不再需要那额外的1个比特来存储符

## 延迟渲染怎么使用AO？

- 延迟渲染的G-buffer中一般包含了法线和深度信息，可以使用一些屏幕空间的AO方法，例如使用法线的 [[SSAO]]，[[HBAO]]，[[GTAO]] 等。

## 延迟渲染和前向渲染采样深度图的性能对比 ？

如果想要在片元着色过程中对深度图进行采样，
- 在延迟渲染中，在进行片元着色的时候，G-buffer会直接给出正确的深度信息。
- 而在前向渲染中，在进行片元着色的时候，此时可能还没有形成完整正确的深度信息，想要在前向渲染中采样深度图，需要提前进行一个z-prepass。

## 延迟渲染的时间复杂度？

在不进行光源剔除的情况下，问题规模为执行的片元着色次数。假设场景中的光源数量为m，屏幕分辨率为a×b（常数），其时间复杂度为 $O(m\times a\times b)$。

## 前向渲染的时间复杂度？

在不进行光源剔除的情况下，问题规模为执行的片元着色次数。假设场景中的光源数量为mmm个，一共会产生n个片元（变量），其时间复杂度为O(m×n)

## 延迟渲染为什么不能使用MSAA？

延迟着色也可以将每个像素位置上的NNN个样本都存储在G-buffer中，从而实现MSAA抗锯齿，但是由于内存成本、填充率和以及额外的计算开销等因素，使得这种方法过于昂贵，几乎难以实现。

延迟渲染的实现依赖于MRT，理论上MRT是可以和MSAA一起使用的，但是没有人会这么做，性能开销太大。

## Forward,Deffered,Tile-Based Deffered, Forward+,Cluster Forward渲染管线

渲染路径分为前向着色和延迟着色。

光源剔除方案分为分块着色（tiled shading）和聚类着色（clustered shading）。光源剔除方案可以分别应用于前向着色和延迟着色，即一共四种情况：

1. Tile-Based Forward Rendering：Forward+
2. Clustered-Based Forward Rendering
3. Tile-Based Deffered Rendering：TBDR
4. Clustered-Based Deffered Rendering

## Alpha blend的方向？和early-z等方法的冲突？

1，大部分透明度算法都需要将透明物体的颜色与其背后物体的颜色进行混合，为此需要使用alpha混合（alpha blending）的概念。为了使得一个物体看起来更加透明，我们需要将其alpha小于1的物体渲染在场景的最前面（即从前向后）。这里会使用一个over操作来实现，即将透明物体放置在现有场景前面。

2，alpha测试（alpha test）是指如果某个片元的alpha低于设定的阈值，就将这个片元抛弃，例如镂空（cutout）纹理，它会与early-z相冲突。
- 进入到片元着色器中的片元已经写入了深度, 如果使用 alpha 测试, 抛弃了某个片元, 那此时就需要恢复之前的状态, 这往往难以实现. 所以 vulkan 在检测到 discard 操作时, 会自动禁用 early-z

## TBDR的缺点?

1. 与桌面端的IMR相比，效率并不高。
2. 强烈依赖early-z，对透明效果的实现有一定限制。

## 在前向渲染管线中，如何获取屏幕法线数据？

1. 做一个prepass，用来存储normal数据
2. 使用z-buffer，根据深度梯度近似重建法线信息，但是这样做是不准确的。
    1. 在计算 AO 的时候可以这么做, 因为 AO 是比较低频的数据

## 在移动端TBR架构中，Vertex Shader和光栅化是怎样执行的？会执行多次吗？
