---
Type:
  - 面经
aliases: 
tags: 
modifiedDate: 2025/07/09, 14:26:34
---

# 杂项面经

## 有哪几种 Buffer 缓冲, 作用是什么?

- 缓冲区, Buffer, 即一块用于临时存储数据的内存区域. 通常指存储在 GPU 上的 Buffer, 我们在应用阶段填充 Buffer 中的数据, 并在 GPU 中使用. 
- 在 vulkan 中, 通常有这些 Buffer
    - 帧缓冲
        - 颜色缓冲
        - 深度和模板缓冲
    - 用于渲染的
        - Index Buffer
        - Vertex Buffer
    - 各种描述符
        - 纹理 image
        - structure buffer
    - 一些渲染技术
        - 延迟渲染与GBuffer
        - Visibility Buffer

## 一个gameobject必备的组件有哪些？transform除了空间属性以外还有什么意义？

- unity 中的 GameObject 只有 transform 组件必须, 其它都可以按需添加或者移除
- transform 组件控制了物体的空间数学, 即位置, 缩放和旋转. 还有父子层级. 可以用来检索物体

## prefab和单纯的gameobject有什么区别？

prefab 是一个可重用的 GameObject 的模板定义, 单纯的 GameObject 可以用 Prefab 实例化出来. 实例化出来的 GameObject 可以跟随 Prefab 变化或独立

## 纹理填充率和像素填充率？

- 纹理填充率（texture fill rate）
    - 指 GPU 在单位时间内可以处理的纹素数量, 单位是十亿纹素每秒 (GTexel/s), 计算方式为$$纹理填充率=核心频率*纹理单元数量/1000$$
- 像素填充率（pixel fill rate）
    - 指 GPU 单位时间内可以渲染的像素数量, 单位是 十亿像素每秒 (GPixels/s), 计算方式为

      $$像素填充率=核心频率*光栅单元数量/1000$$

## unity的几种管线？有什么区别？

Untiy 目前有三种管线, 分别是 Bulit-in 内置管线, URP 通用渲染管线以及 HDRP 高清渲染管线. 以及可以自定义的 SRP 管线
- Built-in 管线的可定制性较差, 目前不推荐新项目使用. 
- [[可编程渲染管线]] 提供了一套引擎级别的渲染框架, Unity 官方使用 SRP 实现了两套管线, 分别是 URP 和 HDRP. URP 针对移动平台, 使用广泛, HDRP 针对高性能平台, 未来可期. 
- 可以使用 SRP 实现满足自己需求的管线

## 花屏、撕裂、黑屏等故障检测？

- 花屏：大部分花屏问题都是由显卡引起的，一般有以下情况：
    1. 爆显存
    2. 显存虚焊或者损坏
    3. 显卡核心虚焊或者损坏
    4. 驱动故障
    5. 显卡供电不足（金手指氧化等）
    6. 显卡温度过高（散热不好）
    7. 显示器本身坏了
- 黑屏
    - 除了显卡本身硬件故障之外（和上面的花屏类似），还有一种常见的驱动故障，即掉驱动（即丢失驱动文件），需要自行进行更新。
- 撕裂
    - 画面撕裂的原因一般是帧率（显卡生成画面的速度）与显示器刷新率不匹配。解决这个问题是方法是打开[[垂直同步]]，常用的垂直同步技术有G-SYNC（Nvidia）和Free-Sync（AMD）。

## 提高渲染效率的方法？

- 优化的第一步是定位性能瓶颈, 详见[[性能优化面经#如何测试渲染流程中的瓶颈？如果游戏性能出现问题，怎么考虑问题？]]
- 可以使用一系列辅助工具, 以及一系列测试方法. 在确定了性能瓶颈的为欸之后, 再进行针对性的优化

## 如何保证稳定帧率？

- 帧率稳定是指, 在游戏过程中, 无论是否随着视角变换和游戏画面内容的变换, 使得每帧的渲染时间保持稳定
- 更进一步的也可以说提高 1%low 帧
1. 使用视角稳定的渲染算法，要求算法具有稳定的时间开销。
2. 使用剔除技术，视角变化会带来画面深度复杂度的变化，避免这种变化对渲染时间产生剧烈影响。
3. 优化场景设计。
4. 避免在一帧中继续密集计算，可以将计算任务分配到多帧中进行。

## 了解哪些GPU架构？

- 现代GPU都使用了统一着色器架构，即使用统一的 [[ALU]] 来实现不同的着色器功能。
- Nvidia GTX RTX 系列显卡, 每代架构都有所不同, 目前最新的 RTX50 系使用了 BlackWell 架构, 专注于机制的 AI 性能和能效比. 上一代 40 系使用 AdaLoveLace. 
- AMD Radeon 系列显卡, 目前最新的 RX90 系列使用了 RDNA4 架构, 和 Nvidia 相同, 加入了对 AI 的支持
- 移动端GPU的渲染架构一般使用了 [[TBDR]]。主流的硬件架构有：Adreno，PowerVR，Mali等。

## 移动端、PC 端 GPU 在显存、架构上有何不同？为什么移动端采用这种解决方案？

- PC端使用IMR 或 Deffered 渲染架构，CPU 和 GPU 是独立的，会使用独立的存储空间，即内存和显存；
    - GPU 的专门显存速度极快, 带宽极高, 但相应的**成本高**且**功耗巨大**, 以及存在**一定延迟**
- 移动端一般使用TBR（TBDR）渲染架构，移动端芯片一般是 SOC，会将 CPU 和 GPU 封装在一起，并使用统一内存架构。
    - 高效率**低功耗**
    - **小体积**, 低成本. 从而**内存带宽小**
- 主要原因是移动端设备必须在**“功耗、散热、成本”**这个“铁三角”的严格限制下生存。
    - **功耗限制：** 手机靠电池供电，整机功耗预算只有区区几瓦，而访问内存是芯片上最耗电的操作之一。
    - **散热限制：** 手机没有风扇，只能被动散热。高功耗带来的高热量会迅速导致芯片降频，性能崩溃。
    - **成本与空间限制：** 独立的GPU和显存方案对于手机来说过于昂贵和庞大。
- 游戏主机的芯片与移动端芯片类似，使用共享内存架构。

> 因为**功耗、散热和体积**的严格限制，移动端**必须**采用**SoC和统一内存架构**。又因为统一内存架构导致**内存带宽成为巨大瓶颈**，所以移动端**必须**采用**TBR渲染架构**来克服这一瓶颈，实现极致的能效比。

## 了解哪些图形 API? 他们之间的区别是什么

目前主流的图形 API 有 DX11, opengl, OpenGLES, WEBGL
以及
DX12, vulkan, metal
区别见[[图形API对比]]

## DLSS有了解吗？

[[DLSS]]
DLSS现在是一套技术的统称，其中包含深度学习超采样（DLSS），深度学习抗锯齿（DLAA）。DLSS 3.0中引入了帧生成（Frame Generation），即补帧。DLSS 3.5中引入了光线重建（Ray Reconstruction），即基于AI的光线追踪降噪器。
DLSS4 中使用了视觉 Transformer, 引入了多帧生成

## 顶点属性太多，槽位不够怎么办？

使用一个较大的 Structure 缓冲区, 其中包含顶点属性的结构体, 并使用索引来访问结构体中的顶点属性. 

## 模型面数太多, 怎么优化?

1. 让美术修改模型, 进行拓补和降面处理, 或者制作 LOD
2. 使用一些算法生成 LOD
3. 使用 VertexBuffer
4. 考虑使用 [[Nanite]] 中的自动细分
5. 对于某些特殊模型（地形），使用自适应曲线细分来程序化生成网格。

## 有详细了解原神的各个渲染 Pass 吗？

- **阴影**: 8 级 CSM, 其中前 4 级 CSM 每帧更新, 后 4 级 CSM 轮流更新. (每帧更新 5 级 CSM, 每 8 帧能更新完所有层级)
- **AO**: 
    - HBAO
    -  AO Volume:** 对于场景中不会移动的静态物体，可以在游戏开发阶段就**预先计算**好它们之间的遮蔽关系，并将结果存储在一种“体积纹理”中。
    - **Capsule AO:** 对于角色这样的动态物体，用其高精度模型来实时计算AO过于昂贵。因此，用几个简单的**“胶囊体（Capsule）”**来近似模拟角色的身体和四肢，然后用这些胶囊体来计算遮挡。
- **光照**：[[ClusterBasedLighting]]，划分方式为$64 \times 64 \times 16$，最多支持1024个光源。
- 体积光 与光源划分对齐, 使用 Ray Marching
- IBL 反射探针 (CubeMap), 探针
- 镜面反射 SSR, 探针

## 知道 Single Pass 吗？

> 针对 VR 等设备

单pass**立体**渲染（Single Pass Stereo Rendering）, 是相对两 Pass 而言的. 即使用单个 Pass 来完成双眼画面的渲染, 共享剔除和阴影计算等任务, 有效减少状态切换带来的开销
关键技术为
- **实例化（Instancing）**
- **多视图渲染（Multiview Rendering）** 不同于 [[MRT]]
    - MRT 为一次输入，多种不同类型的输出, depth, color 等
    - Multiview 为一次指令，多个**不同视角**的输出。或者说**多个相机**

## 说一说 GPU Driven 能实现哪些功能？具体怎么实现的？

[[GPU Driven Pipeline]] 核心思想是把 CPU 上的工作转移到 GPU 上, 减少两者之间的通信开销, 从而解决 DrawCall 瓶颈等
主要有两方面的作用
- 剔除
    - 在 GPU 上进行 Cluster 和 Triangle 级别的剔除, 如背面剔除, 如 **Nanite** 在运行时使用 computeshader 进行 cluster 剔除和 LoD 选择
- 提交
    - 提交是指在GPU 中发起draw call，其中包含相同shader类型下的贴图合并，例如虚拟纹理技术。

## 了解游戏中的贴花是如何实现的？

贴画的实现主要有一下几种方法
- **基于面片**: 在表面位置渲染一个应用贴花纹理的四边形面片
- **基于纹理**: 在应用贴花的部分, 将原始纹理与贴花混合
- **基于 SubMesh** : 复制场景物体的表面，根据贴花范围裁剪出一块新的、独立的、与原表面几乎重合的“贴皮”网格，然后给这个新网格赋予贴花材质。
- 投影贴花 (Projective Decals)
    - 在延迟渲染中, 一个额外 pass 渲染贴画
    - 贴花由立方体表示影响范围, 对于盒子覆盖到的每一个屏幕像素, 读取 G-buffer 获得表面点世界坐标
    - 根据表面点坐标获取其相对贴花的坐标, 并以此为 uv, 采样贴画纹理并覆盖 G-Buffer

## 如何提高实时渲染的质量？

- 从根本上, 高质量的美术资产, 模型, 材质, 纹理
- 高质量的阴影和全局光照算法
- 后处理, Color Grading

## 游戏中如何实现点选物体的功能？

1. 从相机处向鼠标点击的屏幕像素位置发射一条光线, 与场景物体进行相交测试. 注意加速算法.
2. 也可以为每个模型保存一个 ID, 额外使用一张贴图保存可见物体的 ID. 从而可以直接选择到对应物体. 思想类似 [[Visibility Buffer]]

## 是否了解骨骼动画的实现?

骨骼动画, 其技术原理叫[[顶点混合]]或者说是线性蒙皮混合. 
大意为使用一组骨骼来控制蒙皮顶点, 每个骨骼对于不同顶点有不同的权重, 其方程如下所示:

$$
\mathbf{u}(t)= \sum_{i=0}^{n-1} w_{i} \mathbf{B}_{i}(t) \mathbf{M}_{i}^{-1} \mathbf{p},\quad where \quad \sum_{i=0}^{n-1} w_{i}=1, \quad w_{i} \geq 0
$$

上述方程的含义是：有n个骨骼会对点 $\mathbf{p}$ 的世界空间坐标产生影响；$w_i$ 的值代表了骨骼i对于顶点 $\mathbf{p}$ 坐标的影响权重；矩阵 $\mathbf{M}_{i}$ 代表骨骼 i 的模型变换矩阵，它负责将骨骼变换到世界空间中。$\mathbf{B}_{i}(t)$ 是一个世界变换矩阵，代表了第i个骨骼的世界变换，它随着时间的变化可以让物体动起来；它通常是若干个矩阵连接而成。
最后得到的 $u(t)$ 即为变换后的世界空间坐标.

## 角色压到草之后, 草弯曲是如何实现的?

主流方法是基于顶点着色器, 可分为两个主要步骤

### 1. 传递交互信息

引擎需要知道**是谁**以及**在哪里**压草, 需要从 CPU 上传递到 GPU 上的顶点着色器. 通常有两种做法.

#### 直接传递坐标

将角色及其它可交互物体的坐标直接作为 const 发送给各种接收源, 这里是 草.
这种方法相对简单, **但是如果有大量交互源, 遍历所有交互源十分耗时.**

#### 使用交互贴图

渲染一张 RT. 在这张 RT 上记录角色或其它任何交互源的位置. 
这张“交互贴图”就像一张 **“压力图”**，记录了哪里正在对草地施加影响。
- 无论有多少个交互源，着色器最终只需要采样一张贴图即可获得所有交互信息。它天然地支持多个物体同时与草地互动。

>  可以尝试记录角色移动的淡出轨迹, 这样草的变形更为真实?

### 2. 在顶点着色器中计算形变

- 获得上一步得到的交互源信息.
- 根据距离, 计算弯曲幅度. 方向.
- 通常只有上半部分弯曲.
- 将计算出的位移量应用到原始的顶点坐标上，得到一个新的坐标。

## 离角色很近的地方的树叶是如何渲染保持性能的？植被渲染的优化方法？

1. 对于植被的渲染, 我们可以采用 LoD 方法, 以及对于远处的物体, 可以使用广告牌替代
    1. 近处的物体, 使用面片显得太过于虚假. 需要使用精细的 3D 模型
2. 对树木范围, 进行**分块划分**存储渲染, 使用**流式**管理这些数据对象的加载和卸载。
3. 使用 compute shader 进行裁剪, 以及使用一些其它的剔除方法

## 大世界渲染的场景管理方法？

- 对地形网格使用[[自适应曲面细分]], 或者使用几何 ClipMap
- 对地形网格分区存储, 并分区加载
- 使用 [[虚拟纹理|Virtual Texture]] 和[[流式加载]]

## 介绍一下建模整体流程？

### 1. 设计

各种原画, 概念稿等

### 2. 模型创建

1. 使用基本几何体搭建模型大致轮廓
2. 高精度雕刻
3. 模型拓补, 重新“搭建”一个全新的、结构优化的、面数极低的**低精度模型**。
4. 展开 UV. 将三维模型的表面，像剥橘子皮或制作地球仪展开图一样，平铺到一个二维平面上。

### 3. 烘焙与纹理绘制

1. 贴图烘焙
    1. 将**高精度模型**上的海量细节，以特殊贴图的形式“烘焙”或“转移”到**低精度模型**上。
    2. 这样低精度模型也能拥有高精度模型的着色效果
2. 纹理绘制
    - 在专业的PBR 软件中, 如Substance 3D Painter 中, 绘制纹理贴图

### 4. 蒙皮动画制作 (角色)

角色还有一些服饰等元素, 需要在专门软件中制作, 如 md, cc 等? #没看懂 

## z-fighting怎么处理？ 动近平面和远平面哪一个比较好？

[[Z-Fighting]] 指两个三角形由于过于接近或重合, 又因为深度缓冲的精度不够, 导致在视角变换时甚至不动是, 两个三角形轮流相互覆盖, 导致出现闪烁现象. 通常有如下几种处理方法
- 由于投影变换导致 z 是非线性的, 绝大数物体共享接近 1 的深度值
- 使用反向 zbuffer, 浮点数在 0 处的精度高, 1 处的精度低
- 尽可能推远近裁剪平面, 让远裁剪尽可能近, 即减少需要表示的深度范围
- 视锥体深度划分, 将大的视锥体在深度方向上划分为若干个不重叠的小视锥体, 这些小视锥体结合在一起就是大视锥体. 
- 对数 Z-buffer, 可以通过 Log 函数的曲线理解. 目前常用的为反向 z
  ![[assets/对数曲线图-1.png|300]]
    - 它利用了对数函数 `log(x)` 的一个特性：当 `x` 很大时，`log(x)` 的增长会变得非常缓慢。
    - 原来线性的情况下, 0.9 到 1 的深度只占据 10%的深度范围.
    - 在对数 z 的情况下, 原始 0.9 到 1 的深度占据了 40% [^1]$的深度范围, 大大提高可用精度
- 手动分离这些过于接近的表面

## AO 的效果

[[AO]]
AO 指着色点半球反向内的某些方向, 可能会被自身物体的其它部分或者场景中的其它物体遮挡, 导致亮度变暗。是反应空间几何关系的一种效果，可以帮助产生深度暗示。
方法主要有
- 物体空间内的 AO. 
    - 圆盘法
    - 近似法
    - 基于符号距离场的方法+ConeTracing
- 屏幕空间方法
    - SSAO
    - HBAO
    - GTAO

## 垂直同步的原理

[[垂直同步]]旨在解决画面撕裂问题, 而画面撕裂源于渲染帧率和显示器刷新率不匹配. 一般来说是游戏渲染速度过快导致的. 可以使用一些方法, 让 GPU 进行强制等待.  或者让显示器进行等待
- [[V-Sync]] 垂直同步
    - 使用双缓冲或三缓冲
    - 对于双缓冲, 显示器使用一个, GPU 使用另一个. 当缓冲满时, GPU 必须等待.
- [[G-Sync]] 和 [[FreeSync]]
    - 让显示器等待 GPU, 显示器只有在接收到 GPU 渲染完成新的一帧时, 才会进行刷新. 否则复用上一帧画面

## 如何从深度图中还原法线？

- 可以认为深度图为表面的高度图. 通过对某个纹素计算其水平和垂直梯度, 可以得到表面的两条切线. 两条切线进行叉乘, 即可对表面法线近似还原. 
- 但这个法线不一定是正确的. 因为深度图中两个相邻纹素可能来自不同表面. 
- 再者, 这只能还原出低频的几何法线, 和法线贴图是不能比的, 所以一般用于 AO 等低频效果. 

## 如何在一个圆内均匀采样?

- 使用[[Blue Noise|蓝噪声]], 准随机, 但是更均匀.
- 拒绝采样, 在正方形内生成随机点.  根据距离判断是否园内
- 反演变换法. **不要**直接随机化半径和角度, 这会导致聚集在中心. 因为**面积不是均匀**的
    - 两个 0-1 随机数, 一个映射为角度, 另一个开平方根作为半径
    - ***取平方根的操作，正好抵消了面积与半径的平方关系***
- 同心圆映射法
    - 使用随机数生成器生成[0,1]范围内的均匀方形采样，再使用下面函数转换为均匀圆盘采样。

      ```cpp
      float2 ToUnitDisk( float2 unitSquare )
      {
        float2 p = 2 * unitSquare  - 1;
        float radius;
        float phi;
        if( abs( p.x ) > abs( p.y ) )
        {
          radius = p.x;
          phi = (PI/4) * (p.y / p.x);
        }
        else
        {
          radius = p.y;
          phi = (PI/2) - (PI/4) * (p.x / p.y);
        }
        return float2( radius * cos( phi ), radius * sin( phi ) );
      }
      ```

[^1]: $\ln(1.9) = 0.64$
