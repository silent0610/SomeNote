---
Type:
  - Paper
aliases: 
Status: 
tags: 
modifiedDate: 星期一, 五月 26日 2025, 8:40:36 晚上
PaperType:
  - Review
---

## 摘要

随着深度学习技术的不断发展，注意力机制已经成为提升模型性能的重要手段，特别是在自然语言处理和计算机视觉领域。传统的自注意力机制（Self-Attention）虽在多种任务中取得显著成果，但其计算复杂度为 $O(n^2)$，在处理长序列时存在较大的计算与内存开销。为了解决这一问题，线性注意力机制应运而生，通过优化计算复杂度和内存消耗，将注意力计算的时间复杂度降低至 $O(n)$，显著提高了处理长序列任务时的效率。本文首先回顾了注意力机制的基本概念及其局限性，并详细介绍了线性注意力机制的提出及其优势，如时间复杂度的降低、内存消耗的减少和可扩展性的提高。同时，本文还探讨了线性注意力的局限性，如表达能力和聚焦能力的不足，并提出了相应的改进方法。最后，本文总结了当前线性注意力机制的主要发展方向，涵盖门控机制、状态空间模型、核函数和硬件高效等方面，展望了未来在长序列数据处理和大规模数据集应用中的潜力。总体而言，线性注意力机制在提升计算效率和模型扩展性方面具有重要的应用前景。

## 背景（注意力机制介绍）

### 传统注意力机制基本概念

注意力机制最初在 2014 年由Bahdanau 等人[]引入到序列到序列（Seq2Seq）模型中，用于改善机器翻译任务。随后，Vaswani 等人在 2017 年提出了完全依赖于注意力机制的Transformer 模型[]，该模型在处理序列数据时不依赖于传统的循环神经网络结构，而是通过自注意力（Self-Attention）机制捕捉序列内部的依赖关系。

注意力机制允许模型动态地对输入数据的不同部分分配不同的处理权重。这种机制可以提高模型处理复杂数据的能力，因为它能够识别并集中资源处理那些对当前任务最重要的信息。注意力机制提高了模型对重要特征的识别能力，从而提升了模型的性能。

注意力机制被广泛应用于自然语言处理（NLP）中，显著提升了机器翻译、文本分类、问答系统中的性能。KAM-BERT模型，通过将知识生成的注意力图直接整合到自注意力机制中，以提高预训练语言模型的性能。Bai 等人，提出了一种基于多级自注意力网络和门控脉冲神经 P 系统的序列推荐方法，旨在解决序列推荐的长期依赖问题，并充分利用上下文信息预测和生成用户行为序列。Sible 两人在文章中探讨了如何通过字典和注意力掩码来改进罕见词的翻译，利用自注意力机制提高翻译模型的性能。同样的，在计算机视觉领域，注意力机制被广泛应用于图像分类、目标检测、图像分割等任务。Chang 等人提出了一个基于注意力机制的图像生成模型，通过使用掩码技术来生成图像，展示了注意力机制在图像生成任务中的应用。CA-Stream是一种基于注意力的池化方法，用于提高图像识别的可解释性。该方法通过关注图像中的关键区域来提高模型的性能和解释能力。Guo 等人提出了一种新的视觉注意力网络，通过模拟人类视觉注意力机制来增强卷积神经网络在图像识别任务中的表现。总而言之，注意力机制已经成为深度学习中不可或缺的一部分，展现出巨大的潜力和价值。

### 传统注意力机制局限性

即使自注意力机制被如此广泛的应用，甚至成为了深度学习的基建之一，其仍有几个悬而未决的问题。例如在计算注意力权重时，它需要对输入序列中的每个元素与其他所有元素进行比较，以确定它们之间的关联程度。这种全局的、无差别的比较可能会导致模型可能会将注意力分配到不相关或次要的特征上，进而导致模型训练效率下降或预测精度降低。此外，尽管注意力权重提供了一定的解释，但模型的内部工作机制仍可能难以理解。而最为突出的问题是**长序列处理困难**。由于自注意力的二次方复杂度，处理长序列数据时会面临巨大的计算和存储压力，效率低下。这限制了自注意力机制在处理长文本或视频序列等任务中的应用。
众所周知，尽管基于Attention机制的Transformer类模型有着良好的并行性能，但它的空间和时间复杂度都是O(n2)O(n2)级别的，nn是序列长度，所以当nn比较大时Transformer模型的计算量难以承受。

我们注意到 Attention 的本质是计算序列中每个位置之间的相似性，用以生成注意力权重矩阵。如果输入序列长度为 n，则需要计算 nxn 的相似性矩阵，所以其计算复杂度为 $O (n^2)$。
我们可以从网络结构层面了解为什么其复杂度是 n2，如图所示
![attention结构介绍](assets/Pasted%20image%2020241220101417.png#centre)
Attention 可以用如下形式表示

$$
Attention(Q,K,V)=softmax(QK^⊤)V
$$

这里的 $Q∈R^{n×dk},K∈R^{m×dk},V∈R^{m×dv}$，简单起见我们就没显式地写出 Attention 的缩放因子了。本文我们主要关心 Self Attention 场景，所以为了介绍上的方便统一设 $Q,K,V∈R^{n×d}$，一般场景下都有 n>d 甚至 n≫d（BERT base 里边 d=64）。

事实上，我们可以很容易的得出结论，制约 Attention 性能的关键因素，其实是定义里边的 Softmax。$QK^T$ 这一步我们得到一个 n×n 的矩阵。而当用于归一化的 softmax 函数的输入是一个 nxn 矩阵时，其时间复杂度为 O（n^2）。就是这一步决定了 Attention 的复杂度是 O (n2)；如果没有 Softmax，那么就是三个矩阵连乘 $QK^TV$，而矩阵乘法是满足结合率的，所以我们可以先算 $K^TV$，得到一个 d×d 的矩阵，然后再用 Q 左乘它，由于 d≪n，所以这样算大致的复杂度只是 O (n)。
也就是说，去掉 Softmax 的 Attention 的复杂度可以降到最理想的线性级别 O (n)。
 
这就是所有对线性注意力机制的研究在思考的问题，即如何改变自注意力的计算方式和顺序，以及可能地引入其他激活函数或机制，以降低时间复杂度，同时不降低多少性能。

### 线性注意力的提出

Katharopoulos 等人提出了基于核特征映射的线性注意力，在他们的研究中，他们提出了一种新的 Transformer模型，该模型通过将自注意力（self-attention）表达为核特征映射的线性点积，利用矩阵乘法的结合性质将复杂度从O(N^2)降低到O(N)，其中N是序列长度。这种方法显著加快了自回归Transformer的速度，并揭示了它们与递归神经网络（RNNs）的关系。他们提出的线性Transformer在自回归预测非常长序列时，速度比传统的Transformer快达4000倍。
当然，也有其它的对注意力进行改进的努力，本文将会在后文进行介绍。

## 详述线性注意力

### 概述

与传统的自注意力方法相比，线性注意力通过优化计算复杂度，尤其是在处理长序列时，显著提高了效率。核心思想是将原始的注意力计算（基于矩阵乘法）通过某些近似或分解方法转化为线性计算，使得计算复杂度从 O (N²) 降到 O (N)。常见的线性注意力方法包括上文提到的**核方法**，**低秩近似**，**改变 softmax 的使用方式**等。

### 优缺点

所以，我们可以总结出线性注意力的优点
1. 时间复杂度降低 其有效将时间复杂度从 n2 降低到 n 
2. **内存消耗降低** 同时传统的自注意力需要存储一个**N×N**的矩阵来计算注意力权重随着 N 的增加，内存消耗急剧增加。线性注意力通过减少矩阵存储需求，降低了内存消耗。
3. **可扩展性强** 结合上面两个优点，由于复杂度和内存需求都与序列长度成线性关系，线性注意力可以很好地扩展到大规模数据集，尤其适用于长序列数据和大规模模型。

然而，线性复杂度的这种简化必然带来某种程度的性能损失，比如
1. **表达能力有限**：线性注意力由于其简化的计算方式，可能无法像传统的基于softmax的注意力机制那样有效地捕捉长距离依赖关系和复杂的上下文信息。这导致线性注意力在某些任务上的性能可能不如标准注意力机制。
2. 聚焦能力不足以前的线性注意力模块中注意力权重的分布相对平滑，缺乏处理最具信息的特征的能力。（Focused Linear Attention）

## 应用领域

线性注意力因其优越性，被广泛应用于 CV 和 NLP 领域中。例如FLatten Transformer:使用聚焦线性注意力机制构建的视觉Transformer。在多个视觉任务上取得了优异的性能。
Agent Attention: On the Integration of Softmax and Linear Attention 提出了一种新型的代理注意力（Agent Attention），通过引入代理tokens来聚合全局语义信息，从而将传统的二次复杂度降低为线性复杂度。
Mobile Attention为移动设备设计的首个基于核的线性注意力机制。它通过减少头维度来降低计算复杂度，使其更适合移动设备使用。
EfficientViT，采用了创新的 **多尺度线性注意力**，显著减少了计算开销，能够在多种硬件平台上实现快速部署。
 [Agostinelli](https://arxiv.org/search/cs?searchtype=author&query=Agostinelli,+V), 等人提出了模块化线性注意力，使得注意力机制可以在不同的子任务上根据需要进行调整。在多种 NLP 任务上得到了性能提升。
 SLAB结合了简化的线性注意力和渐进式重新参数化的批量归一化，从而在保证模型性能的同时大幅提高了其效率，尤其是在资源受限的环境下。
LinRec为基于Transformer的顺序推荐系统（LinRec）提出了一种新的L2归一化线性注意力，该系统在理论上提高了效率，同时保留了传统点积注意力的学习能力。
Based通过设计简单且高效的注意力机制来平衡模型的召回能力和推理吞吐量，以便更好地适应资源受限的硬件环境（如移动设备）以及在大规模数据上的应用。

## 研究方向

本节概述了高效 Transformer 模型的一般分类，按其核心技术和主要应用场景进行划分。尽管大多数模型的主要目标是通过优化自注意力机制的内存复杂度来提高效率，但我们也包括了一些旨在提高 Transformer 架构总体效率的方法。

### 进展

我们可以系统的梳理线性注意力机制的演变过程，解释传统自注意力机制和 RNN、LSTM 的关系，再到如何形成 Retentive、GLA 等线性注意力的改进版，最后再到 Mamba、Mamba-2、RWKV 等方法

线性注意力每一次计算出的中间结果保存在历史中间矩阵，这个中间矩阵，我们可以称之为 State Space Model ，也就是可以理解为是一种中间状态模型。通过更新状态空间（SSM）来维护信息流，而不像传统注意力那样直接计算每个 token 之间的关系。因此，线性注意力能够保持较低的计算成本，但同时也牺牲了信息的精确捕捉，特别是无法有效地突出当前时刻与历史时刻之间的关键依赖关系。

线性注意力与 **RNN** 中的 hidden state 以及 **LSTM** 中的 cell state 相似，这表明线性注意力机制可以通过递归结构逐步增强对历史信息的依赖。然而，单纯的线性注意力依然存在无法灵活控制历史信息保留的不足，这促使了进一步改进。

**Retentive Network** 和 **GLA（Gated Linear Attention）** 就是两种改进方法。Retentive Network 通过引入控制历史信息保留的机制，允许模型有选择性地记住或遗忘信息。而 GLA 则通过门控机制，使得线性注意力能够像 **LSTM** 一样有效地控制信息流动和记忆，从而更好地捕捉长程依赖。

 **Mamba** 和 **Mamba-2** 模型它们通过引入 **SSM** 和 **HiPPO** 结构来优化传统注意力计算。Mamba 模型通过结合递归结构与状态空间模型，解决了传统注意力在长序列处理中的计算瓶颈，而 Mamba-2 则进一步改进了训练效率和性能，引入了 **State Space Attention (SSA)** 和 **State Space Duality (SSD)**，优化了注意力计算的并行化和长程依赖建模能力。

最后， **RWKV** 模型，它通过递归的 **时间混合（time mixing）** 技术，将传统 Transformer 的注意力机制替换为递归计算，不仅提高了计算效率，还支持了长程记忆。RWKV 通过递归结构优化了注意力机制的计算，标志着线性注意力进一步向简洁高效的递归模型演进。

### 改进 Transformer

当然，改进transformer 不只有上述的一条路，谷歌研究员在[一篇综述](https://papers.cool/arxiv/2009.06732))中进行了详细介绍，本文在这里对其内容进行再次总结。

#### • 固定模式（FP）

最早对自注意力的修改是通过限制视野范围，采用固定的预定义模式（如局部窗口和块模式），来稀疏化注意力矩阵。

- **块模式**：这种技术的简单实现方式是块状（或分块）范式，它通过将输入序列分割成固定的块来考虑局部感受野。例如，Blockwise（Qiu 等人，2019）和/或 Local Attention（Parmar 等人，2018）模型通过将输入序列分割成块来减少复杂度，将复杂度从 O(N2)降低到 O(B2)O(B^2)O(B2)（其中 B 是块大小，且 B≪NB \ll NB≪N），从而显著减少了计算成本。这种分块或分块方法成为许多更复杂模型的基础。
- **步长模式**：另一种方法是采用步长注意力模式，即仅在固定间隔内进行注意力计算。模型如 Sparse Transformer（Child 等人，2019）和/或 Longformer（Beltagy 等人，2020）采用了步长或“膨胀”窗口。
- **压缩模式**：另一种方法是使用某种池化操作来下采样序列长度，从而形成一种固定模式。例如，Compressed Attention（Liu 等人，2018）使用步长卷积有效地减少序列长度。

#### • 模式组合（CP）

组合方法的关键思想是通过结合两种或更多不同的访问模式来提高覆盖范围。例如，Sparse Transformer（Child 等人，2019）通过将一半的注意力头分配给步长模式，另一半分配给局部注意力模式，从而结合了步长和局部注意力模式。类似地，Axial Transformer（Ho 等人，2019）通过对输入张量的单一轴执行一系列自注意力计算来应用模式组合。本质上，模式组合通过聚合和组合多个模式来减少内存复杂度，同时提高自注意力机制的整体覆盖范围。

#### • 可学习模式（LP）

可学习模式是对固定、预定模式的一种扩展。显然，使用可学习模式的模型旨在以数据驱动的方式学习访问模式。学习模式的一个关键特点是确定令牌的相关性，然后将令牌分配到桶或簇中（Vyas 等人，2020；Wang 等人，2020b）。值得注意的是，Reformer（Kitaev 等人，2020）引入了一种基于哈希的相似度度量来有效地将令牌聚类成块。类似地，Routing Transformer（Roy 等人，2020）使用在线 k-means 聚类对令牌进行聚类。与此同时，Sinkhorn Sorting Network（Tay 等人，2020b）通过学习对输入序列块进行排序，揭示了注意力权重中的稀疏性。在所有这些模型中，相似度函数与网络的其他部分端到端联合训练。学习模式的关键思想仍然是利用固定模式（如分块模式），但这种方法通过学习排序/聚类输入令牌，从而在保持固定模式效率的同时，使模型能够更优化地全局查看序列。

#### • 神经记忆（Neural Memory）

另一个显著的方法是利用可学习的侧向记忆模块，可以一次访问多个令牌。常见的形式是全局神经记忆，这能够访问整个序列。全局令牌作为一种模型记忆，学习从输入序列中聚集信息。这一概念最早是在 Set Transformers（Lee 等人，2019）中提出的诱导点方法。这些参数通常被解释为“记忆”，并作为未来处理的临时上下文。全局记忆令牌也被用于 ETC（Ainslie 等人，2020）和 Longformer（Beltagy 等人，2020）。通过有限的神经记忆（或诱导点），我们能够对输入序列执行类似池化的操作来压缩输入序列——这一巧妙的技巧在设计高效自注意力模块时十分有用。

#### • 低秩方法（Low-Rank Methods）

另一种新兴的技术是通过利用自注意力矩阵的低秩近似来提高效率。核心思想是假设 N×NN \times NN×N 矩阵具有低秩结构。Linformer（Wang 等人，2020c）就是这一技术的经典示例，它将键和值的长度维度投影到一个较低维度的表示（N→kN \to kN→k）。显然，低秩方法缓解了自注意力内存复杂度的问题，因为 N×NN \times NN×N 矩阵现在被分解为 N×kN \times kN×k。

#### • 核方法（Kernels）

另一种之前流行的提高 Transformer 效率的方法是通过核化（kernelization）来看待注意力机制。使用核方法（Katharopoulos 等人，2020；Choromanski 等人，2020a）能够通过巧妙的数学重写避免显式计算 N×NN \times NN×N 矩阵。由于核方法是对注意力矩阵的近似，因此它们也可以被视为低秩方法的一种。最近在这一领域的工作包括 Performer、Linear Transformers 和 Random Feature Attention（RFA，Peng 等人，2021）。

#### • 循环（Recurrence）

块方法的自然扩展是通过递归连接这些块。Transformer-XL（Dai 等人，2019）提出了一种段级别的递归机制，连接多个段和块。这些模型在某种意义上可以视为固定模式模型。然而，由于其与其他块/局部方法的偏差，我们将其单独归为一个类别。

#### • 下采样（Downsampling）

另一种常见的减少计算成本的方法是通过减少序列的分辨率，从而按相应的因子减少计算成本。这类模型的示例包括 Perceiver（Jaegle 等人，2021）、Funnel Transformers（Dai 等人，2020）、Swin Transformer（Liu 等人，2021b）和 Charformer（Tay 等人，2021c）等。值得注意的是，这类模型可能与使用记忆令牌的模型有些重叠，因为像 Set Transformer 这样的模型也可以视为一种下采样方法，尽管是在注意力机制内部。最近的 Nyströmformer（Xiong 等人，2021b）表面上看似低秩或基于核的方法，但实际上它是一种下采样方法，其中“地标”仅仅是基于步长的池化——与 Set Transformer、Funnel Transformer 或 Perceiver 类似。

#### • 稀疏模型与条件计算（Sparse Models and Conditional Computation）

尽管这些模型并不专门针对注意力模块，但稀疏模型通过稀疏激活一部分参数，通常可以提高参数与 FLOPs 比率。该类模型的示例包括 Switch Transformers（Fedus 等人，2021）、ST-MoE（Zoph 等人，2022）、GShard（Lepikhin 等人，2020）、Product-Key Memory Layers（Lample 等人，2019）。在我们研究的模型中，稀疏模型通常是在自适应基础上运行，其中稀疏性通常是通过类似专家混合的机制学习的。在这个背景下，我们还可以将注意力权重的稀疏化视为这一范式的一部分。因此，我们认为，稀疏高效模型的出现应该为高效 Transformer 分类创造一个新的类别。

## 未来研究方向

计算机水平的不断发展、计算效率的提升以及对大规模数据处理需求的不断增加，给当今的深度学习模型尤其是自注意力模型带来了新的挑战。线性注意力机制逐渐成为提升计算效率和模型可扩展性的一个重要研究方向。本文结合研究现状对线性注意力机制的未来研究方向进行了简单分析。

### 线性注意力发展方向总结

随着深度学习模型尤其是基于注意力机制的模型在处理大规模数据时取得的显著成果，线性注意力机制逐渐成为提升计算效率和模型可扩展性的一个重要研究方向。以下是线性注意力机制未来发展的几个主要方向：

#### RNN

从 SSM 的视角看，线性注意力本质上和 RNN 类似。未来研究者可以在 Mamba 和 RWKV 等工作的基础上，继续探索如何结合 RNN 的优势来提升线性注意力的性能和效率。具体来说，可以研究如何将 RNN 的循环特性与线性注意力的状态更新机制相结合，以增强模型对长序列数据的建模能力。同时，可以探索如何利用 RWKV 中的时间混合模块和 Mamba 中的选择性状态空间模型，来实现更高效的信息处理和更灵活的特征聚合。此外，研究者还可以考虑如何优化线性注意力模型以更好地适应现代硬件架构，比如通过改进内存访问模式和并行化计算过程来提升计算效率。这些研究方向有望使线性注意力模型在处理大规模数据集时展现出更高的效率和更强的泛化能力。

#### 3. **核函数**

核函数（Kernel Functions）在支持向量机（SVM）和高维数据处理等领域具有广泛应用。在线性注意力中，核函数被用来近似传统的点积计算，从而减少计算复杂度。核化方法将输入的注意力矩阵转化为低维空间中的函数映射，从而避免了直接进行全连接矩阵乘法的高计算成本。这使得模型能够在保持计算效率的同时，仍然捕捉到数据中的重要信息。

核函数的应用不仅限于简化计算，还能够通过引入非线性变换，增强模型的表达能力。例如，常见的高斯核、线性核和多项式核等，都能够有效地对注意力矩阵进行变换，提供更加灵活的表示方式。未来，结合核函数的线性注意力模型有望在更复杂的任务中表现出更高的效率和更强的泛化能力。
Conformer
Relu

#### 4. **硬件高效**

随着计算硬件的不断发展，如何让线性注意力模型能够充分利用硬件加速能力，成为提升其计算效率的一个关键方向。当前，许多深度学习模型的计算瓶颈主要出现在对大量参数和大规模数据的处理上，特别是对于长序列输入，内存和计算能力的消耗尤为严重。

为了解决这一问题，研究人员正在探索如何优化线性注意力模型，使其能够更好地适配现代硬件架构，如图形处理单元（GPU）、张量处理单元（TPU）以及定制硬件加速器等。这包括但不限于优化内存访问模式、并行化计算过程以及降低精度以减少硬件计算负担。未来，硬件高效的线性注意力模型将能够在较低的计算成本下处理更大规模的数据集，满足现实中对大规模数据处理和实时推理的需求。

## 结论

本文深入探讨了传统注意力机制的基本概念、局限性以及线性注意力机制的发展，分析了线性注意力机制如何通过优化计算复杂度、降低内存消耗以及提高模型可扩展性，在处理长序列任务时展现出显著优势。与此同时，本文也指出了线性注意力的缺陷，例如表达能力有限、聚焦能力不足等，并介绍了针对这些问题的解决方案。

在研究方向上，本文总结了当前线性注意力机制的几种重要发展趋势，并对未来的研究方向进行了展望.
总的来说，线性注意力机制在深度学习领域，尤其是在自然语言处理和计算机视觉中，展现了巨大的潜力。随着技术的发展，结合门控机制、结构化状态空间模型、核函数以及硬件优化等手段，未来的线性注意力模型将在处理长序列数据、提高计算效率、拓展应用领域等方面发挥更加重要的作用。
