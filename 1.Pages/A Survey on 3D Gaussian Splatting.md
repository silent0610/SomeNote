---
Type:
  - Paper
Status:
  - done
tags: 
PaperType:
  - Review
---

## 摘要

3D高斯点云（3D Gaussian Splatting，简称3D GS）最近在显式辐射场和计算机图形学领域中成为了一项颠覆性技术。这种创新方法的特点是利用数百万个可学习的3D高斯分布，代表了与主流神经辐射场方法（这些方法主要使用隐式的、基于坐标的模型将空间坐标映射到像素值）显著不同的方向。3D GS通过其显式的场景表示和可微分渲染算法，不仅承诺了实时渲染的能力，还引入了前所未有的可编辑性。这使得3D GS成为下一代3D重建和表示的潜在变革者。本文提供了对3D GS领域最近发展和关键贡献的首次系统综述。我们首先详细探讨了3D GS的基本原理以及推动其出现的关键因素，为理解其重要性奠定基础。我们讨论的重点之一是3D GS的实际应用性。通过实现前所未有的渲染速度，3D GS为虚拟现实、互动媒体等一系列应用开辟了新的可能性。此外，我们还对领先的3D GS模型进行了比较分析，通过在各种基准任务上的评估，突出了它们的性能和实际应用价值。综述最后，我们总结了当前的挑战，并提出了未来研究的潜在方向。通过这篇综述，我们希望为新手和资深研究人员提供一个有价值的资源，促进在显式辐射场表示领域的进一步探索和进展。

**Index Terms** 3D高斯泼溅, 显示辐射场, 实时渲染, 场景理解

## 1 介绍

基于图像的3D场景重建的目标是将捕捉场景的多个视图或视频转换为一个可以被计算机处理和理解的3D模型。这个长期存在且艰巨的问题对于机器理解真实世界环境的复杂性至关重要，并促进了包括3D建模和动画、机器人导航、历史保存、增强/虚拟现实和自动驾驶等在内的广泛应用。3D场景重建的研究始于深度学习兴起之前，早期的努力主要集中在光场和基本的场景重建方法上[1]–[3]。然而，这些早期尝试受限于对密集采样和结构化捕获的依赖，在处理复杂场景和光照条件时面临重大挑战。结构光重建（structure-from-motion）[4]的出现以及随后的多视图立体视觉（multi-view stereo）[5]算法的进展为3D场景重建提供了更强大的框架。尽管有了这些进展，这些方法在新视角合成方面依然存在困难，并且缺乏与深度场景理解模型的兼容性。NeRF代表了这一进程中的一次飞跃。通过利用深度神经网络，NeRF能够将空间坐标直接映射到颜色和密度上。NeRF的成功在于其能够创建连续的体积场景函数，生成前所未有的细节和真实感。然而，像任何新兴技术一样，这种实现也有其代价：i）计算密集性。基于NeRF的方法计算密集[6][9]，通常需要长时间的训练和大量的渲染资源，尤其是在高分辨率输出的情况下。ii）可编辑性。由于神经网络的权重与场景的几何或外观属性的变化没有直观的关系，修改隐式表示的场景变得具有挑战性。

在这种背景下，3D高斯点云（3D Gaussian Splatting，简称3D GS）[10]应运而生，它不仅仅是一个渐进的改进，而是一种范式转变的方法，重新定义了场景表示和渲染的边界。虽然NeRF在创建照片级真实感图像方面表现出色，但对于更快、更高效的渲染方法的需求日益显现，尤其是在对延迟高度敏感的应用（如虚拟现实和自动驾驶）中。3D GS通过引入一种先进的显式场景表示，解决了这一需求，使用数百万个可学习的3D高斯分布来建模场景。与隐式、基于坐标的模型[11][12]不同，3D GS采用了显式表示和高度并行化的工作流程，促进了更高效的计算和渲染。3D GS的创新之处在于其独特地结合了可微分管道和基于点的渲染技术[13]–[17]的优点。通过使用可学习的3D高斯分布来表示场景，它保留了连续体积辐射场强大的拟合能力，这对于高质量图像合成至关重要，同时避免了基于NeRF的方法所带来的计算开销（例如，计算密集的光线追踪和空白空间中的不必要计算）。  
![图 1. 每个月，关于 3D GS 的后续 arXiv 论文和官方 GitHub 星标数量都在增加。](assets/Pasted%20image%2020241127225800.png#center)

3D GS的引入不仅仅是技术上的进步，它代表了我们在计算机视觉和图形学中处理场景表示和渲染方式的根本转变。通过实现实时渲染能力而不牺牲视觉质量，3D GS为虚拟现实、增强现实、实时电影渲染等领域开辟了众多新的可能性[18]–[21]。这项技术不仅有望提升现有应用，还能启用一些由于计算限制而此前无法实现的新应用。此外，3D GS的显式场景表示提供了前所未有的灵活性，可以控制物体和场景的动态变化，这是在处理复杂几何形状和多变光照条件下至关重要的因素[22]–[24]。这种编辑能力与训练和渲染过程的高效性相结合，使得3D GS在塑造相关领域的未来发展方面成为一股变革力量。

为了帮助读者跟上3D GS快速发展的步伐，我们提供了关于3D GS的首次综述，呈现了这一主题上最重要文献的系统性、及时的收集。鉴于3D GS是一个非常新的创新（见图1），本综述特别关注其基本原理以及自其引入以来出现的各种发展和贡献。所选的后续工作主要来自顶级会议，以提供对3D GS理论基础、重要发展和新兴应用的全面、最新分析。鉴于3D GS的快速发展和初步阶段，本综述不可避免地具有偏向性，但我们力求提供一个平衡的视角，反映该领域的当前状态和未来潜力。我们的目标是总结主要的研究趋势，并为渴望理解和贡献这一迅速发展的领域的研究人员和从业者提供有价值的资源。

本文的结构概述见图2，具体安排如下：第2节简要介绍问题的提出、术语定义和相关研究领域；第3节介绍了3D GS的核心思想，涵盖了使用学习到的3D高斯分布进行渲染的过程和优化细节（即如何学习3D高斯分布）；第4节提出了若干旨在提高原始3D GS能力的有前景的研究方向；第5节展示了3D GS在多个应用领域和任务中的显著影响，展示了其多功能性；第6节进行性能比较与分析；最后，第7节和第8节总结了进一步研究的开放问题，并对综述进行总结。  
![](assets/Pasted%20image%2020241127230144.png)

> 图 2. 综述整体结构

## 2 背景

在本节中，我们首先简要介绍了辐射场（Radiance Fields）的基本概念（第2.1节），这是场景渲染中的一个关键概念。我们概述了两种主要的辐射场表示方式：隐式表示，如NeRF[12]，通过神经网络进行直接但计算要求高的渲染；显式表示，如网格[25]，通过使用离散结构实现更快的访问，但代价是较高的内存使用。第2.2节进一步建立了与相关领域（如场景重建和渲染）之间的联系。如需更全面了解辐射场、场景重建与表示以及渲染方法，请参考优秀的综述文章[26]–[30]，以获得更多见解。

### 2.1 问题方程

#### 2.1.1 辐射场

辐射场是对三维空间中光分布的表示，它捕捉了光如何与环境中的表面和材料相互作用[27]。从数学角度来看，辐射场可以表示为一个函数 $L : R^5 → R^+$，其中 L(x, y, z, θ, φ) 将空间中的一个点 (x, y, z) 和由球坐标 (θ, φ) 指定的方向映射到一个非负的辐射值。辐射场可以通过隐式或显式表示来封装，每种方式在场景表示和渲染中具有特定的优势。

#### 2.1.2 隐式辐射场

隐式辐射场表示场景中的光分布，而不显式定义场景的几何形状。在深度学习时代，它经常使用神经网络来学习连续的体积场景表示[31]，[32]。最突出的例子是NeRF[12]。在NeRF中，神经网络，通常是多层感知器(MLP)，用于将一组空间坐标(x，y，z)和观察方向(θ，φ)映射到颜色和密度值。任何点的辐射度都不是显式存储的，而是通过查询MLP即时计算的。因此，函数可以写成：

$$
L_{\mathrm{implicit}}(x,y,z,\theta,\phi)=\mathrm{MLP}(x,y,z,\theta,\phi).\quad(1)
$$

这种格式允许复杂场景的可微和紧凑表示，尽管由于体积光线行进，通常以高计算负载为代价[10]。

#### 2.1.3 显示辐射场

相比之下，显式辐射场直接以离散的空间结构（如体素网格或点集）表示光线的分布。该结构中的每个元素存储其对应空间位置的辐射信息。这种方式允许更直接且通常更快速地访问辐射数据，但代价是更高的内存占用以及潜在的分辨率降低。显式辐射场表示的一种通用形式可以写为：

$$
L_{\mathrm{implicit}}(x,y,z,\theta,\phi)=\mathrm{MLP}(x,y,z,\theta,\phi).\quad(1)
$$

其中 DataStructure 可以是体积、点云等格式。$f(θ,φ)$ 是一个根据观察方向修改辐射度的函数。

#### 2.1.4 3D 高斯泼溅：两全其美

3D GS[10]是一种显式辐射场，具有隐式辐射场的优点。具体来说，它通过利用可学习的3D高斯作为灵活有效的表示，利用了两种范式的优势。这些高斯在多视图图像的监督下进行优化，以准确地表示场景。这种基于3D高斯的可微分流水线结合了基于神经网络的优化和显式结构化数据存储的益处。这种混合方法旨在实现实时、高质量的渲染，并且需要更少的训练时间，特别是对于复杂场景和高分辨率输出。3D高斯表示被公式化为：

$$
L_{\mathrm{3DGS}}(x,y,z,\theta,\phi)=\sum_{\vdots}G(x,y,z,\boldsymbol{\mu}_{i},\boldsymbol{\Sigma}_{i})\cdot c_{i}(\theta,\phi),\quad(3)
$$

其中G是均值μi和协方差Σi的高斯函数，c表示视图相关颜色。

### 2.2 上下文和术语

一些技术和研究学科与3D GS有着密切的关系，为了清楚起见，将在以下章节中简要描述。

#### 2.2.1 场景重建和渲染

粗略地说，场景重建涉及从图像或其他数据的集合创建场景的 3D 模型。渲染是更具体的术语，其关注于将计算机可读信息 (例如，场景中的 3 D 对象) 转换为基于像素的图像。早期技术基于光场生成逼真的图像[1]-[3]。运动结构[4]和多视图立体[5]算法通过从图像序列中估计 3 D 结构进一步推进了这一领域。这些历史方法为更复杂的场景重建和渲染技术提供了坚实的基础[34]-[37]。

#### 2.2.2 神经渲染和辐射场

神经渲染将深度学习与传统图形技术相结合，以创建逼真的图像。早期的尝试利用卷积网络来估计混合权重[36]或纹理空间解[38]。如第二节所述。在 2.1.1 中，辐射场表示一个函数，该函数描述了在每个方向上穿过空间中每个点的光量。NeRFs[8]、[9]、[12]使用神经网络（通常是 MLP）来模拟辐射场，从而实现详细和真实的场景渲染。

#### 2.2.3 体积表示和光线行进

体积表示不仅将对象和场景建模为曲面，还将对象和场景建模为填充有材质或空白空间的体积。这允许更准确地渲染雾、烟雾或半透明材料等现象。光线行进是一种用于体积表示的技术，通过跟踪光通过体积的路径来渲染图像[11]。NeRF[12]分享了体积光线行进的相同精神，并引入了重要性采样和位置编码来提高合成图像的质量。在提供高质量结果的同时，体积光线行进在计算上是昂贵的，这促使人们寻找更有效的方法，如3D GS。

#### 2.2.4 基于点的渲染

基于点的渲染是一种使用点而不是传统的多边形来可视化3D场景的技术。这种方法对于渲染复杂、非结构化或稀疏的几何数据特别有效。点可以用额外的属性来增强，如可学习的神经描述符[39]、[40]，并有效地渲染[41]、[42]，但这种方法存在渲染中的漏洞或混叠效果等问题。3D GS[10]通过使用各向异性高斯来扩展这一概念，以获得更连续和更有凝聚力的场景表示。更多的实现细节将在第二节中进一步讨论。3.

## 3 3D 高斯泼溅: 原理

3D GS在实时、高分辨率图像渲染方面取得了突破，无需依赖深度神经网络。本节旨在提供关于3D GS的基本见解。我们首先在第3.1节详细说明如何通过构造良好的3D高斯分布生成图像，即3D GS的前向处理过程。然后在第3.2节介绍如何针对给定场景获得构造良好的3D高斯分布，即3D GS的优化过程。  
![](assets/Pasted%20image%2020241127230232.png)

> 图 3. NeRF 与 3D GS 的对比  
(a) NeRF 沿光线采样，然后查询 MLP 以获取相应的颜色和不透明度，这可以视为一种反向映射（光线追踪）。  
(b) 相比之下，3D GS 将所有 3D 高斯分布投影到图像空间（即 splatting），然后执行并行渲染，这可以视为一种前向映射（splatting 和光栅化）。  
最佳效果请以彩色查看。

### 3.1 使用学习好的 3DGS 进行渲染

考虑由（数百万）优化的3D高斯表示的场景。目标是从指定的相机姿态生成图像。回想一下，NeRFs通过计算要求很高的体积光线行进来完成这项任务，对每个像素的3D空间点进行采样。这种范式难以实现高分辨率图像合成，无法实现实时渲染，尤其是对于计算资源有限的平台【10】。相比之下，3D GS通过将这些3D高斯投影到基于像素的图像平面上开始，该过程称为“飞溅”（参见图3b）。之后，3D GS对这些高斯进行排序，并计算每个像素的值。如图3所示，NeRF和3D GS的渲染可以被视为彼此的逆过程。在下文中，我们从3D高斯的定义开始，它是3D GS中场景表示的最小元素。接下来，我们描述如何将这些3D高斯用于可微渲染。最后，我们介绍了 3DGS中使用的加速技术，这是快速渲染的关键。
- **3DGS 的性质**。3DGS由其中心（位置）μ、不透明度α、3D协方差矩阵Σ和颜色c来表征。c由视图相关外观的球面谐波表示。所有属性都是可学习的，并通过反向传播进行优化。
- **截头体剔除**。给定指定的相机姿态，该步骤确定哪些3D高斯在相机的平截头体之外。通过这样做，给定视图之外的3D高斯将不会参与后续计算，从而节省计算资源。
- **泼溅**。在这一步中，将3D空间中的3D高斯（椭球）投影到2D图像空间（椭圆）中渲染。给定观察变换W和3D协方差矩阵Σ，使用以下方法计算投影的2D协方差矩阵Σ'：

$$
\boldsymbol{\Sigma}^{\prime}=\boldsymbol{J} \boldsymbol{W} \boldsymbol{\Sigma} \boldsymbol{W}^{\top} \boldsymbol{J}^{\top},\quad(4)
$$

     式中，J 为射影变换的仿射逼近的雅可比矩阵[10]、[43]。\
- **逐像素渲染**.在深入研究 3D GS 的最终版本之前，它利用了几种技术来促进并行计算，我们首先阐述了它更简单的形式，以提供对其基本工作机制的见解。给定像素 x 的位置，可以通过观察变换 W 计算其到所有重叠高斯的距离，即这些高斯的深度，从而形成高斯 N 的排序列表。然后，采用 alpha 合成来计算该像素的最终颜色：

$$
C=\sum_{n=1}^{|\mathcal{N}|} c_n \alpha_n^{\prime} \prod_{j=1}^{n-1}\left(1-\alpha_j^{\prime}\right) \quad(5)
$$

  式中，cn 为习得颜色。最终不透明度α′n 是学习不透明度α n 和高斯的乘法结果，定义如下：

$$
\alpha_n^{\prime}=\alpha_n \times \exp \left(-\frac{1}{2}\left(\boldsymbol{x}^{\prime}-\boldsymbol{\mu}_n^{\prime}\right)^{\top} \boldsymbol{\Sigma}_n^{\prime-1}\left(\boldsymbol{x}^{\prime}-\boldsymbol{\mu}_n^{\prime}\right)\right),
$$

  式中，x′和μ′n 是投影空间中的坐标。考虑到生成所需的排序列表很难并行化，所描述的渲染过程可能比 NeRFs 慢，这是一个合理的担忧。事实上，这种担忧是有道理的；当利用这种简单的逐像素方法时，渲染速度会受到显著影响。为了实现实时渲染，3D GS 做出了几项让步以适应并行计算。
- 图块 (分片) 为了避免为每个像素导出高斯的成本计算，3D GS 将精度从像素级转移到面片级细节。具体来说，3D GS 最初将图像划分为多个不重叠的面片（在原始论文[10]中称为“图块”）。图 4b 提供了图块的图示。如[10]中所建议的，每个图块包括 16 × 16 像素。3D GS 进一步确定哪些图块与这些投影高斯相交。假设投影的高斯可以覆盖若干图块，逻辑方法涉及复制高斯，为每个副本分配相关图块的标识符 (即，图块 ID)。
- 并行渲染。在复制之后，3D GS 将相应的图块 ID 与从每个高斯的视图变换获得的深度值组合。这导致未排序的字节列表，其中高位表示图块 ID，低位表示深度。通过这样做，排序列表可以直接用于渲染 (即，α合成)。图 4c 和图 4d 提供了这种概念的视觉演示。值得强调的是，渲染每个图块和像素是独立发生的，这使得这个过程非常适合并行计算。另一个好处是，每个图块的像素可以访问公共共享存储器并保持统一的读取序列 (图 5)，从而能够以更高的效率并行执行α合成。在原始论文[10]的正式实现中，该框架将图块和像素的处理分别视为 CUDA 编程架构中的块和线程。  
简而言之，3D GS 在渲染过程中引入了几种近似，以提高计算效率，同时保持高标准的图像合成质量。

![](assets/Pasted%20image%2020241127230346.png)

>图 4. 3D GS 前向过程的示意图（参见第 3.1 节）。  
(a) Splatting 步骤将 3D 高斯分布投影到图像空间。  
(b) 3D GS 将图像划分为多个不重叠的图块（tiles）。  
(c) 3D GS 复制覆盖多个图块的高斯分布，并为每个副本分配一个标识符，即图块 ID。  
(d) 通过渲染排序后的高斯分布，我们可以获得图块内的所有像素。  
注意，像素和图块的计算工作流程是独立的，可以并行处理。  
最佳效果请以彩色查看。

![](assets/Pasted%20image%2020241127230511.png)

> 图 5. 基于图块的并行渲染（在像素级别）示意图。  
图块内的所有像素（此处为 Tile1）访问存储在共享内存中的相同排序的高斯列表进行渲染。随着系统按顺序处理每个高斯分布，图块内的每个像素根据距离（即公式 6 中的 exp 项）评估高斯分布的贡献。因此，图块的渲染可以通过遍历一次高斯列表来完成。红色高斯的计算方式类似，出于简洁性，此处省略。

## 3.2 3D高斯溅射的优化

3D GS 的核心在于一种优化流程，该流程旨在构建大量的 3D 高斯分布，从而精准捕捉场景的本质，进而实现自由视角渲染。一方面，需要通过可微渲染优化 3D 高斯分布的属性，使其适应给定场景的纹理。另一方面，能够良好表示特定场景所需的 3D 高斯分布数量在优化前是未知的。一种有前景的做法是让神经网络自动学习 3D 高斯分布的密度。我们将在第 3.2.1 节介绍如何优化每个高斯分布的属性，并在第 3.2.2 节介绍如何控制高斯分布的密度。这两种流程在优化工作流中交替进行。由于优化过程中涉及大量手动设置的超参数，为简洁起见，我们省略了对大多数超参数的符号表示。

### 3.2.1 参数优化

- 损失函数. 在完成图像合成后，可以计算渲染图像与真实图像之间的差异。所有可学习参数通过随机梯度下降（SGD）进行优化，采用 $l_1$ 损失函数和 D-SSIM 损失函数进行训练：

$$
\mathcal{L}=(1-\lambda) \mathcal{L}_1+\lambda \mathcal{L}_{\text {D-SSIM }},\quad(7)
$$

  其中，λ∈[0,1]是权重因子。3D GS 的损失函数与 NeRF 的略有不同。NeRF 通常在像素级别计算损失，而不是在图像级别计算损失，这是因为光线行进（ray-marching）的计算成本较高。
- 参数更新. 3D 高斯分布的大多数属性可以通过反向传播直接优化。但需要注意的是，直接优化协方差矩阵 Σ 可能导致其成为非正半定矩阵，这与协方差矩阵通常的物理意义不符。为了解决这个问题，3D GS 选择优化四元数 q 和一个三维向量 s。其中，q表示旋转，s 表示缩放。通过这种方式，协方差矩阵 Σ 可以按以下方式重新构造：

$$
\boldsymbol{\Sigma}=\boldsymbol{R} \boldsymbol{S} \boldsymbol{S}^{\top} \boldsymbol{R}^{\top},
$$

  其中，R 和 S 分别表示由 q 和 s 导出的旋转矩阵和缩放矩阵。从四元数 q 和向量 s 开始，到协方差矩阵 Σ、投影协方差矩阵 Σ′，再到不透明度 α 的计算，存在一个复杂的计算图（即 q,s→Σ→Σ′→α）。为了避免自动微分所带来的计算成本，3D GS 通过推导 q 和 s 的梯度，从而在优化过程中直接计算它们的更新。

### 3.2.2 密度控制

- 初始化（Initialization）.3D GS 从 SfM（结构光束法）或随机初始化的稀疏点集开始。需要注意的是，一个良好的初始化对于收敛和重建质量至关重要[44]。随后，采用点密度化（point densification）和点修剪（point pruning）技术来控制 3D 高斯分布的密度。
- 点密度化（Point Densification）.在点密度化阶段，3D GS 自适应地增加高斯分布的密度，以更好地捕捉场景的细节。此过程重点关注几何特征缺失的区域或高斯分布过于分散的区域。密度化过程将在定期间隔（即在一定数量的训练迭代之后）执行，主要关注那些具有大视图空间位置梯度的高斯分布（即大于特定阈值的高斯分布）。这个过程包括在重建不足的区域克隆小的高斯分布，或者在重建过度的区域拆分大的高斯分布。对于克隆，创建一个高斯副本并将其移动到位置梯度的方向；对于拆分，将大的高斯分布替换为两个较小的高斯分布，并按特定因子缩小它们的规模。这个步骤旨在优化高斯分布在 3D 空间中的分布和表示，从而提高重建的整体质量。
- 点修剪（Point Pruning）点修剪阶段涉及去除冗余或影响较小的高斯分布，可以视为一种正则化过程。通过消除几乎透明（不透明度 α 低于指定阈值）或在世界空间或视图空间中过大（过度扩展）的高斯分布来执行修剪。此外，为了防止在输入相机附近高斯分布密度的不合理增加，经过一定迭代次数后，将这些高斯分布的 α 值设置为接近零。这样可以在增加必要高斯分布的密度的同时，有效去除冗余的高斯分布。这个过程不仅有助于节省计算资源，还确保模型中的高斯分布对于场景表示保持精确和有效。

## 4 3D 高斯泼溅: 方向

尽管 3D GS 已经取得了显著的里程碑，但仍有很大的改进空间，例如数据和硬件需求、渲染与优化算法，以及下游任务中的应用。在随后的章节中，我们将详细介绍 3D GS 的一些扩展版本，具体包括：  
i) 数据高效的 3D GS 45–55（第 4.1 节） . ii) 内存高效的 3D GS 56–64（第 4.2 节） .iii) 逼真渲染的 3D GS 65–80（第 4.3 节）. iv) 改进的优化算法 22，77，81–86（第 4.4 节）. v) 具有更多属性的 3D 高斯分布 87–93（第 4.5 节）. vi) 与结构化信息结合的 3D GS 94–96（第 4.6 节）

### 4.1 数据高效的 3D GS

3D GS 的一个显著问题是在观察数据不足的区域出现伪影。这一挑战在辐射场渲染中较为普遍，稀疏数据往往导致重建不准确。从实际角度来看，从有限视角重建场景是一个重要问题，特别是对于在最小输入下增强功能的潜力。为了解决数据高效性问题，采用了两种主要策略：  
i) 基于正则化的方法 引入额外约束，如深度信息，以增强细节和全局一致性【46】【49】【51】【55】。例如，DNGaussian【49】提出了一种深度正则化方法，解决了稀疏输入视角下几何降解的问题。FSGS【46】设计了一种高斯反池化（Gaussian Unpooling）过程用于初始化，并且引入了深度正则化。MVSplat【51】提出了成本体积表示法，以提供几何提示。遗憾的是，在处理有限视角（甚至只有一个视角）时，正则化技术的效果往往减弱。  
ii) 基于泛化的方法 专注于学习先验【47】【48】【53】。一种典型的实现是使用深度神经网络生成可以直接用于渲染的 3D 高斯分布，而无需优化。这种范式通常需要多个视角进行训练，但只需一个输入图像即可重建 3D 场景。例如，PixelSplat【47】提出从密集概率分布中采样高斯分布，结合多视角极平面变换器和重参数化技巧，以避免局部最小值并保持梯度流动。Splatter Image【48】在单目设置下应用了 GS，通过基于学习的方法，利用 2D 图像到图像的网络将输入图像映射为每个像素的 3D 高斯分布。需要注意的是，这种范式主要集中于物体的重建，且其泛化能力仍有很大改进空间。

### 4.2 内存高效的 3D GS

尽管 3D GS 展现出了显著的能力，但其可扩展性仍面临显著挑战，特别是在与 NeRF 基方法相比时。后者通过仅存储已学习的 MLP 参数，简单而高效。然而，在大规模场景管理中，这一可扩展性问题变得更加突出，计算和内存需求大幅上升。因此，急需优化模型训练和存储过程中的内存使用。减少内存使用的主要方向有两种：  
i) **减少 3D 高斯分布的数量**【58】【62】【63】。例如，Papantonakis 等人【63】提出了一种基于分辨率的修剪方法，将高斯分布的数量减少一半。Lee 等人【58】引入了一种新的基于体积的掩蔽策略，有效地减少了高斯分布的数量，而不损害性能。  
ii) **压缩 3D 高斯分布属性的内存使用**【58】【61】【62】。例如，Niedermayr 等人【61】将颜色和高斯参数压缩成紧凑的代码书，使用灵敏度度量进行有效量化和微调。HAC【62】通过高斯分布预测每个量化属性的概率，并设计了一个自适应量化模块。尽管当前的方法在存储（训练后）中已经实现了几倍到几十倍的压缩比，但在训练阶段仍有巨大的内存优化潜力。

### 4.3 逼真渲染的 3D GS

当前 3D GS 的渲染管线（第 3.1 节）相对简单，但也存在一些缺点。例如，简单的可见性算法可能导致高斯分布深度/混合顺序发生剧烈变化【10】。渲染图像的真实感，包括诸如别名效应、反射和伪影等方面，还可以进一步优化。以下是增强真实感的几个关键点：  
i) 不同分辨率【67】【78】。由于离散采样范式（将每个像素视为一个点而非一个区域），3D GS 在处理不同分辨率时容易产生别名效应，导致模糊或锯齿边缘。Yan 等人【67】认为，这主要是因为传统的渲染方法无法有效管理像素采样频率与场景高频细节之间的差异，导致视觉伪影和性能问题。因此，他们引入了多尺度 3D GS，其中场景使用不同大小的高斯分布表示。Analytic-Splatting【78】采用了高斯积分的解析近似方法，并利用条件逻辑函数的累积分布函数来更好地捕捉像素的强度响应。  
ii) 反射【68】【97】【98】。实现反射材料的真实渲染一直是 3D 场景重建中的一个难题。GaussianShader【68】通过将简化的阴影函数与 3D 高斯分布结合，增强了神经渲染中反射表面的表现。  
iii) 几何结构。3D GS 的一个局限性是忽视了场景的底层几何和结构，特别是在复杂场景和变化的视角与光照条件下。这激发了关于几何感知重建的研究【22】【44】【99】–【102】。例如，GeoGaussian【77】专注于保留非纹理区域的几何结构，如墙壁和家具，这些区域随着时间的推移往往会退化。

### 4.4 改进的优化算法

尽管各向异性高斯分布在表示复杂几何形状方面有利，但它们可能会产生不希望出现的视觉伪影。例如，尤其是在具有视角依赖外观的区域，这些较大的 3D 高斯分布可能会引起弹出伪影，导致视觉元素突然出现或消失，从而破坏沉浸感。此外，结合额外的正则化（例如几何正则化【77】【83】和频率正则化【84】）并改进 3D GS 的优化过程（第 3.2 节）可以加速收敛，平滑视觉噪声，并提高渲染图像的质量。改进 3D GS 优化的三大方向如下：

i) 引入额外的正则化【22】【84】。3D GS 经常面临过度重建的挑战，其中稀疏的大 3D 高斯分布在高方差区域表现不佳，导致模糊和伪影。为了解决这一问题，FreGS【84】提出了一种渐进式频率正则化方法，从频率的角度精炼高斯密度化。另一条显著的分支是几何感知重建，正如第 4.3 节中所介绍的。这一工作特别关注如何保持场景的结构。例如，Scaffold-GS【22】引入了一个稀疏的锚点网格来组织局部 3D 高斯分布，这些高斯分布会根据视角和距离动态调整不透明度和颜色等属性。

ii) 改进优化过程【44】【77】。在解决无纹理表面的大规模场景密集初始化问题时，GaussianPro【44】提出了一种先进的高斯密度化（第 3.2.2 节）策略，利用重建几何体的先验和补丁匹配技术。

iii) 放松优化约束【81】【82】。对外部工具/算法的依赖可能会引入误差并限制系统性能的潜力。  
例如，常用于初始化过程的 SfM（结构光束法）容易出错，并且在复杂场景中表现不佳。Yang 等人【81】提出了 COLMAP-Free 3D GS，该方法引入了视频流连续性和显式点云表示，从而消除了对 SfM 预处理的需求。尽管现有方法令人印象深刻，但它们主要集中于优化高斯分布以从头开始精确重建场景，忽视了一个有挑战性但前景广阔的范式，即通过建立的“元表示”以少量样本方式重建场景。有关更多见解，请参见第 7 节的“从大规模数据中学习物理先验”。

### 4.5 具有更多属性的 3D 高斯分布

尽管 3D 高斯分布（第 3.1 节）的属性设计仅用于新视角合成，但通过增强 3D 高斯分布的附加属性，如语言特征【87】–【89】、语义/实例特征【90】–【92】以及时空特征【93】, 3D GS 展示了其在各个领域变革性的潜力。以下是一些使用具有特殊设计属性的 3D 高斯分布的有趣应用：

i) 语言嵌入场景表示【87】–【89】。由于当前语言嵌入场景表示的高计算和内存需求，Shi 等人【87】提出了一种量化方案，通过简化语言嵌入而非原始高维嵌入来增强 3D 高斯分布。这种方法还减少了语义歧义，通过在不同视角之间平滑语义特征，利用不确定性值增强了开放词汇查询的精度。

ii) 场景理解和编辑【90】–【92】。Feature 3DGS【90】将 3D GS 与 2D 基础模型的特征场蒸馏结合。通过学习低维特征场，并应用轻量级卷积解码器进行上采样，Feature 3DGS 实现了更快的训练和渲染速度，同时支持语义分割和语言引导的编辑等应用。

iii) 时空建模【93】【103】。为了捕捉 3D 场景的复杂时空动态，Yang 等人【93】将时空概念化为统一体，并通过一组 4D 高斯分布近似动态场景的时空体积。提出的 4D 高斯表示法及相应的渲染管线能够建模空间和时间中的任意旋转，并允许端到端训练。

### 4.6 结合结构化信息的 3D GS

除了通过增加附加属性来增强 3D 高斯分布，另一种有前景的方法是引入适应特定应用的结构化信息（例如，空间 MLP 和网格）来适应下游任务。接下来，我们展示了几个结合特殊设计的结构化信息的 3D GS 的有趣应用：

i) 面部表情建模。考虑到在稀疏视角条件下创建高保真 3D 头部头像的挑战，Gaussian Head Avatar【96】引入了可控的 3D 高斯分布和基于 MLP 的变形场。具体而言，通过优化中性 3D 高斯分布和变形场，它捕捉了详细的面部表情和动态，从而确保了细节的保真性和表情的准确性。

ii) 时空建模。Yang 等人【94】提出了通过变形 3D 高斯分布重建动态场景。变形 3D 高斯分布在标准空间中学习，并与变形场（即空间 MLP）结合，后者建模时空动态。该方法还结合了退火平滑训练机制，在不增加额外计算成本的情况下提高了时序平滑性。

iii) 风格迁移。Saroha 等人【153】提出了 GS in style，一种用于实时神经场景风格化的先进方法。为了在不牺牲渲染速度的情况下在多个视角之间保持一致的风格化外观，他们使用了预训练的 3D 高斯分布，结合了多分辨率哈希网格和一个小型 MLP 来生成风格化视图。总之，结合结构化信息可以作为补充部分，适应那些与 3D 高斯分布的稀疏性和无序性不兼容的任务。

![](assets/Pasted%20image%2020241127230647.png)

> 图6。受益于GS的典型应用（第5节）。一些图像是从[125]、[128]、[138]、[142]、[151]借用并重新绘制的. 

## 5 应用领域与任务

基于 3D GS 的快速发展，已经在多个领域涌现出一系列创新应用（见图 6），例如机器人技术（第 5.1 节）、动态场景重建与表示（第 5.2 节）、AI 生成内容（第 5.3 节）、自动驾驶（第 5.4 节）、医疗系统（第 5.5 节）、大规模场景重建（第 5.6 节）以及其他科学领域【24】【154】–【156】。在此，我们重点介绍一些典型应用，突显 3D GS 的变革性影响和潜力。

### 5.1 同时定位与地图构建（SLAM）

SLAM 是机器人技术和自主系统中的一个核心计算问题。它涉及一个机器人或设备在未知环境中理解其位置信息，同时实时绘制环境的布局。SLAM 在自动驾驶汽车和机器人导航等应用中至关重要。SLAM 的核心是创建一个未知环境的地图，并实时确定设备在该地图上的位置。因此，SLAM 对计算密集型的场景表示技术提出了巨大挑战，但它也为 3D GS 提供了一个良好的测试平台【157】。

3D GS 进入 SLAM 领域，作为一种创新的场景表示方法。传统的 SLAM 系统通常使用点云/曲面云或体素网格来表示环境【158】–【165】。与此不同，3D GS 利用各向异性高斯分布来更好地表示环境。最近的创新研究在 SLAM 中应用了 3D GS【104】–【108】【110】【113】【166】，展示了这一范式的潜力和多样性。直观的方式是使用 3D 高斯分布作为密集地图的基本表示，并优化跟踪过程。例如，GS-SLAM【104】采用了一种自适应策略，添加或移除 3D 高斯分布，从而优化场景几何重建，并改善已观察区域的映射。类似地，Sun 等人【113】在在线映射过程中提出了额外的正则化项，以避免对最新帧的过拟合。SplaTAM【105】结合了一个简便的在线跟踪和映射方法，利用轮廓掩模来捕捉场景密度的存在，促进密集优化和结构化地图扩展。另一方面，设计先进的场景表示方法也是值得探索的。例如，Photo-SLAM【108】提出了一种混合高斯地图，将显式几何特征用于精确定位，并结合隐式光度特征进行纹理映射。此外，一个有趣的问题是基于高斯的地图表示如何帮助机器人任务，一些早期的导航尝试已被提出【167】–【169】。尽管这些现有的基于高斯的 SLAM 系统令人印象深刻，但它们仍然面临持续的挑战，如动态元素、传感器噪声、非朗伯物体和深度模糊，这些问题仍需进一步探索。

### 5.2 动态场景重建

动态场景重建是指捕捉和表示随时间变化的场景的三维结构和外观的过程【170】–【173】。这涉及创建一个数字模型，准确反映场景中物体的几何形状、运动和视觉特性，随着它们的演变而变化。动态场景重建在虚拟现实、增强现实、3D 动画和计算机视觉等多个应用中至关重要。为了将 3D GS 的概念扩展到动态场景，一个简单的方法是加入时间维度，从而实现对随时间变化的场景进行表示。基于 3D GS 的动态场景重建方法【93】–【95】、【103】、【118】–【123】、【174】–【178】通常可分为两大类。第一类方法利用额外的结构化信息，如空间 MLP 或网格（第 4.6 节）。例如，Yang 等人【94】首次提出了针对动态场景设计的可变形 3D 高斯分布。这些 3D 高斯分布在标准空间中学习，并可用于通过隐式变形场（实现为 MLP）来建模时空变形。GaGS【125】涉及对一组高斯分布进行体素化，然后使用稀疏卷积提取几何感知特征，这些特征随后用于变形学习。另一方面，第二类方法基于场景变化可以通过专门设计的渲染过程将其编码到 3D 高斯表示中（第 4.5 节）。例如，Luiten 等人【118】引入了动态 3D 高斯分布，通过保持 3D 高斯的属性在时间上不变，同时允许其位置和方向发生变化，从而建模动态场景。Yang 等人【93】设计了一种 4D 高斯表示，其中使用额外的属性表示 4D 旋转和球谐函数，以近似场景的时空体积。尽管在高斯层面建模动态和变形方面取得了显著进展，但仍迫切需要在物体层面探索运动建模，这可能为解决像伪影减少和精确捕捉长时间序列中的细粒度运动等常见挑战提供解决方案。

### 5.3 AI 生成内容（AIGC）

AIGC 是指由人工智能系统自主创建或显著修改的数字内容，特别是在计算机视觉、自然语言处理和机器学习领域。AIGC 的特点是能够模拟、扩展或增强人类生成的内容，推动从逼真图像合成到动态叙事创作等应用的实现。AIGC 的意义在于它在各个领域的变革潜力，包括娱乐、教育和技术发展【179】–【182】。它是数字内容创作发展中的关键元素，提供了可扩展、可定制且通常比传统方法更高效的替代方案。3D GS 的显式特性使其具有实时渲染能力和前所未有的控制与可编辑性，这使其在 AIGC 应用中高度相关。3D GS 的显式场景表示和可微渲染算法与 AIGC 在生成高保真、实时和可编辑内容方面的要求完全契合，尤其对于虚拟现实、互动媒体等应用至关重要。近期的研究有效地将 3D GS 与生成模型【126】–【129】、【183】–【207】、虚拟形象【23】【130】【133】【208】–【229】和场景编辑【90】–【92】、【102】【119】【121】【134】–【136】【230】–【239】等领域结合。例如，DreamGaussian【126】通过三步过程加速了从单视图图像生成逼真 3D 资产：基于扩散的生成高斯过程，接着是一个基于局部密度查询的高效算法用于从 3D 高斯分布中提取网格，最后是一个 UV 空间的细化阶段，以提高纹理细节。通过将 3D GS 与参数化的可变形面部模型结合，GaussianAvatars【214】在虚拟形象动画中提供了增强的保真度和灵活性，在新视角渲染和表情重现方面显著改善了现有方法。为了提高基于文本指令的编辑效果，Chen 等人【134】设计了一个语义追踪器来在训练过程中追踪编辑目标，而 Fang 等人【135】提出了提取与指令相关的兴趣区域。这些进展为多个工业应用提供了希望，包括数字资产化（与网格提取）、长视频生成（例如 Sora）等。

### 5.4 自动驾驶

自动驾驶旨在使车辆在没有人工干预的情况下进行导航和操作。这些车辆配备了一套传感器，包括摄像头、光学雷达（LiDAR）和雷达，结合先进的算法、机器学习模型和强大的计算能力【240】–【243】。其核心目标是感知环境、做出明智决策，并安全高效地执行操作【244】–【247】。自动驾驶车辆需要感知和解释周围环境，以安全导航。这涉及实时重建驾驶场景，准确识别静态和动态物体，并理解它们的空间关系和运动【248】–【250】。在动态驾驶场景中，由于其他车辆、行人或动物等运动物体的存在，环境持续变化【251】。准确地实时重建这些场景对安全导航至关重要，但由于涉及的元素的复杂性和可变性，这一任务具有挑战性。在自动驾驶中，3D GS 可以通过将数据点（例如来自 LiDAR 等传感器的数据）融合为一致的连续表示来重建场景。这对于处理数据点的不同密度以及确保平滑准确地重建场景中的静态背景和动态物体尤其有用。为了从稀疏传感器数据中重建复杂的 3D 场景，特别是在高速行驶和有移动物体的情况下，主流框架将城市/街道场景分为静态和动态元素，其中动态元素使用复合动态高斯图【137】、与语义标签结合的点云【138】或物理约束模型【139】进行建模。通过深入探索物理和语义感知的 3D GS（见第 7 节“物理和语义感知场景表示”），可以预期 3D GS 将理想地成为自动驾驶环境感知的基石。

### 5.5 内窥镜场景重建

外科 3D 重建是机器人辅助手术中的一个基础任务，旨在通过精确建模动态外科场景来增强术中导航、术前规划和教育模拟。近期的进展通过将前沿动态辐射场整合到这一领域，着眼于克服单视角视频重建的固有挑战——例如外科工具的遮挡以及在内窥镜探查的有限空间内视角稀疏性【252】–【254】。尽管取得了进展，仍然呼吁在组织变形性和拓扑变化方面的高保真度，并且对于更快渲染的迫切需求，以弥补对延迟敏感的应用中的实用性【140】–【142】。从内窥镜视频中重建可变形组织的即时性和精确性的结合，是推动机器人手术朝着减少患者创伤和增强现实/虚拟现实应用迈进的关键，最终有助于培养更直观的手术环境，并促进手术自动化和机器人技术的未来。与典型的动态场景重建相比，内窥镜场景重建面临独特的挑战，例如稀疏的训练数据，这是由于有限空间内相机的受限运动、工具遮挡导致的未观察区域和组织的明显非刚性变形。现有方法主要使用额外的深度引导来推测组织的几何形状【140】–【142】。例如，EndoGS【142】通过结合深度引导的监督与时空加权掩模和表面对齐正则化项，提高了 3D 组织渲染的质量和速度，同时解决了工具遮挡的问题。EndoGaussian【141】引入了两种新策略：用于密集初始化的整体高斯初始化和用于建模表面动态的时空高斯跟踪。Zhao 等人【143】认为这些方法存在重建不足的问题，并提出从频率角度缓解这一问题。此外，EndoGSLAM【116】和 Gaussian Pancake【144】为内窥镜场景设计了 SLAM 系统，并展示了显著的速度优势。需要注意的是，目前的工作主要集中在从单视角进行重建，这在外科应用中仍面临障碍。

### 5.6 大规模场景重建

大规模场景重建是自动驾驶、空中测绘和增强现实/虚拟现实等领域中的一个关键组成部分，要求既具有逼真的视觉质量，又具备实时渲染能力。在 3D GS 出现之前，通常采用基于 NeRF 的方法来完成这一任务，这些方法虽然对小型场景有效，但当扩展到较大的区域（例如超过 1.5 平方公里）时，往往在细节和渲染速度方面存在不足。尽管 3D GS 在 NeRF 的基础上展示了显著的优势，但将 3D GS 直接应用于大规模环境仍然面临重大挑战。3D GS 需要大量的高斯分布来保持大面积上的视觉质量，这会导致 GPU 内存需求过高，并在渲染时带来巨大的计算负担。例如，一个覆盖 2.7 平方公里的场景可能需要超过 2000 万个高斯分布，甚至最先进的硬件（如 NVIDIA A100 40GB 内存）也可能达到极限【146】。为了应对这些挑战，研究人员在两个关键领域取得了重大进展：

i) 训练：采用了分而治之的策略【145】–【148】，将大场景划分为多个独立的单元，便于对广阔环境进行并行优化。秉承这一思路，Zhao 等人【152】提出了 3D GS 训练的分布式实现。另一个挑战是在保持视觉质量的同时，由于大规模场景通常具有无纹理的表面，可能会妨碍高斯初始化和密度控制等优化的有效性（第 3.2 节）。提升优化算法是缓解这一问题的可行方案【44】【147】。

ii) 渲染：采用计算机图形学中的细节层次（LoD）技术已被证明具有重要作用。LoD 调整 3D 场景的复杂度，以平衡视觉质量和计算效率。目前的实现方法包括仅将必要的高斯分布输入光栅化器【147】，或者设计显式的 LoD 结构，如八叉树（Octree）【148】和层次结构【145】。此外，集成 LiDAR 等额外输入模态可以进一步增强重建过程【149】–【151】。大规模场景重建中的一个显著挑战是捕捉限制，这可以通过利用良好的先验（参见第 7 节“从大规模数据中学习物理先验”）来缓解。

## 6 性能比较

在本节中，我们通过展示几个之前讨论过的 3D GS 算法的性能，提供更多的实证证据。3D GS 在多个任务中的广泛应用，以及针对每个任务定制的算法设计，使得在单一任务或数据集上对所有 3D GS 算法进行统一比较变得不可行。因此，基于我们在第 5 节的分析，我们选择了几个 3D GS 领域内的代表性任务进行深入的性能评估。性能评分主要来自原始论文，除非另有说明。

### 6.1 性能基准测试：定位

SLAM 中的定位任务涉及确定机器人或设备在环境中的准确位置和方向，通常使用传感器数据。  
- **数据集**：Replica【255】数据集包含 18 个高度详细的 3D 室内场景。这些场景不仅在视觉上逼真，还提供了全面的数据，包括密集网格、高质量 HDR 纹理以及每个元素的详细语义信息。根据【256】的做法，使用了三组关于房间的序列和五组关于办公室的序列进行评估。  
- **基准算法**：为了进行性能比较，我们涉及了五个最新的基于 3D GS 的算法【104】–【107】、【113】和六个典型的 SLAM 方法【256】–【261】。  
- **评估指标**：绝对轨迹误差（ATE）的均方根误差（RMSE）是评估 SLAM 系统常用的指标【262】，它测量了整个轨迹中估计位置和真实位置之间欧几里得距离的均方根。
- **结果**: 如表 1 所示，近期基于 3D 高斯分布的定位算法相比现有的基于 NeRF 的密集视觉 SLAM 显示出明显的优势。例如，HFSLAM【113】相较于先前的最先进方法（SOTA）【260】，在轨迹误差上提高了约 50%，将误差从 0.52 厘米减少到 0.25 厘米。我们认为这一改进得益于为场景重建的密集且准确的 3D 高斯分布，这些高斯分布能够处理真实传感器的噪声。这表明，有效的场景表示能够提高定位任务的准确性。

> 表 1  
> Replica【255】上的定量定位结果（第 6.1 节），以绝对轨迹误差（ATE，单位：厘米）为评估标准。（前三名的得分分别用红色、蓝色和绿色标记。此说明适用于其他表格。）

![](assets/Pasted%20image%2020241127230819.png)

>Replica【255】上的定量渲染结果（第 6.2 节），以 PSNR、SSIM 和 LPIPS 为评估标准。FPS 的数据来自【106】。

![](assets/Pasted%20image%2020241127230903.png)

## 6.2 性能基准测试：静态场景

渲染的目标是将计算机可读的信息（例如场景中的 3D 物体）转化为基于像素的图像。本节重点评估静态场景中渲染结果的质量。

-  **数据集**：与第 6.1 节相同，使用 Replica【255】数据集进行性能比较。  
-  **基准算法**：为了进行性能比较，我们涉及了四篇近期将 3D 高斯分布引入系统的论文【104】–【107】以及三种密集 SLAM 方法【257】【258】【260】。  
- **评估指标**：使用峰值信噪比（PSNR）、结构相似性（SSIM）【263】和学习感知图像补丁相似性（LPIPS）【264】来衡量 RGB 渲染性能。
- **结果**: 表 2 显示，基于 3D 高斯分布的系统通常优于这三种密集 SLAM 对手。例如，Gaussian-SLAM【107】建立了新的最先进方法（SOTA），并显著超越了之前的方法。与 Point-SLAM【260】相比，GSSLAM【106】在实现非常有竞争力的精度时速度快了约 578 倍。与依赖于深度信息（如深度引导光线采样）来合成新视角的之前方法【260】相比，基于 3D GS 的系统不再需要这些操作，从而允许任何视角进行高保真渲染。

## 6.3 性能基准测试：动态场景

本节重点评估动态场景中的渲染质量。

- **数据集**：D-NeRF【170】数据集包括每个视频包含 50 至 200 帧，来自独特视角的捕捉。该数据集包含合成的、动画化的物体，出现在复杂场景中，且具有非朗伯材质。每个场景提供 50 至 200 张训练图像和 20 张测试图像，旨在评估单目设置下的模型。  
- **基准算法**：为了进行性能比较，我们涉及了四篇近期使用 3D GS 模型动态场景的论文【93】【95】【119】【176】以及六种基于 NeRF 的方法【33】【170】【173】【265】–【267】。  
- **评估指标**：使用与第 6.2 节相同的指标，即 PSNR、SSIM【263】和 LPIPS【264】进行评估。
- **结果**: 从表 3 可以看出，基于 3D GS 的方法明显优于现有的最先进方法（SOTA）。3D GS 的静态版本【10】未能成功重建动态场景，导致性能显著下降。通过建模动态性，D-3DGS【94】在 PSNR 上超越了最先进方法 FFDNeRF【173】6.83 dB。这些结果表明，引入额外属性或结构化信息以建模高斯分布的变形，从而模拟场景动态是有效的。

> 表 3  
> D-NeRF【170】上的定量渲染结果（第 6.3 节），以 PSNR、SSIM 和 LPIPS 为评估标准。* 表示数据来源于【95】。

![](assets/Pasted%20image%2020241127231022.png)

> 表 4  
> nuScenes【243】上的定量渲染结果（第 6.4 节），以 PSNR、SSIM 和 LPIPS 为评估标准。* 表示数据来源于【137】。

![](assets/Pasted%20image%2020241127231029.png)

> 表 5  
> ZJU-MoCap【272】上的定量虚拟形象建模结果（第 6.5 节），以 PSNR、SSIM 和 LPIPS* 为评估标准。非高斯方法的得分和 FPS 数据分别来源于【210】和【224】。† 表示原论文报告值的平均值。

![](assets/Pasted%20image%2020241127231035.png)

## 6.4 性能基准测试：驾驶场景

本节重点评估驾驶场景中的渲染质量，这对于自动驾驶至关重要。

-  **数据集**：nuScenes【243】数据集是一个全面的自动驾驶数据集，包含 1000 个驾驶场景，这些场景通过多种传感器捕捉，包括六个摄像头、一个 LiDAR、五个雷达、GPS 和 IMU。该数据集为 23 个物体类别提供了详细的标注和 3D 边界框。六个具有挑战性的场景被用于评估【137】。  
- **基准算法**：为了进行性能比较，我们涉及了一个基于 3D GS 的方法【137】，以及六种基于 NeRF 的方法【8】【9】【268】–【271】。  
- **评估指标**：使用 PSNR、SSIM【263】和 LPIPS【264】进行评估。
- **结果**: 表 4 中的结果表明，基于 3D GS 的方法在所有评估指标上显著超越了基于 NeRF 的方法。例如，DrivingGaussian-L【137】在 PSNR 上超越了 S-NeRF【270】3.31 dB。这表明，3D 高斯分布能够利用多传感器信息来捕捉驾驶场景中的动态物体，尤其是快速移动的物体。

## 6.5 性能基准测试：人类虚拟形象建模

人类虚拟形象建模旨在从给定的多视角视频中创建人类虚拟形象模型。
- **数据集**：ZJU-MoCap【272】数据集是一个广泛使用的人类建模基准，使用 23 台同步摄像机以 1024×1024 分辨率捕捉。按照【273】的方法，评估中使用了六个对象（即 377、386、387、392、393 和 394）。
- **基准算法**：为了进行性能比较，我们涉及了四篇近期使用 3D GS 模型人类虚拟形象的论文【210】【212】【221】【224】以及六种人类渲染方法【272】–【277】。
- **评估指标**：使用 PSNR、SSIM【263】和 LPIPS*【264】来衡量 RGB 渲染性能。这里，LPIPS* 等于 LPIPS × 1000。
- **结果**: 表 5 展示了人类虚拟形象建模领域顶尖解决方案的数值结果。我们观察到，将 3D GS 引入框架后，渲染质量和速度均有显著提升。例如，GART【210】在 PSNR 上超越了当前的最先进方法 Instant-NVR【277】1.21 dB。需要注意的是，Human101【224】在实现非常有竞争力的精度时，比 Instant-NVR【277】快了大约 68 倍。考虑到增强的保真度、推理速度和可编辑性，基于 3D GS 的虚拟形象建模可能会彻底改变 3D 动画、互动游戏等领域。

## 6.6 性能基准测试：外科场景

从内窥镜视频进行 3D 重建对机器人辅助手术中的微创手术至关重要，它能够支持术前规划、通过 AR/VR 模拟进行训练，并为术中提供指导。
- **数据集**：EndoNeRF【252】数据集提供了专门的立体摄像头捕捉数据，包括两个体内前列腺切除术的样本。该数据集旨在代表真实世界中的外科复杂性，包括工具遮挡和明显非刚性变形等具有挑战性的场景。
- **基准算法**：为了进行性能比较，我们涉及了三篇近期使用 3D 高斯重建动态内窥镜场景的论文【140】–【142】，以及三种基于 NeRF 的外科重建方法【252】–【254】。
- **评估指标**：使用 PSNR、SSIM【263】和 LPIPS【264】进行评估。此外，还报告了 GPU 内存的需求。
- **结果**: 表 6 显示，引入 3D 高斯的显式表示带来了显著的改进。例如，EndoGaussian【141】在所有指标上超越了一个强有力的基准，LerPlane-32k【253】。特别地，EndoGaussian 在速度上大约提高了 224 倍，同时仅消耗了 10% 的 GPU 资源。这些令人印象深刻的结果证明了基于高斯分布（GS）的方法的高效性，这些方法不仅加速了处理速度，还最小化了 GPU 负载，从而减轻了硬件的需求。这样的特性对于现实世界中的外科应用部署至关重要，其中优化资源使用可能是实际应用可行性的关键决定因素。

> 表 6  
> EndoNeRF【252】上的定量外科 3D 重建结果（第 6.6 节），以 PSNR、SSIM 和 LPIPS 为评估标准。非高斯方法的得分、FPS 和 GPU 使用（内存）数据来源于【141】。* 表示数据来源于【137】。† 表示原论文报告值的平均值。

![](assets/Pasted%20image%2020241127231225.png)

## 7 未来研究方向

尽管 3D GS 的后续研究成果令人印象深刻，并且这些领域已经或可能被 3D GS 所颠覆，但普遍认为 3D GS 仍然有相当大的改进空间。

• **物理和语义感知的场景表示**  
作为一种新的显式场景表示技术，3D 高斯分布提供了超越单纯增强新视角合成的变革潜力。通过设计物理和语义感知的 3D GS 系统，它有潜力为场景重建和理解的同步进展铺平道路。这将有望在多个领域和下游应用中带来革命性的变化。例如，结合对象的一般形状等先验知识，可以减少对大量训练视角的需求【47】【48】，同时改进几何形状/表面重建【77】【100】。评估场景表示的一个关键指标是其生成场景的真实感，包括几何、纹理和光照保真度的挑战【66】【121】【134】。通过将物理原理和语义信息融入 3D GS 框架中，可以预期真实感将得到增强，从而促进动态建模【21】【278】、编辑【90】【92】、生成【126】【127】等工作。总之，追求这种先进且多功能的场景表示为计算创造力和多个领域的实际应用开辟了新的创新可能性。

• **从大规模数据中学习物理先验**  
在探索物理和语义感知的场景表示潜力时，利用大规模数据集来学习物理先验成为一个有前景的方向。其目标是对真实世界数据中固有的物理属性和动态进行建模，并将其转化为可应用于各种领域（如机器人技术和视觉效果）的可操作见解。建立一个学习框架，用于提取这些物理先验，使其能够在少量数据输入下快速适应新的物体和环境。此外，集成物理先验不仅可以提高生成场景的准确性和真实感，还能增强其交互性和动态特性。这在 AR/VR 环境中特别有价值，因为用户与虚拟物体进行互动时，这些物体的行为应与现实世界中的物体一致。然而，现有的关于从广泛的 2D 和 3D 数据集中捕捉和提炼基于物理的知识的工作仍然较少。相关领域中的重要努力包括用于弹性物体建模的 Spring-Mass 3D 高斯分布【279】和基于多视角立体的可泛化高斯表示【280】。进一步探索真实到模拟（real2sim）和模拟到真实（sim2real）可能为该领域的进展提供可行的路径。

• **3D GS 在机器人中的应用**  
在机器人领域，尤其是涉及类似人类操作物体的任务时，机器人的需求日益增加，需要以更直观和动态的方式导航和操作其环境。这一需求源于希望在真实世界中部署智能机器人，在这些环境中，它们经常面临新的和不熟悉的任务。传统的机器人操作方法主要依赖通过语义表示来理解环境，即识别物体及其属性。然而，这些方法往往忽略了物体如何随时间移动和互动的重要性，而这对于按人类意图完成任务至关重要。例如，设想一个机器人根据口头指令堆叠积木。仅使用语义表示，机器人可能会识别这些积木，但如果它不理解积木应该如何相对地位移并随时间变化，就可能无法完成堆叠任务。这种理解的差距可能导致在需要与多个物体互动或在动态环境中导航时任务执行失败。由于其显式性质，3D GS 可以超越仅对环境进行语义和结构分析的应用，它还涵盖了动态方面，提供了对场景如何演变和物体如何随时间互动的全面理解。这对于执行导航和操作周围环境的机器人至关重要。尽管基于高斯分布的世界模型【281】【282】和强化学习【283】【284】等初步努力很有前景，但它们仅代表了这一领域的初步探索。预计该领域的进一步研究将增强机器人在执行需要理解物理空间和其内在时间变化的任务时的能力。

• **使用 3D GS 建模物体的内部结构**  
尽管 3D GS 能够生成高度逼真的渲染图，但在当前的 GS 框架中，建模物体（例如计算机断层扫描中的扫描物体）的内部结构仍然是一个显著挑战。由于 splatting 和密度控制过程，当前的 3D 高斯表示是无序的，无法与物体的实际内部结构很好地对齐。此外，许多应用更倾向于将物体表示为体积（例如计算机断层扫描）。然而，3D GS 的无序性使得体积建模变得特别困难。Li 等人【285】使用带有密度控制的 3D 高斯分布作为体积表示的基础，且未涉及 splatting 过程。X-Gaussian【286】虽然涉及了 splatting 过程以加速训练和推理，但无法生成体积表示。使用 3D GS 建模物体的内部结构仍然是一个未解的问题，值得进一步探索。

• **3D GS 在自动驾驶模拟中的应用**  
收集真实世界的自动驾驶数据集既昂贵又具有后勤挑战性，但对于训练有效的基于图像的感知系统至关重要。为了缓解这些问题，模拟作为一种成本效益较高的替代方案应运而生，它能够在多样化的环境中生成合成数据集。然而，开发能够产生逼真且多样的合成数据的模拟器面临诸多挑战。这些挑战包括实现高水平的逼真性、适应各种控制方法以及准确模拟不同的光照条件。尽管早期在使用 3D GS 重建城市/街道场景方面的工作【137】–【139】取得了一定进展，但这仅仅是充分发挥 3D GS 能力的冰山一角。仍然有许多关键方面需要探索，例如集成用户定义的物体模型、建模物理感知的场景变化（例如，车辆轮子的旋转）以及增强可控性和真实感（例如，在不同光照条件下）。

• **赋予 3D GS 更多的可能性**  
尽管 3D GS 展示了巨大的潜力，但其应用的全部范围仍未被充分挖掘。一条有前景的探索方向是为 3D 高斯分布增添附加属性（例如第 4.5 节提到的语言和时空属性），并引入结构化信息（例如第 4.6 节提到的空间 MLP 和网格），以针对特定应用进行定制。此外，最近的研究开始揭示 3D GS 在多个领域中的能力，例如点云配准【287】、图像表示与压缩【60】以及流体合成【288】。这些发现为跨学科的学者提供了进一步探索 3D GS 的重要机会。

## 8 结论

据我们所知，本综述首次全面概述了 3D GS，这一突破性技术正在革新显式辐射场、计算机图形学和计算机视觉领域。它清晰地描绘了从传统的基于 NeRF 的方法到 3D GS 的范式转变，突出了 3D GS 在实时渲染和增强可编辑性方面的优势。通过深入分析和广泛的定量研究，我们展示了 3D GS 在实际应用中的优越性，特别是在对延迟极为敏感的应用中。我们提供了关于该领域原理、未来研究方向以及未解挑战的洞见。总体而言，3D GS 是一项具有变革性技术，预计将在未来 3D 重建和表示领域的进展中发挥重要影响。本综述旨在成为该领域的基础性资源，推动这一快速发展的领域进一步探索和进步。
