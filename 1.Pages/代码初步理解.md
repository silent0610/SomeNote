---
Type:
  - Page
aliases: 
Status:
tags: 
modifiedDate: æ˜ŸæœŸä¸€, äº”æœˆ 26æ—¥ 2025, 8:27:35 æ™šä¸Š
---
[æœ¬ç§‘æ¯•ä¸šè®¾è®¡](æœ¬ç§‘æ¯•ä¸šè®¾è®¡.md)

```dataview
list
filter(file.outlinks, (x)=>!contains(string(x),"assets"))
FROM ""
where contains(file.name,this.file.name)
```

[æœ¬ç§‘æ¯•ä¸šè®¾è®¡](æœ¬ç§‘æ¯•ä¸šè®¾è®¡.md)

## Llama

### æ–‡ä»¶ä½œç”¨

[mindformers/models/llama Â· MindSpore/mindformers - ç äº‘ - å¼€æºä¸­å›½ (gitee.com)](https://gitee.com/mindspore/mindformers/tree/dev/mindformers/models/llama)

```
llama
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ convert_weight.py         # æƒé‡è½¬æ¢è„šæœ¬
    â”œâ”€â”€ llama.py                  # æ¨¡å‹å®ç°
    â”œâ”€â”€ llama_config.py           # æ¨¡å‹é…ç½®é¡¹
    â”œâ”€â”€ llama_layer.py            # llamaç½‘ç»œå±‚å®šä¹‰
    â”œâ”€â”€ llama_processor.py        # llamaé¢„å¤„ç†
    â”œâ”€â”€ llama_tokenizer.py        # tokenizer
    â””â”€â”€ llama_transformer.py      # transformerå±‚å®ç°
```

#### llama.py

##### `def layer_compute_dtype`

è®¾ç½®å¹¶è¡Œå¤„ç†ä¸­çš„æ•°æ®ç±»å‹

> [!NOTE]-  
> è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º `layer_compute_dtype` çš„å‡½æ•°ï¼Œå®ƒç”¨äºè®¡ç®—å¹¶è®¾ç½®ç¥ç»ç½‘ç»œä¸­æ¯ä¸€å±‚çš„æ•°æ®ç±»å‹ã€‚è¿™ä¸ªå‡½æ•°æ¥æ”¶äº”ä¸ªå‚æ•°ï¼š`layer`ï¼Œ`layer_id`ï¼Œ`offset`ï¼Œ`parallel_config` å’Œ `n_layers`ã€‚
> 
> é¦–å…ˆï¼Œå‡½æ•°è®¡ç®—äº†`pp_dis`ï¼Œè¿™æ˜¯ä¸€ä¸ªè¡¨ç¤ºå¹¶è¡Œå¤„ç†çš„é˜¶æ®µæ•°çš„å€¼ã€‚ç„¶åï¼Œå®ƒæ£€æŸ¥`offset`çš„ç±»å‹ã€‚å¦‚æœ`offset`æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œé‚£ä¹ˆå®ƒä¼šæ£€æŸ¥åˆ—è¡¨çš„é•¿åº¦æ˜¯å¦ä¸`pipeline_stage`ç›¸ç­‰ã€‚å¦‚æœä¸ç­‰ï¼Œå®ƒä¼šæŠ›å‡ºä¸€ä¸ª`ValueError`ã€‚å¦‚æœ`offset`æ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œé‚£ä¹ˆå®ƒä¼šç›´æ¥è¢«èµ‹å€¼ç»™`offset_layer`ã€‚å¦‚æœ`offset`æ—¢ä¸æ˜¯åˆ—è¡¨ä¹Ÿä¸æ˜¯æ•´æ•°ï¼Œé‚£ä¹ˆå®ƒä¼šæŠ›å‡ºä¸€ä¸ª`TypeError`ã€‚
> 
> æ¥ä¸‹æ¥ï¼Œå‡½æ•°è®¡ç®—`pp_id`ï¼Œè¿™æ˜¯ä¸€ä¸ªè¡¨ç¤ºå½“å‰å±‚åœ¨å¹¶è¡Œå¤„ç†é˜¶æ®µä¸­çš„ä½ç½®çš„å€¼ã€‚ç„¶åï¼Œå®ƒå°†`pp_id`èµ‹å€¼ç»™`layer.pipeline_stage`ã€‚
> 
> ç„¶åï¼Œå‡½æ•°è®¡ç®—`dis`ï¼Œè¿™æ˜¯ä¸€ä¸ªè¡¨ç¤ºæ¢¯åº¦èšåˆç»„çš„æ•°é‡çš„å€¼ã€‚å¦‚æœ`pipeline_stage`å¤§äº1ï¼Œé‚£ä¹ˆå®ƒä¼šè°ƒç”¨`layer.set_comm_fusion(2)`ã€‚å¦åˆ™ï¼Œå®ƒä¼šè°ƒç”¨`layer.set_comm_fusion(int((layer_id + offset_layer) / dis) + 1)`ã€‚
> 
> æœ€åï¼Œå‡½æ•°æ£€æŸ¥`parallel_config.recompute`çš„ç±»å‹ã€‚å¦‚æœå®ƒæ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œé‚£ä¹ˆå¦‚æœå®ƒä¸ºçœŸå¹¶ä¸”`select_recompute`ä¸ºå‡ï¼Œé‚£ä¹ˆå®ƒä¼šè°ƒç”¨`layer.recompute()`ã€‚å¦‚æœ`parallel_config.recompute`ä¸æ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œé‚£ä¹ˆå¦‚æœ`parallel_config.recompute.recompute`ä¸ºçœŸå¹¶ä¸”`select_recompute`ä¸ºå‡ï¼Œé‚£ä¹ˆå®ƒä¼šè°ƒç”¨`layer.recompute(recompute_slice_activation=parallel_config.recompute.recompute_slice_activation)`ã€‚

æ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªå‡½æ•°çš„ç›®çš„æ˜¯æ ¹æ®è¾“å…¥çš„å‚æ•°æ¥è®¾ç½®ç¥ç»ç½‘ç»œä¸­æ¯ä¸€å±‚çš„æ•°æ®ç±»å‹å’Œå¹¶è¡Œå¤„ç†çš„é˜¶æ®µã€‚

##### `LlamaModel`

æ¨¡å‹å…·ä½“æ„å»º

#### llama_transformer.py

##### `LLamaAttention`

è¿™é‡ŒåŸºæœ¬ä¸Šå’ŒåŸå§‹ attention ä¸€æ ·ï¼ŒåŒºåˆ«åœ¨äºä½¿ç”¨äº† Rope æ—‹è½¬ä½ç½®ç¼–ç ã€‚  
softmax å¤„ä½¿ç”¨çš„æ˜¯ float32ç¼–ç 

##### `LlamaDecodeLayer`

è¿™é‡Œæµç¨‹æ˜¯å…ˆè¿›è¡Œ LayerNorm--->ä½¿ç”¨ `LlamaRMSNorm` å‡½æ•°  
æ¥ç€è¿›è¡Œ attention--->ä½¿ç”¨ `LlamaAttention`  
åŸå§‹è¾“å…¥+attentionè¾“å‡º=è¾“å‡º1  
è¿›è¡Œ LayerNorm--->ä½¿ç”¨ `LlamaRMSNorm` å‡½æ•°  
è¿›è¡Œå…¨è¿æ¥æ“ä½œ--->LlamaMLP(å¤šå±‚æ„ŸçŸ¥æœº) è¿™é‡Œæ˜¯ `LlamaFeedForward`  
è¾“å‡º1+MLPè¾“å‡º=è¾“å‡º2  
è¿™é‡Œå’ŒåŸå§‹transformersçš„decoderåŒºåˆ«æ˜¯åœ¨è¾“å…¥è¿›è¡ŒLayerNormæ“ä½œã€‚

![300](assets/ä»£ç åˆæ­¥ç†è§£.png)

#### llama_layer.py

##### `LlamaFeedForward`

MLP å¤šå±‚æ„ŸçŸ¥æœº  
å…¨è¿æ¥

è¿™é‡Œç”¨äº†3ä¸ªçº¿æ€§å±‚å’Œä¸€ä¸ªæ¿€æ´»å‡½æ•° actï¼Œçº¿æ€§å±‚åˆ†åˆ«æ˜¯ gate_proj(G)ï¼Œup_proj(U)ï¼Œdown_proj(D)ï¼Œç»´åº¦åˆ†åˆ«æ˜¯[h,i],[h,i],[i,h]ï¼Œå‡æ—  biasï¼Œè®¡ç®—æ–¹å¼ä¸º D(act(GX) * UX)

è¿™é‡ŒåŒºåˆ«äºåŸå§‹transformersçš„mlpï¼ŒåŸå§‹æ˜¯ç”±ä¸¤ä¸ªçº¿æ€§å±‚ç»„æˆï¼Œç¬¬ä¸€ä¸ªçº¿æ€§å±‚å…ˆå°†ç»´åº¦æ˜ å°„ä¸º4hç»´ï¼Œç¬¬äºŒä¸ªçº¿æ€§å±‚å†æ˜ å°„å›hç»´ï¼Œæ¥ç€è¿›è¡Œæ¿€æ´»å‡½æ•°æ“ä½œã€‚è€Œllamaåˆ™æ˜¯å°†åŸæœ‰4hå˜æˆä¸€ä¸ªå¸¸é‡ä½œä¸ºè¾“å…¥ï¼Œä¸”è®¡ç®—æ–¹å¼ä¹Ÿç•¥æœ‰ä¸åŒã€‚è¿™é‡ŒçŒœæƒ³æ˜¯å› ä¸ºåŸå…ˆhä¸ç®—å¤§ï¼Œæ‰€ä»¥4hä¹Ÿåœ¨ä¸€ä¸ªæ¥å—çš„èŒƒå›´ï¼Œä½†æ˜¯éšç€å¤§æ¨¡å‹hå‚æ•°çš„å¢å¤§ï¼Œ4hä¹Ÿä¼šå‘ˆçº¿æ€§å¢åŠ ï¼Œæ‰€ä»¥è¿™é‡Œè®¾äº†ä¸€ä¸ªå¸¸é‡ã€‚

##### `LlamaSiLU`

æ¿€æ´»å‡½æ•° SiLU å®ç°

##### `FreqsMgr`

ä½ç½®ç¼–ç  é¢‘ç‡è®¡ç®—ï¼Ÿ

##### `LlamaRotaryEmbedding`

æ—‹è½¬ä½ç½®ç¼–ç çš„ä¸»è¦å®ç° ^990869

##### `LlamaEmbedding`

ç¼–ç å±‚

##### `LlamaRMSNorm`

RMS æ ‡å‡†åŒ–

##### `LlamaFeedForward`

MLP å¤šå±‚æ„ŸçŸ¥æœº  
å…¨è¿æ¥

##### `CausalMask`

æ©è”½

#### llama_processor.py

##### `LlamaProcessor`

å¯èƒ½æ˜¯ç”¨äºå¤„ç† Llama æ¨¡å‹çš„è¾“å…¥çš„  
åˆ†è¯ç­‰

---

## GENRE

æç¤ºé—­æºLLMsè¿›è¡ŒåŸºäºå†…å®¹çš„æ¨è

### news_summarizer.py

ç”Ÿæˆå†…å®¹æ‘˜è¦  
ç¡®å®šå¥½æç¤ºè¯  
åŸæ ¼å¼ï¼š

```
title {title}
abstract {abstract}
category {category}
subcategory {subcategory}
```

è¦æ±‚çš„æ ¼å¼ï¼š

```
newtitle {newtitle}
```

æ•´ä½“æµç¨‹å¦‚ä¸‹

### user_profiler_mind.py

ç”¨æˆ·è‚–åƒï¼ˆæ ¹æ®æµè§ˆè®°å½•é¢„æµ‹ç”¨æˆ·å…´è¶£å’ŒåŒºåŸŸï¼‰

è¾“å…¥æŸä¸ªç”¨æˆ·çš„æµè§ˆå†å²

```
(1) {news title}
...
(n) {news title}
```

è¾“å‡ºè¯¥ç”¨æˆ·çš„åŒºåŸŸå’Œ

```
[topics]
- topic1
- topic2
...
[region] (optional)
- region1
- region2
...
```

### personalized_news_generator.py

ç”Ÿæˆç”¨æˆ·æ„Ÿå…´è¶£çš„æ–°é—»  
è¾“å…¥ä¸€ç³»åˆ—ç”¨æˆ·æ„Ÿå…´è¶£çš„ç±»åˆ«å’Œæ ‡é¢˜

```
(1) (the category of the first news) the title of the first news
...
(n) (the category of the n-th news) the title of the n-th news
```

è¾“å‡ºæ–°çš„ã€ç”¨æˆ·å¯èƒ½æ„Ÿå…´è¶£çš„æ–°é—»

```
{"title": <title>, "abstract": <news abstract>, "category": <news category>}
```

å…¶å®ƒæ¯”å¦‚GoodReadså¤§åŒå°å¼‚

### Processor

prompter.py  
è¯»å–æ•°æ®é›†ï¼Œå°†å…¶è½¬åŒ–ä¸ºéœ€è¦çš„æ ¼å¼

> [!Note]-  
> è¿™æ®µPythonä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º`MindPrompter`çš„ç±»ï¼Œå®ƒå¯èƒ½æ˜¯ç”¨äºå¤„ç†æ–°é—»æ•°æ®çš„ã€‚
> 
> åœ¨`__init__`æ–¹æ³•ä¸­ï¼Œå®ƒæ¥å—ä¸€ä¸ªå‚æ•°`data_path`ï¼Œè¿™æ˜¯æ•°æ®æ–‡ä»¶çš„è·¯å¾„ã€‚ç„¶åï¼Œå®ƒè¯»å–`data_path`æŒ‡å‘çš„æ–‡ä»¶ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨`self.news_df`ä¸­ã€‚å®ƒè¿˜å®šä¹‰äº†ä¸€ä¸ªå­—å…¸`self.keys`ï¼Œè¿™ä¸ªå­—å…¸æ˜ å°„äº†æ–°é—»çš„å„ä¸ªå±æ€§åˆ°å®ƒä»¬åœ¨æ•°æ®æ–‡ä»¶ä¸­çš„åˆ—åã€‚
> 
> `stringify`æ–¹æ³•å°†`self.news_df`ä¸­çš„æ¯ä¸€è¡Œè½¬æ¢ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå¹¶å°†è¿™äº›å­—ç¬¦ä¸²å­˜å‚¨åœ¨`self._news_list`ä¸­ã€‚å­—ç¬¦ä¸²çš„æ ¼å¼æ˜¯`[key] value`ï¼Œå…¶ä¸­`key`æ˜¯æ–°é—»çš„å±æ€§ï¼Œ`value`æ˜¯è¯¥å±æ€§çš„å€¼ã€‚
> 
> `get_news_dict`æ–¹æ³•å°†`self.news_df`ä¸­çš„æ¯ä¸€è¡Œè½¬æ¢ä¸ºä¸€ä¸ªå­—å…¸é¡¹ï¼Œå¹¶å°†è¿™äº›å­—å…¸é¡¹å­˜å‚¨åœ¨`self._news_dict`ä¸­ã€‚å­—å…¸çš„é”®æ˜¯æ–°é—»çš„IDï¼ˆ'nid'ï¼‰ï¼Œå€¼æ˜¯æ–°é—»çš„æ ‡é¢˜ï¼ˆ'title'ï¼‰ã€‚

---

## DIRE

### æ¨¡å‹ç»“æ„

#### Embedding åµŒå…¥å±‚

**æ–‡æœ¬å¤„ç†**  
åœ¨æ–‡æœ¬åºåˆ—å¼€å¤´åŠ å…¥æ ‡ç­¾\<news article>åœ¨æ¯ä¸ªç‰¹å¾å‰åŠ å…¥æ ‡ç­¾\<feature\>ä»¥è¡¨ç¤ºç‰¹å¾ï¼Œéšåä½¿ç”¨é€šç”¨apiåˆ†è¯  
æ¯”å¦‚

>"news article:[title] Here's Exactly When To Cook Every Dish For anksgiving Dinner[abstract] Time out turkey day down to the minute.[category] foodanddrink"

**åˆ†è¯**tokenizer  
ä½¿ç”¨å­—èŠ‚å¯¹ç¼–ç ï¼ˆBPEï¼‰ç®—æ³•å¯¹æ•°æ®è¿›è¡Œåˆ†è¯ï¼Œä½¿ç”¨ SentencePiece çš„å®ç°ã€‚å¯è°ƒç”¨api

**ç¼–ç **  
[æ—‹è½¬ä½ç½®ç¼–ç ](#^990869)

#### è§£ç å±‚

å°±æ˜¯Llama Decoderçš„åºåˆ—

#### æ³¨æ„åŠ›èåˆå±‚

æ¨¡å‹çš„æœ€åä¸€éƒ¨åˆ†  
åŒ…æ‹¬çº¿æ€§å±‚å’ŒåŠ æ€§æ³¨æ„åŠ›æœºåˆ¶ä¸¤éƒ¨åˆ†

##### çº¿æ€§å±‚

çº¿æ€§å˜æ¢  
![](assets/ä»£ç åˆæ­¥ç†è§£-1.png)  
é™ç»´  
![](assets/ä»£ç åˆæ­¥ç†è§£-2.png)

##### åŠ æ€§æ³¨æ„åŠ›æœºåˆ¶

ç¤ºæ„å›¾  
$z = ğ´ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘œğ‘› (Z) âˆˆ R^ğ‘‘$  
å‹ç¼©ç‰¹å¾ï¼Œè¡¨ç¤ºæœ€åçš„å‘é‡ï¼ˆï¼‰  
![](assets/ä»£ç åˆæ­¥ç†è§£-3.png)

```python
class AdditiveAttention(nn.Module):
	def __init__(self, embed_dim, hidden_size):
		super().__init__()

		self.embed_dim = embed_dim
		self.hidden_size = hidden_size

		self.encoder = nn.Sequential(
			nn.Linear(self.embed_dim, self.hidden_size),
			nn.Tanh(),
			nn.Linear(self.hidden_size, 1, bias=False),
		)

	def forward(self, inputs: torch.Tensor, attention_mask: torch.Tensor = None) -> [torch.Tensor, torch.Tensor]:
		"""

		@param inputs: [B, L, D]
		@param attention_mask: [B, L]
		@return: [B, D]
		"""

		attention = self.encoder(inputs).squeeze(-1)  # [B, L]
		if attention_mask is None:
			attention = torch.exp(attention)  # [B, L]
		else:
			attention = torch.exp(attention) * attention_mask  # [B, L]
		attention_weight = attention / (torch.sum(attention, dim=-1, keepdim=True) + torch.finfo(torch.float32).eps)  # [B, L]

		return torch.sum(inputs * attention_weight.unsqueeze(-1), dim=1)  # [B, D]
```

>[!note]-  
>è¿™æ˜¯ä¸€ä¸ªå®ç°åŠ æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAdditive Attentionï¼‰çš„ PyTorch æ¨¡å—ã€‚ä»¥ä¸‹æ˜¯å¯¹ä»£ç çš„è¯¦ç»†è§£é‡Šï¼š
> 
> 1. `__init__` æ–¹æ³•ï¼šåœ¨åˆå§‹åŒ–è¿‡ç¨‹ä¸­ï¼Œå®šä¹‰äº†æ¨¡å—çš„åŸºæœ¬å‚æ•°ï¼ŒåŒ…æ‹¬è¾“å…¥åµŒå…¥ç»´åº¦ `embed_dim` å’Œéšè—å±‚å¤§å° `hidden_size`ã€‚ç„¶åï¼Œæ„å»ºäº†ä¸€ä¸ªç®€å•çš„åºåˆ—æ¨¡å‹ `encoder`ï¼Œè¯¥æ¨¡å‹åŒ…æ‹¬ä¸¤ä¸ªçº¿æ€§å±‚å’Œä¸€ä¸ª Tanh æ¿€æ´»å‡½æ•°ã€‚ç¬¬ä¸€ä¸ªçº¿æ€§å±‚å°†è¾“å…¥ç»´åº¦ä¸º `embed_dim` çš„å¼ é‡æ˜ å°„åˆ°ç»´åº¦ä¸º `hidden_size`ï¼Œç„¶ååº”ç”¨ Tanh æ¿€æ´»å‡½æ•°ï¼Œæœ€åé€šè¿‡ç¬¬äºŒä¸ªçº¿æ€§å±‚å°†å…¶æ˜ å°„åˆ°ç»´åº¦ä¸º 1ï¼Œå¾—åˆ°ä¸€ä¸ªæ ‡é‡å€¼ã€‚
> 
> 2. `forward` æ–¹æ³•ï¼šè¿™æ˜¯æ¨¡å—çš„å‰å‘ä¼ æ’­å‡½æ•°ã€‚æ¥æ”¶ä¸¤ä¸ªè¾“å…¥å‚æ•°ï¼Œ`inputs` å’Œ `attention_mask`ã€‚`inputs` æ˜¯å½¢çŠ¶ä¸º `[B, L, D]` çš„è¾“å…¥å¼ é‡ï¼Œè¡¨ç¤ºæ‰¹æ¬¡å¤§å°ï¼ˆBï¼‰ã€åºåˆ—é•¿åº¦ï¼ˆLï¼‰å’Œè¾“å…¥åµŒå…¥ç»´åº¦ï¼ˆDï¼‰ã€‚`attention_mask` æ˜¯ä¸€ä¸ªå¯é€‰çš„å½¢çŠ¶ä¸º `[B, L]` çš„æ³¨æ„åŠ›æ©ç ã€‚
> 
>    - `attention = self.encoder(inputs).squeeze(-1)`: é€šè¿‡å¯¹è¾“å…¥ `inputs` åº”ç”¨åºåˆ—æ¨¡å‹ `self.encoder` å¾—åˆ°ä¸€ä¸ªå½¢çŠ¶ä¸º `[B, L, 1]` çš„å¼ é‡ï¼Œç„¶åä½¿ç”¨ `squeeze(-1)` æ“ä½œå»é™¤æœ€åä¸€ä¸ªç»´åº¦ï¼Œå¾—åˆ°å½¢çŠ¶ä¸º `[B, L]` çš„æ³¨æ„åŠ›å¼ é‡ã€‚
> 
>    - æ³¨æ„åŠ›æƒé‡è®¡ç®—ï¼š
>       - å¦‚æœ `attention_mask` ä¸º Noneï¼Œåˆ™åº”ç”¨æŒ‡æ•°å‡½æ•°ï¼Œå³ `attention = torch.exp(attention)`ã€‚
>       - å¦‚æœæä¾›äº† `attention_mask`ï¼Œåˆ™å°†å…¶ä¸æ³¨æ„åŠ›å¼ é‡ç›¸ä¹˜ï¼Œå³ `attention = torch.exp(attention) * attention_mask`ã€‚è¿™æ˜¯ä¸ºäº†åœ¨è®¡ç®—æ³¨æ„åŠ›æƒé‡æ—¶åº”ç”¨æ©ç ã€‚
> 
>    - è®¡ç®—æ³¨æ„åŠ›æƒé‡å½’ä¸€åŒ–ï¼šé€šè¿‡é™¤ä»¥æ³¨æ„åŠ›å¼ é‡çš„æ€»å’Œï¼Œå¹¶æ·»åŠ ä¸€ä¸ªå°çš„ epsilon é¿å…é™¤é›¶é”™è¯¯ï¼Œå¾—åˆ°å½¢çŠ¶ä¸º `[B, L]` çš„æ³¨æ„åŠ›æƒé‡ `attention_weight`ã€‚
> 
>    - æœ€ç»ˆè¾“å‡ºï¼šä½¿ç”¨æ³¨æ„åŠ›æƒé‡å¯¹è¾“å…¥åºåˆ— `inputs` è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°å½¢çŠ¶ä¸º `[B, D]` çš„è¾“å‡ºã€‚è¿™æ˜¯é€šè¿‡ `torch.sum(inputs * attention_weight.unsqueeze(-1), dim=1)` å®ç°çš„ï¼Œå…¶ä¸­ `attention_weight.unsqueeze(-1)` æ˜¯ä¸ºäº†ä¸è¾“å…¥å¼ é‡ç›¸ä¹˜æ—¶ç»´åº¦åŒ¹é…ã€‚
> 
> è¿™ä¸ªæ¨¡å—çš„ä¸»è¦ç›®çš„æ˜¯é€šè¿‡åŠ æƒæ±‚å’Œçš„æ–¹å¼ï¼Œæ ¹æ®è¾“å…¥åºåˆ—ä¸­ä¸åŒä½ç½®çš„æ³¨æ„åŠ›æƒé‡æ¥ç”Ÿæˆæœ€ç»ˆçš„è¾“å‡ºã€‚

æ€»ä½“æ¥è¯´ï¼ŒåŠ æ€§æ³¨æ„åŠ›æœºåˆ¶é€šè¿‡å­¦ä¹ æƒé‡æ¥åŠ¨æ€åœ°å…³æ³¨è¾“å…¥çš„ä¸åŒéƒ¨åˆ†ï¼Œä»¥ä¾¿æ›´å¥½åœ°æ•æ‰è¾“å…¥ä¹‹é—´çš„å…³ç³»ã€‚è¿™ç§æœºåˆ¶çš„ä¼˜åŠ¿åœ¨äºå¯ä»¥å¤„ç†ä¸åŒé•¿åº¦çš„è¾“å…¥åºåˆ—ï¼Œå¹¶ä¸”å…·æœ‰è¾ƒå¥½çš„è¡¨è¾¾èƒ½åŠ›ã€‚

### å¾®è°ƒç­–ç•¥

#### å†»ç»“å’Œç¼“å­˜

å†»ç»“ä½å±‚ï¼Œåªå¾®è°ƒæœ€ä¸Šé¢ä¸¤å±‚ï¼Œä»è€Œå‡å°‘è®¡ç®—é‡  
**ç¼“å­˜**  
ç¼“å­˜è¢«å†»ç»“çš„å±‚å—ï¼Ÿ

#### LORAå¾®è°ƒ

[ä¸€æ–‡è¯»æ‡‚ï¼šè¯¦ç»†è§£é‡ŠLoRAå¾®è°ƒåŸç†ï¼ˆé™„æ‰‹æ’¸ä»£ç ï¼‰ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/681502990)

### User Encoder

>[!note]-  
>åŠ æƒèšåˆå†…å®¹ç¼–ç å™¨ç”Ÿæˆçš„å‘é‡
> ```python
> class UserEncoder(torch.nn.Module):
>     def __init__(self, args):
>         super(UserEncoder, self).__init__()
>         self.args = args
>         self.news_additive_attention = AdditiveAttention(
>             args.news_dim, args.user_query_vector_dim)
>         if args.use_padded_news_embedding:
>             # self.news_padded_news_embedding = nn.Embedding(1, args.news_dim)
>             self.pad_doc = nn.Parameter(torch.empty(1, args.news_dim).uniform_(-1, 1)).Type(torch.FloatTensor)
>         else:
>             # self.news_padded_news_embedding = None
>             self.pad_doc = None
>         
> 
>     def _process_news(self, vec, mask, pad_doc,
>                     additive_attention, use_mask=False, 
>                     use_padded_embedding=False):
>         assert not (use_padded_embedding and use_mask), 'Conflicting config'
>         if use_padded_embedding:
>             # batch_size, maxlen, dim
>             batch_size = vec.shape[0]
>             padding_doc = pad_doc.expand(batch_size, self.args.news_dim).unsqueeze(1).expand( \
>                                          batch_size, self.args.user_log_length , self.args.news_dim)
>             # batch_size, maxlen, dim
>             vec = vec * mask.unsqueeze(2).expand(-1, -1, self.args.news_dim) + padding_doc * (1 - mask.unsqueeze(2).expand(-1, -1, self.args.news_dim))
>         # batch_size, news_dim
>         vec = additive_attention(vec,
>                                  mask if use_mask else None)
>         return vec
> 
>     
>     def forward(self, log_vec, log_mask):
>         """
>         Returns:
>             (shape) batch_size,  news_dim
>         """
>         # batch_size, news_dim
>         log_vec = self._process_news(log_vec, log_mask, self.pad_doc,
>                                      self.news_additive_attention, self.args.user_log_mask,
>                                      self.args.use_padded_news_embedding)
>         
>         user_log_vecs = log_vec
> 
> 
>         return user_log_vecs
> 
> ```

---

## åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤ç®—æ³•

**å‚è€ƒæ–‡ç« **ï¼š  
[åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤ç®—æ³•ï¼ˆUserCFï¼‰åŸç†ä»¥åŠä»£ç å®è·µ - ç®€ä¹¦ (jianshu.com)](https://www.jianshu.com/p/7c5d9c008be9)

### ç®—æ³•åŸç†

**ç”¨æˆ·ä¸ç”¨æˆ·ä¹‹é—´çš„ç›¸ä¼¼åº¦**  
å¦‚æœè¦ç»™ä¸€ä¸ªç”¨æˆ·Aæ¨èç‰©å“ï¼Œå¯ä»¥å…ˆæ‰¾åˆ°ä¸Aæœ€ä¸ºç›¸ä¼¼çš„ç”¨æˆ·Bï¼Œæ¥ç€è·å–ç”¨æˆ·Bæœ€å–œæ¬¢çš„ä¸”ç”¨æˆ·Aæ²¡æœ‰å¬è¯´è¿‡çš„ç‰©å“ï¼Œå¹¶é¢„æµ‹ç”¨æˆ·Aå¯¹è¿™äº›ç‰©å“çš„è¯„åˆ†ï¼Œä»ä¸­é€‰å–è¯„åˆ†æœ€é«˜çš„è‹¥å¹²ä¸ªç‰©å“æ¨èç»™ç”¨æˆ·Aã€‚

#### ç”¨æˆ·ä¹‹é—´ç›¸ä¼¼åº¦è®¡ç®—

- Jaccardå…¬å¼  
![ä»£ç ç†è§£-5](assets/ä»£ç åˆæ­¥ç†è§£-4.png)  
å¯¹äºç”¨æˆ·uå’Œç”¨æˆ·vï¼Œä»¤N(u)ä»£è¡¨ç”¨æˆ·uå–œæ¬¢çš„ç‰©å“åˆé›†ï¼Œä»¤N(v)ä»£è¡¨ç”¨æˆ·vå–œæ¬¢çš„ç‰©å“åˆé›†ã€‚N(u)âˆ©N(v)ä»£è¡¨çš„æ˜¯ç”¨æˆ·uå’Œç”¨æˆ·véƒ½å–œæ¬¢çš„ç‰©å“ï¼ŒN(u)âˆªN(v)ä»£è¡¨çš„æ˜¯ç”¨æˆ·uå’Œç”¨æˆ·vå–œæ¬¢çš„ç‰©å“çš„åˆé›†

å°†ç”¨æˆ·uä¸ç”¨æˆ·véƒ½å–œæ¬¢çš„ç‰©å“çš„æ•°é‡é™¤ä»¥ä»–ä»¬å–œæ¬¢ç‰©å“çš„æ€»å’Œï¼Œå¦‚æœuå’Œvå–œæ¬¢çš„ç‰©å“æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼Œåˆ™uå’Œvçš„ç›¸ä¼¼åº¦ä¸º1

- ä½™å¼¦ç›¸ä¼¼åº¦  
  ![ä»£ç ç†è§£-6](assets/ä»£ç åˆæ­¥ç†è§£-5.png)  
  åˆ†æ¯éƒ¨åˆ†æ˜¯uå–œæ¬¢çš„ç‰©å“çš„æ•°é‡ä¸vå–œæ¬¢çš„ç‰©å“çš„æ•°é‡çš„ä¹˜ç§¯  
  ![ä»£ç ç†è§£-7](assets/ä»£ç åˆæ­¥ç†è§£-6.png)

#### ç”¨æˆ·å¯¹ç‰©å“æ„Ÿå…´è¶£ç¨‹åº¦

![ä»£ç ç†è§£-8](assets/ä»£ç åˆæ­¥ç†è§£-7.png)  
![S(\mu, K)](https://math.jianshu.com/math?formula=S(%5Cmu%2C%20K)) ä»£è¡¨çš„æ˜¯ä¸ç”¨æˆ·![\mu](https://math.jianshu.com/math?formula=%5Cmu)æœ€ç›¸ä¼¼çš„Kä¸ªç”¨æˆ·ï¼Œå°†ä¸ç”¨æˆ·![\mu](https://math.jianshu.com/math?formula=%5Cmu)ç›¸ä¼¼çš„ç”¨æˆ·åˆ—è¡¨æŒ‰ç…§ç›¸ä¼¼åº¦è¿›è¡Œæ’åºå°±å¯ä»¥å¾—åˆ°ã€‚![N(i)](https://math.jianshu.com/math?formula=N(i))ä»£è¡¨çš„æ˜¯å¯¹å–œæ¬¢ç‰©å“içš„ç”¨æˆ·é›†åˆï¼Œ![W\mu\nu](https://math.jianshu.com/math?formula=W%5Cmu%5Cnu)ä»£è¡¨çš„æ˜¯ç”¨æˆ·![\mu](https://math.jianshu.com/math?formula=%5Cmu)å’Œç”¨æˆ·![\nu](https://math.jianshu.com/math?formula=%5Cnu)ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œè¿™ä¸ªä¹Ÿå¯ä»¥ç›´æ¥ä»ç”¨æˆ·ç›¸ä¼¼åº¦è¡¨ä¸­å¾—åˆ°ã€‚![R\nu i](https://math.jianshu.com/math?formula=R%5Cnu%20i)ä»£è¡¨ç”¨æˆ·vå¯¹ç‰©å“içš„å…´è¶£ï¼Œå› ä¸ºä½¿ç”¨çš„æ˜¯å•ä¸€è¡Œä¸ºçš„éšåé¦ˆæ•°æ®ï¼Œæ‰€ä»¥æ‰€æœ‰çš„![R\nu i=1](https://math.jianshu.com/math?formula=R%5Cnu%20i%3D1)ã€‚

å¯¹äºä¸ç”¨æˆ·![\mu](https://math.jianshu.com/math?formula=%5Cmu)æœ€ç›¸ä¼¼çš„Kä¸ªç”¨æˆ·ï¼Œæˆ‘ä»¬åˆ†åˆ«è®¡ç®—ç”¨æˆ·![\mu](https://math.jianshu.com/math?formula=%5Cmu)ä¸è¿™Kä¸ªç”¨æˆ·å–œæ¬¢çš„ç‰©å“é›†åˆ![I_n, n \in \{1,2,...,N\}](https://math.jianshu.com/math?formula=I_n%2C%20n%20%5Cin%20%5C%7B1%2C2%2C...%2CN%5C%7D)ä¹‹é—´çš„æ„Ÿå…´è¶£ç¨‹åº¦ï¼Œå¾—åˆ°ç”¨æˆ·![\mu](https://math.jianshu.com/math?formula=%5Cmu)  
å¯¹è¿™Nä¸ªç‰©å“çš„æ„Ÿå…´è¶£ç¨‹åº¦åˆ—è¡¨ï¼Œç„¶åå°†å…¶é€†åºæ’åºï¼Œå–å‰mä¸ªç‰©å“æ¨èç»™ç”¨æˆ·![\mu](https://math.jianshu.com/math?formula=%5Cmu)

### æµç¨‹

1. è·å–æ•°æ®é›†ï¼Œå¹¶ç­›é€‰å‡ºåˆé€‚éƒ¨åˆ†
2. å»ºç«‹User-Itemè¡¨ï¼Œå³ç”¨æˆ·-ç‰©å“åˆ—è¡¨ï¼Œè®°å½•äº†æ¯ä¸ªç”¨æˆ·å–œçˆ±çš„ç‰©å“ã€‚ 

| ç”¨æˆ·  | æµè§ˆè¿‡çš„æ–°é—»  |
| --- | ------- |
| A   | {a,b,d} |
| B   | {a,c,d} |
| C   | {b,e}   |
| D   | {c,d,e} |

^5c83b5

3. å»ºç«‹å€’æ’è¡¨ï¼Œå»ºç«‹å€’æ’è¡¨ï¼Œå³Item-Userè¡¨ã€‚ï¼ˆåªéœ€è¦è®¡ç®—é‚£äº›å½¼æ­¤ä¹‹é—´æœ‰å…±åŒå–œçˆ±ç‰©å“çš„ç”¨æˆ·ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼‰

| æ–°é—»  | æµè§ˆè¿‡çš„ç”¨æˆ·  |
| --- | ------- |
| a   | {A,B}   |
| b   | {A,C}   |
| c   | {B,D}   |
| d   | {A,B,D} |
| e   | {C,D}   |

4. å»ºç«‹ç”¨æˆ·äº¤é›†çŸ©é˜µï¼ˆç”¨äºè®¡ç®—ç”¨æˆ·é—´çš„ç›¸ä¼¼æ€§ï¼‰

|     | A   | B   | C   | D   |
| --- | --- | --- | --- | --- |
| A   | 0   | 2   | 1   | 1   |
| B   | 2   | 0   | 0   | 2   |
| C   | 1   | 0   | 0   | 1   |
| D   | 1   | 2   | 1   | 0   |

5. è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ

| |A|B|C|D|
|---|---|---|---|---|
|A|0|0.67|0.41|0.33|
|B|0.67|0|0|0.67|
|C|0.41|0|0|0.41|
|D|0.33|0.67|0.41|0|

6. è¿›è¡Œç‰©å“æ¨è

ä¾‹å¦‚å¯¹Cè¿›è¡Œæ¨è  
ç”±è¡¨å¯çŸ¥ï¼ŒCå’ŒADæœ‰ç›¸ä¼¼  
æŸ¥[User-Itemè¡¨](#^5c83b5)ï¼Œå¾—åˆ°ADå–œæ¬¢çš„ç‰©å“ï¼Œå†å‡å»Cå–œæ¬¢çš„ç‰©å“æœ€åå¾—åˆ°å¾…é€‰ç‰©å“{a,c,d}  
è®¡ç®—æ„Ÿå…´è¶£ç¨‹åº¦

```
p(C,a) = W[C][A] = 0.41  
p(C,c) = W[C][D] = 0.41  
p(C,d) = W[C][A] + W[C][D] = 0.82
```

å€’æ’å¾—åˆ°æ¨èåˆ—è¡¨

### æµç¨‹æ€»ç»“

- è®­ç»ƒé˜¶æ®µ
- æ¨èé˜¶æ®µ

å¯¹äºè®­ç»ƒé˜¶æ®µï¼Œå¯åˆ†ä¸ºä»¥ä¸‹å‡ æ­¥ï¼š

1. æ•°æ®é¢„å¤„ç†ï¼Œå»ºç«‹User-Itemè¡¨
2. å»ºç«‹Item-Userå€’æ’è¡¨
3. å»ºç«‹ç”¨æˆ·ç‰©å“äº¤é›†çŸ©é˜µ
4. å»ºç«‹ç”¨æˆ·ç›¸ä¼¼åº¦çŸ©é˜µ

å¯¹äºæ¨èé˜¶æ®µï¼Œå¯åˆ†ä¸ºä»¥ä¸‹å‡ æ­¥ï¼š

1. å¯»æ‰¾ä¸è¢«æ¨èç”¨æˆ·æœ€ç›¸ä¼¼çš„Kä¸ªç”¨æˆ·
2. è®¡ç®—ç”¨æˆ·å¯¹ç‰©å“çš„æ„Ÿå…´è¶£åˆ—è¡¨å¹¶é€†åºæ’åˆ—

çº¿æ€§æµç¨‹ï¼Œç”»ä¸äº†æµç¨‹å›¾

## LLMç”¨äºå†…å®¹ç¼–ç å™¨

### run.py

#### main()å‡½æ•°

``utils.setuplogger() ``è®¾ç½®æ—¥å¿—ï¼ˆå¾…äº†è§£ï¼‰  
`args = parse_args()`å‚æ•°è§£æï¼ŒåŒ…æ‹¬æ¨¡å‹ï¼Œæƒé‡ä½ç½®ï¼Œåˆ†è¯å™¨ä½ç½®ç­‰ç­‰

```python
if 'train' in args.mode:
    train(args)
if 'test' in args.mode:
    test(args)
```

æ¨¡å¼é€‰æ‹©

#### train()å‡½æ•°

```python
# Only support title Turing now
assert args.enable_hvd  # TODO
if args.enable_hvd:
    import horovod.torch as hvd

if args.load_ckpt_name is not None:
    #TODO: choose ckpt_path
    ckpt_path = utils.get_checkpoint(args.model_dir, args.load_ckpt_name)
else:
    ckpt_path = utils.latest_checkpoint(args.model_dir)


hvd_size, hvd_rank, hvd_local_rank = utils.init_hvd_cuda(
    args.enable_hvd, args.enable_gpu)
```

åŠ è½½å¤šå¡è®­ç»ƒæ¡†æ¶ï¼Œæƒé‡ä½ç½®ç­‰ç­‰

```python
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased") #baseæŒ‡æ¨¡å‹å¤§å°ï¼ˆå±‚æ•°ï¼‰ï¼ŒuncasedæŒ‡æ˜¯å¦åŒºåˆ†å¤§å°å†™
config = AutoConfig.from_pretrained("bert-base-uncased", output_hidden_states=True) # è¾“å‡ºéšè—å±‚çŠ¶æ€ï¼Ÿ
config.num_hidden_layers = 8 #é»˜è®¤12å±‚ï¼Ÿåªä½¿ç”¨8å±‚ï¼Ÿ
bert_model = AutoModel.from_pretrained("bert-base-uncased",config=config) #åŠ è½½æ¨¡å‹
```

- åŠ è½½bertæ¨¡å‹

```python
# freeze parameters å†»ç»“ä¸éœ€è¦ä½¿ç”¨çš„å‚æ•°
for name,param in bert_model.named_parameters():
    if name not in finetuneset:
        param.requires_grad = False
```

å†»ç»“ä¸éœ€è¦ä½¿ç”¨çš„å‚æ•°

```python
news, news_index, category_dict, domain_dict, subcategory_dict = read_news_bert(
    os.path.join(args.root_data_dir,
                f'{args.dataset}/{args.train_dir}/news.tsv'), 
    args,
    tokenizer
)
```

è¯»å–æ•°æ®é›†  
[read\_news\_bert()](read_news_bert().md)  
ä»å­—å…¸ä¸åˆ—è¡¨è½¬ä¸ºnumpyæ•°ç»„ï¼ˆå­˜å‚¨tokenç­‰ï¼‰ä»¥è¾“å…¥æ¨¡å‹

```python
news_combined = np.concatenate([
    x for x in
    [news_title, news_title_type, news_title_attmask, \
        news_abstract, news_abstract_type, news_abstract_attmask, \
        news_body, news_body_type, news_body_attmask, \
        news_category, news_domain, news_subcategory]
    if x is not None], axis=1)
```

å°†æ–°é—»æ–‡ç« çš„ä¸åŒéƒ¨åˆ†ï¼ˆæ ‡é¢˜ã€æ‘˜è¦ã€æ­£æ–‡ã€ç±»åˆ«ã€åŸŸå’Œå­ç±»åˆ«ï¼‰è¿æ¥æˆä¸€ä¸ªå¤§çš„ NumPy æ•°ç»„ã€‚

#### æ¨¡å‹

`model = ModelBert(args, bert_model, len(category_dict), len(domain_dict), len(subcategory_dict))`  
æ¨¡å‹ç”±news encoderå’Œuser_encoderã€äº¤å‰ç†µæŸå¤±å‡½æ•°ç»„æˆ  
è¾“å…¥ logidï¼ˆç”¨æˆ·å†å²æµè§ˆè®°å½•ï¼‰åˆ°user_encoderå¾—åˆ°ç”¨æˆ·å‘é‡  
news encoderè¾“å…¥input_idsï¼ˆæ–°é—»ï¼‰ å¾—åˆ°æ–°é—»å‘é‡
