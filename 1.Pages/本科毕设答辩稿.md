---
Type:
  - Page
aliases: 
Status: 
tags: 
modifiedDate: 星期一, 五月 26日 2025, 8:41:11 晚上
---

## 精简版本

- 开场白
    - 各位老师上午/下午好，我叫张杰凯，我的指导老师是郭楠老师。我毕业设计的题目是**基于大语言模型的混合推荐算法设计与实现**。
    - 这是我的目录。接下来，我将从研究背景与相关技术，难点问题，研究内容与实现，总结与展望这四个方面详细的介绍我的工作。
- 首先是研究背景与相关技术，首先需要介绍的是推荐系统的现状。
    - 随着信息技术和互联网的进步，人们从信息匮乏的时代逐步迈入了信息过载的时代。商家无法推广商品，用户难以获取信息。*推荐系统就是一个将用户、商家和平台连接起来的桥梁。*
    - *然而，现有推荐系统的一个共同特征是其封闭性——推荐所用的模型是在封闭系统中训练和部署的。模型的训练数据来源于封闭的系统内部，这无疑限制了推荐系统的性能。* 
    - *大模型的快速发展有望解决这个问题。大模型其庞大的知识库和突出的涌现能力有望为封闭的推荐系统与开放世界之间搭建桥梁。*
    - 一种可行的方向就是将大模型作为传统推荐的辅助工具。大模型训练在极大的数据集上，其能作为一个中介，有效的连接推荐系统和开放世界。具体而言，就是使用各种大小的预训练大模型，编码数据集中的各种文本特征或者利用大模型的推理能力获取额外的知识，来获得更好的用户表示。
    - *本次毕设的主要研究内容就是探索如何利用大模型获取额外的知识并利用。事实上，这样的做法会出现两个主要问题*
        - *模型生成问题答案时遇到的组合性差距以及模型生成的正确但无用的知识*
        - *即使成功的从大模型中获取了知识，但知识通常为文本或巨大密集向量通常与推荐系统不直接兼容*
- 接下来，是研究内容与实现，我将对前面提出的两个问题进行分析，并给出自己的解决方案。
    - 对于第一个问题
        - 组合性差距指的是模型在生成组合式问题的正确答案时失败，但可以正确回答所有其子问题。当问题涉及多个部分或子问题时，模型可能难以组合问题并形成整体理解，导致生成的答案不准确。
        - 此外，要求大模型确定用户对某个物品的兴趣可能涉及到多个步骤，大模型可能无法直接产生准确的用户偏好知识。
        - 再者，并非从 大模型 中获取的所有知识都是有用的。例如，对于电影，大模型 可以推断用户可能更喜欢获得多个奖项的，广受好评的电影，而生成的事实知识是关于目标电影的故事情节的。
        - 受因子分解机使用参数化分解来建模变量之间的所有交互的做法影响我们提出了一种基于大模型的多场景适应的因式分解的 Prompt 数据增强方法。利用 大模型获得相关因素，并将用户偏好明确的“因子化”为几个主要因素，将复杂的偏好推理问题分解为每个因素的简单子问题，从而缓解上述问题。
        - 数据增强的整体流程如图所示。其分为两个主要阶段，首先是使用大模型获取影响用户对项目偏好的关键因素。
        - 第二个阶段是使用 大模型 根据 Prompt 生成对应的知识。事实上，来自外部世界的两类信息对于推荐特别有用——从用户行为和个人资料中推断出的深入用户偏好的推理知识，以及关于候选项目具体信息的事实知识。结合上一阶段得到的因素与数据集，生成两种提示词并向 大模型 请求服务，得到最后的用户偏好推理知识和物品事实知识。
        - 如图所示，对于我们使用的三个数据集，我们使用GLM3 给出关键因素并通过人工进行确定。
        - 对于得到的这些关键因素，我们将其融入提示词中，指示 大模型 围绕这些因素进行回答。我们设计一个提示词模板，如图中所示，其意思翻译过来就是**“给出用户的书籍评分记录 {{History}} ，围绕题材，作者，写作风格等因素分析用户对书本的偏好”**。通过这种方式，我们就得到了原始数据集未涉及到的两种开放世界知识。
    - 在解决了上一个问题后，
        - 我们已经成功地从模型中获取了两种开放世界知识，但我们又遇到了新的问题，即我们从大模型中获取的知识是文本形式的，它与推荐系统不直接兼容。即使能够使用一些开源大模型获取其解码后输出，但其输出通常是巨大的密集向量，比如每个 token4096 维。除此之外，模型生成的知识可能包含噪声或不可靠的信息。
        - 为此，本次毕设提出了一种基于大模型的知识适应和知识利用方法。即利用大模型编码知识并设计网络来转换向量，让推荐模型能够利用这些知识
        - 具体的，我们提出的知识适应方法的整体结构如图所示，在第一个阶段，我们利用知识编码器将关于用户偏好的推理知识和关于待选项目的事实知识转为表示向量。在第二个阶段，我们实现一种混合专家适配器模块，将密集向量从语义空间转换到推荐空间
        - 知识编码器的原理比较简单，就像这两个公式所表示的。𝑘𝑙𝑔表示使用大模型生成的两种知识。𝐸𝑛𝑐𝑜𝑑𝑒𝑟为 BERT。𝐴𝑔𝑔𝑟为平均池化。整体流程就是将推理知识和事实知识送入编码器以进行知识编码，得到相应的输出，然后通过平均池化，得到表示向量。
        - 混合专家适配器参考了混合专家方法，对于表示向量，它被输入到门控网络，以获得共享专家和专用专家的权重。此外，推理表示还被输入到共享专家和专用专家中，以获得专家的输出向量。最后，将这些专家的输出向量加权求和，得到最后的推理增强向量。
        - 关于知识利用，即将之前获取到的增强向量直接视为推荐模型的附加输入特征。以 AutoInt 推荐模型和混合专家适配器的结合为例，我们使用 HEA把从知识编码器中获得的知识表示转换为增强向量，这样其就能作为推荐系统的额外特征，与原始特征一道进入推荐模型主体结构进行计算。
    - 虽然我们对之前的两个问题进行了分析并给出了 方案，但我们还没有进行实验以验证我们方法的有效性。于是本次毕设围绕以下三个问题开展了实验
        - 前两个方法整体上可以在不同推荐任务上，比如 CTR 预测和 Reranking 任务，为推荐模型带来怎样的改进？
        - 通过基于大模型的多场景适应因式分解 Prompt 方法获取的推理知识和事实知识如何有助于推荐系统提升性能？
        - 使用不同的知识适应方法，比如将混合专家适配器替换为普通的多层感知机 MLP，将会如何影响推荐模型的性能？
        - 这是我们的实验的三个数据集，分别有电影评分数据集 MovieLens，动漫评分数据集 ANime 和亚马逊书籍评论数据集 Amzonbooks。评价指标为 AUC 和 LogLoss。超参使用网格和Optuna 进行选择
        - 实验 1，在 CTR 和 reranking 任务上的改进
            - 本文所使用的方法有效且具有通用性，能广泛应用于各种推荐模型上，无论是特征交互还是行为建模。例如，9 个推荐模型的 AUC 指标均有大于 0.70%的提升。
            - 应用本文方法能明显提升用于 reranking 任务的推荐模型相关指标。例如，应用了本文方法的 DLCM 模型在 MAP@7 和 NDCG@7 上分别提高 4.25%和 3.53%
        - 实验二，对推理知识和事实知识的消融实验
            - 单独的事实知识效果较差，单独推理知识的效果更为突出。
            - 联合使用显著优于单独使用
        - 实验三：不同知识适应方法的影响
            - HEA 能更好的从两种知识向量中获取用户偏好，从而提高推荐模型性能。
            - 从语义空间到推荐空间的转换，需要复杂的网络结构。
    - 在前两个工作基础上，我们是否能使用其它方法比较简单的继续增强推荐性能，这是一个值得思考的问题。
        - 在学习了集成学习后，本次毕设实现了一种基于软投票的混合推荐方法。
        - 软投票的概念如左图所示，即将各个模型的输出概率取平均。在三个数据集上的实验结果如右图所示。右图中每六个组合为一组，按组合结果倒序排序。第六个为性能最好的单独模型。在分析结果后，我们可以给出如下三个结论。
        - 在软投票的情况下，集成学习效果受单个模型性能的影响较大。
        - 基础 AUC 越高，提升越小
        - 集成效果和基学习器数量并不是正相关。
- 总结一下，本次毕设的主要成果有如下三项，分别是
    - 基于国产化环境和大模型的一种多场景适应因式分解 Prompt 数据增强方法
    - 一种基于大模型的知识适应和知识利用方法
    - 一种基于软投票方法的的混合推荐方法
    - 但事实上，仍有许多可以继续改进的部分，比如
    - 继续改进 Prompt，尝试融入常用提示工程技术的优点，改变 Prompt 进一步提高推荐性能
    - 将知识编码器从 Bert 替换为性能更佳的预训练语言模型，探索不同质量信息是如何影响推荐性能的
    - 基于软投票的混合推荐仅能有限的提高推荐性能，探索使用其他方法
    - 本次毕设的整体结构如图所示。
- 致谢

## 概念

1. **研究背景与相关技术**
    - 推荐系统现状的详细分析和目前存在的主要问题是什么？
        - 随着信息技术和互联网的进步，人们从信息匮乏的时代逐步迈入了信息过载的时代。无论是作为信息消费者的用户，还是作为商家的信息生产者，都面临着巨大的挑战，即难以获取需要的信息以及难以使自己的信息脱颖而出。推荐系统就是一个将用户、商家和平台连接起来的桥梁，是解决这一矛盾的重要工具。
        - 然而，现有推荐系统的一个共同特征是其封闭性——推荐所用的模型是在封闭系统中训练和部署的。经典推荐系统训练使用的数据局限于一个或几个特定的应用领域。模型的训练数据来源于封闭的系统内部，并且训练过程也完全在这个封闭的系统中进行。外部数据不被引入或使用。这不仅限制了推荐模型可以学习的信息，还限制了推荐系统的性能。 
    - 为什么选择基于大语言模型的混合推荐算法作为研究方向？
        - 最近大语言的模型（LLM）的快速发展彻底改变了各个研究领域的学习范式，无论是在NLP，CV 甚至是图形渲染，大模型都体现出一种一统天下的趋势。大型语言模型在NLP领域的应用已经变得无处不在，从文本生成到文本分类、命名实体识别、语义理解等各个任务中都取得了巨大成功。在CV 邻域，出现了一些结合文本和图像信息的多模态模型，通过将文本和图像信息结合起来，模型能够在图像识别、图像生成和多模态理解等任务中取得显著的性能提升。
2. **难点问题**
    - 模型生成问题答案时遇到的组合性差距具体指的是什么？能否给出一个具体的例子？
        - 模型在理解和生成复杂结构、合成新知识或处理多步骤推理任务时的局限性。这种差距表现在模型难以将已学到的简单概念和规则灵活地组合起来，以生成符合逻辑的新答案。
        - ==语言模型==可以准确预测名人的出生和死亡日期，但可能无法准确预测年龄。当然，这种情况随着数据集的增大会有所改善。
3. **研究内容与实现**
4. **实验结果**
    - 实验中使用的三个数据集（MovieLens，ANime，Amzonbooks）的具体特点是什么？为什么选择这些数据集？
        - 本次实验使用的数据集包括广为使用的公共数据集电影评分数据集MovieLens-1M和书本评分数据集Amzon Books，以及相对小众的动漫评分数据集Anime。通过在两个广泛使用的数据集加一个相对小众的数据集上进行实验，可以验证本方法的推广能力。此外，相比于其它数据集，比如新闻推荐数据集Mind，这些数据集的规模较小，有利于快速验证方法的性能。且这三个数据集的数据形式统一，每个用户的历史浏览评分均以一条条记录单独给出，适用于传统的基于ID的推荐系统，如DIN，AutoInt等。
5. **技术细节**
    - 在知识编码器的设计中，为什么选择BERT-base-uncased模型？有没有考虑过其他模型？
        - **广泛使用**：BERT-base-uncased模型是NLP领域中广泛使用的预训练模型之一，具有很好的通用性和稳定性。
        - **性能**：此模型在多个NLP任务上表现出色，证明了其强大的文本表示能力。
        - **资源**：BERT-base-uncased模型的资源和工具较为丰富，易于获取和部署。
        - 比较了llama2 和chatglm，但考虑到计算资源或时间，选择了相对容易部署和训练的BERT-base-uncased模型。
        - 在总结中提到了可以将bert 替换为其它大模型
    - 介绍一下MoE 方法
        - **MoE（Mixture of Local Experts）是由一个专家网络和门控网络组成的系统。所有专家接收相同的输入并且具有相同数量的输出。门控网络用于控制每个专家网络的权重。选择器（Selector）选择器类似于一个多输入、单输出的随机开关。**
6. **集成学习**
    - 你提到了基于软投票的混合推荐方法，这种方法在实际应用中有哪些潜在的优势和局限性？
        - 混合推荐，即将多个模型混合在一起可以减少单个模型的偏差和过拟合问题，提高整体推荐系统的鲁棒性。
        - **灵活性**，软投票可以很容易地适应不同类型的基模型，并且可以轻松地添加或移除基模型，而不影响整体集成方法
        - 软投票的实现相对简单
- 为什么这种做法行不通
    - 实时推荐系统可以接受的延迟通常要求在几十毫秒（ms）到几百毫秒之间，而大模型的参数量过大，其推理时间往往以秒为单位，这是不可接受的。
    - 再者，其各项指标也不高
- 为什么要把原始id转为内部的id
    - 减少参数复杂程度，原始ID（例如UUID、复杂字符串、长文本等）通常比简单的整数ID占用更多的存储空间。将其转化为整数ID可以显著减少存储需求。
    - 原始ID可能包含敏感信息或可以推断出特定的信息（例如用户ID、订单ID等）。将其转换为内部ID可以增加一层安全保护，避免暴露敏感信息。
    - 通过生成内部ID，可以确保系统内ID的一致性和唯一性，避免重复和冲突。也便于操作
- 为什么把文本转为嵌入
    - 文本数据往往是高维的和稀疏的，推荐模型不能直接理解文本
    - 深度学习模型需要固定维度的数值输入。将文本转化为嵌入后，与其它特征保持相同的输入格式
    - 嵌入可以捕捉到文本的语义信息。相似的文本在嵌入空间中往往距离较近，这使得推荐系统能够更好地理解和利用文本内容进行推荐。
- 多个步骤
    - 一是用户对物品的兴趣可能受到多个关键因素的影响，用户的兴趣是多样化和多方面的，LLM首先需要确定这些因素。再者，LLM需要在这些因素的基础上推理出用户对项目的兴趣。这个过程涉及到多个步骤。LLM可能无法准确确定这些关键因素然后在此基础上进行推理。
- 因子分解机
    - [因子分解机](因子分解机.md)
- Prompt 方法
    - [提示工程](提示工程.md)
- FastAPI 框架
    1. **创建FastAPI应用实例**：
        - `app = FastAPI()`: 创建FastAPI应用实例。
    2. **定义请求模型**：
        - `RequestItem`: 使用Pydantic的`BaseModel`定义请求数据模型，包含`prompt`和其他生成文本的参数。
    3. **获取答案函数**：
        - `get_answer(prompt, do_sample, top_k, top_p, role)`: 根据输入的提示和生成参数，使用加载的模型生成文本回复。
    4. **主路由处理函数**：
        - `create_item(request: RequestItem)`: 处理POST请求，接收用户输入，调用`get_answer`函数，并返回生成的文本回复。
    5. **主程序**：
        - `if __name__ == "__main__"`: 如果直接运行此脚本，则初始化Tokenizer、Config和Model，然后启动Uvicorn服务器运行FastAPI应用。
    6. **运行Uvicorn服务器**：
        - `uvicorn.run(app, host="0.0.0.0", port=7990, workers=1)`: 启动服务器，设置主机地址、端口和工作进程数。
- 集成学习
    - Bagging的核心思想是通过对数据集进行有放回抽样（bootstrap sampling），生成多个子数据集，并在每个子数据集上训练一个基学习器。最终的预测结果是这些基学习器的集成输出（如通过投票或平均）**但无法利用多个不同的模型**
    - 通过迭代地训练弱学习器，每次训练时关注前一轮中被错误分类的样本。每个弱学习器的权重根据其错误率进行调整，最终将这些弱学习器的预测结果组合起来，提高整体模型的准确性。
- 与推荐空间显着不同的语义空间中
    - 即使一些 LLM 是开源的，解码的输出通常是大的密集向 量（例如，每个令牌 4096）并且位于与推荐（推荐系统）空间显着不同 的语义空间中。解释这句话
    - 这意味着解码输出的语义（即向量所代表的含义）与推荐系统所需的语义空间不同。推荐系统通常需要根据用户的兴趣和行为来生成推荐，而 LLM 生成的向量可能不直接对应于用户的兴趣或推荐系统的决策逻辑。

## 原始版本

- 开场白 2.30
    - 各位老师上午/下午好，我叫张杰凯，我的指导老师是郭楠老师。我毕业设计的题目是**基于大语言模型的混合推荐算法设计与实现**。
    - 这是我的目录。接下来，我将从我的毕业设计的研究背景与相关技术，难点问题，研究内容与实现，总结与展望这四个方面详细的介绍我的工作。
- 首先是研究背景与相关技术，首先需要介绍的是推荐系统的现状。
    - 随着信息技术和互联网的进步，人们从信息匮乏的时代逐步迈入了信息过载的时代。无论是作为信息消费者的用户，还是作为商家的信息生产者，都面临着巨大的挑战，即难以获取需要的信息以及难以使自己的信息脱颖而出。推荐系统就是一个将用户、商家和平台连接起来的桥梁，是解决这一矛盾的重要工具。
    - 然而，现有推荐系统的一个共同特征是其封闭性——推荐所用的模型是在封闭系统中训练和部署的。经典推荐系统训练使用的数据局限于一个或几个特定的应用领域。模型的训练数据来源于封闭的系统内部，并且训练过程也完全在这个封闭的系统中进行。外部数据不被引入或使用。这不仅限制了推荐模型可以学习的信息，还限制了推荐系统的性能。 
    - 大模型的快速发展有望解决这个问题。基于 Transformer 架构的预训练语言模型凭借其其庞大的知识库和突出的涌现能力有望为弥合经典推荐模型和开放世界知识之间的差距做出重大贡献。大模型有望为封闭的推荐系统与开放世界之间搭建桥梁。
    - 事实上，已经有一些工作已经尝试将推荐系统中的各种任务转换为 Prompt，让诸如 ChatGPT，LlaMA 等大模型直接给出推荐结果，替代经典推荐模型。可惜的是，这种做法的性能往往不佳。其推理延迟是无法接受的。
    - 另一种可行的方向就是将大模型作为传统推荐的辅助工具。大模型训练在极大的数据集上，其能作为一个中介，有效的连接推荐系统和开放世界。具体而言，就是使用各种大小的预训练大模型，编码数据集中的各种文本特征或者利用大模型的推理能力获取额外的知识，来获得更好的用户表示。
    - 本次毕设的主要研究内容就是探索如何利用大模型获取额外的知识并利用。事实上，这样的做法会出现两个主要问题
        - 模型生成问题答案时遇到的组合性差距以及模型生成生成的正确但无用的知识
        - 即使成功的从大模型中获取了知识，但知识通常为文本或巨大密集向量通常与推荐系统不直接兼容
- 接下来，是研究内容与实现，我将对前面提出的两个问题进行分析，并给出自己的解决方案。
    - 对于第一个问题 4:10
        - 组合性差距指的是模型在生成组合式问题的正确答案时失败，但可以正确回答所有其子问题。这可能是因为当问题涉及多个部分或子问题时，模型可能无法正确将这些部分组合起来形成整体理解，导致生成的答案不准确。
        - 此外，要求大模型确定用户对某个物品的兴趣可能涉及到多个步骤，大模型可能无法直接产生准确的用户偏好知识。
        - 再者，并非从 大模型 中获取的所有知识都是有用的。例如，对于电影，大模型 可以推断用户可能更喜欢获得多个奖项的，广受好评的电影，而生成的事实知识是关于目标电影的故事情节的。
        - 受因子分解机使用参数化分解来建模变量之间的所有交互的思想，以及提示工程中生成知识提示技术的影响，我们提出了一种基于大模型的多场景适应的因式分解的 Prompt 方法。利用 大模型获得相关因素，并将用户偏好明确的“因子化”为几个主要因素，将复杂的偏好推理问题分解为每个因素的简单子问题，从而缓解上述问题。
        - 数据增强的整体流程如图所示。其分为两个主要阶段，首先是使用大模型获取影响用户对项目偏好的关键因素。举个例子，比如在书本推荐的情况下，我们设计提示词让 ChatGPT 推测影响用户对电影偏好的因素，然后由人工对这些因素进行确认与完善，得到如题材，作者，主题等因素。
        - 第二个阶段是使用 大模型 根据 Prompt 生成对应的知识。事实上，来自外部世界的两类信息对于推荐特别有用——从用户行为和个人资料中推断出的深入用户偏好的推理知识，以及关于候选项目具体信息的事实知识。结合上一阶段得到的因素与数据集，生成用户偏好提示词和项目事实知识提示词。再使用这些提示词向 大模型 请求服务，得到最后的用户偏好推理知识和物品事实知识。
        - 值得注意的是，本次毕设使用的用于增强的 大模型 是部署于国产化的华为昇腾平台的 ChatGLM3。如左图所示，昇腾与常用的英伟达在底层硬件到运行框架都有所区别，这里就不展开说明了。我们使用基于昇思MindSpore 深度学习框架和 CANN 计算架构的 MindFormers 框架快速部署 ChatGLM3-6B。其部署流程如右图所示。并使用 Python 的FastAPI框架将 GLM3 部署于服务器上，开放端口并得到 url。使用 requests 库的 post 方法向 url 指定的服务器发送一个POST 请求，以获取 GLM3-6B 服务。
        - 回到主题上来，我们通过如下的步骤获取关键因素。对于本次毕设的使用的三个数据集，动漫 Anime，电影 MovieLens 以及书籍 AmzonBooks，我们让 GLM3 输出影响用户对项目偏好的关键因素，比如在 Anime 数据集上，就得到了 Genre，Story 等因素，随后由人类专家确认并删除其中不重要的因素 Marketing 即推广营销。
        - 对于得到的这些关键因素，我们将其融入提示词中，指示 大模型 围绕这些因素进行回答。我们设计一个提示词模板，如图中所示，其意思翻译过来就是**“给出用户的书籍评分记录 {{History}} ，围绕题材，作者，写作风格等因素分析用户对书本的偏好”**。通过这种方式，我们就得到了原始数据集未涉及到的两种开放世界知识。
    - 在解决了上一个问题后，
        - 我们已经成功地从模型中获取了两种开放世界知识，但我们又遇到了新的问题，即我们从大模型中获取的知识是文本形式的，它与推荐系统不直接兼容，即推荐系统无法直接利用这些文本知识。即使能够使用一些开源大模型获取其解码后输出，但其输出通常是巨大的密集向量，比如每个 token4096 维，且其处于与推荐空间显著不同的语义空间中。除此之外，模型生成的知识可能包含噪声或不可靠的信息。
        - 为此，本次毕设提出了一种基于大模型的知识适应和知识利用方法。即利用大模型编码知识并设计网络来转换向量，让推荐模型能够利用这些知识
        - 具体的，我们提出的知识适应方法的整体结构如图所示，在第一个阶段，我们利用知识编码器将关于用户偏好的推理知识和关于待选项目的事实知识转为表示向量。在第二个阶段，我们实现一种参考了 MoE 方法的混合专家适配器，将密集向量从语义空间转换到推荐空间
        - 知识编码器的原理比较简单，就像这两个公式所表示的。𝑘𝑙𝑔分别表示数据集中第 𝑖 个实例通过 大模型 生成的自然语言文本的推理知识和事实知识。𝐸𝑛𝑐𝑜𝑑𝑒𝑟为BERT-base-uncased。𝐴𝑔𝑔𝑟为平均池化。整体流程就是将推理知识和事实知识送入知识编码器以进行知识编码，得到相应的输出，然后通过平均池化，得到推理表示和事实表示向量。
        - 混合专家适配器参考了 混合专家方法，对于推理表示，它被输入到门控网络，以获得共享专家和专用专家的权重。此外，推理表示还被输入到共享专家和专用专家中，以获得各个专家的输出向量。最后，将这些专家的输出向量加权求和，得到最后的推理增强向量。对事实知识表示的操作与之类似。
        - 关于知识利用，即使将之前获取到的增强向量直接视为推荐模型的附加输入特征。具体来说，我们将它们用作推荐模型中的附加特征字段，使它们能够与其他特 征显式交互。以 AutoInt 推荐模型和混合专家适配器的结合为例，我们将文本知识输入到知识编码器中，得到知识表示。在其它原始特征经过通过嵌入层转换为嵌入的同时，我们使用 HEA 将知识表示转换为增强向量，之后，增强向量就能作为推荐系统的额外特征，与从数据集中提取出的原始特征一道进入推荐系统主体结构进行计算。
    - 虽然我们对之前的两个问题进行了分析并给出了解答，但我们还没有进行实验以验证我们方法的有效性。接下来我将围绕以下三个问题开展的实验结果给出方法的有效性证明。
        - 前两个方法整体上可以在不同推荐任务上，比如 CTR 预测和 Reranking 任务，为推荐模型带来怎样的改进？
        - 通过基于大模型的多场景适应因式分解 Prompt 方法获取的推理知识和事实知识如何有助于推荐系统提升性能？
        - 使用不同的知识适应方法，比如将混合专家适配器替换为普通的多层感知机MLP，将会如何影响推荐模型的性能？
        - 这是我们的实验的三个数据集，分别有电影评分数据集 MovieLens，动漫评分数据集 ANime 和亚马逊书籍评论数据集 Amzonbooks。评价指标为 AUC 和 LogLoss。
        - 实验 1，在CTR和reranking任务上的改进
            - （1）应用本文方法能明显提升用于CTR任务的推荐模型性能。例如，当在MovieLens-1M数据集上使用FiGNN，并运用本文方法进行推荐时，AUC提升了2.43%，LogLoss下降了2.09%。
            - （2）本文所使用的方法具有通用性，能广泛应用于各种推荐模型上，无论是特征交互还是行为建模。例如，9个推荐模型的AUC指标均有大于0.70%的提升。
            - （3）相比于特征交互的7种模型，2种用户行为模型即DIN和DIEN在应用本文方法后提升更为明显。这可能是因为模型得用户行为建模层更有效地利用了本文方法生成的知识增强向量，能更好的利用这些知识向量，从而更好地理解用户的行为和偏好。
            - （1）应用本文方法能明显提升用于reranking任务的推荐模型相关指标。例如，应用了本文方法的DLCM模型在MAP@7和NDCG@7上分别提高4.25%和3.53%
            - （2）本文方法对于那些不涉及历史建模的推荐模型，比如DLC和PRM，提升效果更为显著，本文的方法给出的两种知识似乎对这些方法特别有帮助。但对于充分探索了历史记录与候选项目之间关系的MIR，增强效果就不是那么显著了，
        - 实验二，对推理知识和事实知识的消融实验
            - 单独的事实知识效果较差，单独推理知识的效果更为突出。
            - 联合使用显著优于单独使用
        - 实验三：不同知识适应方法的影响
            - HEA能更好的从两种知识向量中获取用户偏好，从而提高推荐模型性能。
            - 从语义空间到推荐空间的转换，需要复杂的网络结构。
    - 在前两个工作基础上，我们是否能使用其它方法比较简单的继续增强推荐性能，这是一个值得思考的问题。
        - 在学习了集成学习后，本次毕设实现了一种基于软投票的混合推荐方法。
        - 软投票的概念如左图所示，即将各个模型的输出概率取平均。在三个数据集上的实验结果如右图所示。右图中每六个组合为一组，按组合结果倒序排序。第六个为性能最好的单独模型。在分析结果后，我们可以给出如下三个结论。
        - 在软投票的情况下，集成学习效果受单个模型性能的影响较大。
        - 基础AUC 越高，提升越小
        - 集成效果和基学习器数量并不是正相关。
- 总结一下，本次毕设的主要成果有如下三项，分别是
    - 基于国产化环境和大模型的一种多场景适应因式分解Prompt数据增强方法
    - 一种基于大模型的知识适应和知识利用方法
    - 一种基于软投票方法的的混合推荐方法
    - 但事实上，仍有许多可以继续改进的部分，比如
    - 继续改进 Prompt，尝试融入常用提示工程技术的优点，改变Prompt进一步提高推荐性能
    - 将知识编码器从Bert替换为性能更佳的预训练语言模型，探索不同质量信息是如何影响推荐性能的
    - 基于软投票的混合推荐仅能有限的提高推荐性能，探索使用其他方法
    - 本次毕设的整体结构如图所示。
- 致谢

## 提示词

根据用户的历史浏览记录用一两句话分析用户对电影的偏好
《寄生虫》3 分
《月光男孩》3 分
《冰雪奇缘》5 分
《为奴十二年》4 分
《绿皮书》3 分
